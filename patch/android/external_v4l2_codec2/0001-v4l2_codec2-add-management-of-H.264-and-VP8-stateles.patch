From be3d40a93c5b9263d70a28088bd287b213dae3c1 Mon Sep 17 00:00:00 2001
From: Nicolas LOUBOUTIN <nicolas.louboutin@st.com>
Date: Fri, 8 Mar 2024 10:48:03 +0100
Subject: [PATCH] v4l2_codec2: add management of H.264 and VP8 stateless
 decoders

Integrate two stateless decoders based on GStreamer implementation.
libv4l2_codec2_components license becomes LGPLv2.1 (dynamic library).

Change-Id: I99c459634c7c95b12f6e9141bdbdeeade5f8d66e
Signed-off-by: Nicolas LOUBOUTIN <nicolas.louboutin@st.com>
---
 common/Android.bp                             |    1 +
 common/MediaDevice.cpp                        |  170 ++
 common/V4L2Device.cpp                         |   33 +-
 .../include/v4l2_codec2/common/MediaDevice.h  |   94 +
 .../include/v4l2_codec2/common/V4L2Device.h   |    9 +-
 components/Android.bp                         |   31 +-
 components/LICENSE                            |  504 +++++
 components/V4L2DecodeComponent.cpp            |   80 +-
 components/V4L2DecodeInterface.cpp            |    2 +-
 components/V4L2Decoder.cpp                    |  632 +++---
 components/V4L2Device.cpp                     |   29 +
 components/VideoFramePool.cpp                 |    2 +-
 components/h264/H264Decoder.cpp               | 1910 +++++++++++++++++
 components/h264/V4L2H264Decoder.cpp           |  716 ++++++
 components/h264/parser/H264DPB.cpp            |  731 +++++++
 components/h264/parser/H264Parser.cpp         | 1877 ++++++++++++++++
 components/h264/parser/NalReader.cpp          |  193 ++
 .../components/V4L2DecodeInterface.h          |    1 +
 .../v4l2_codec2/components/V4L2Decoder.h      |   94 +-
 .../v4l2_codec2/components/VideoFrame.h       |    4 +
 .../v4l2_codec2/components/h264/H264Decoder.h |  232 ++
 .../components/h264/V4L2H264Decoder.h         |  115 +
 .../components/h264/parser/H264DPB.h          |  117 +
 .../components/h264/parser/H264NalUnit.h      |  102 +
 .../components/h264/parser/H264PPS.h          |   92 +
 .../components/h264/parser/H264Parser.h       |  154 ++
 .../components/h264/parser/H264Picture.h      |  107 +
 .../components/h264/parser/H264SEIMessage.h   |  194 ++
 .../components/h264/parser/H264SPS.h          |  218 ++
 .../components/h264/parser/H264Slice.h        |  196 ++
 .../components/h264/parser/NalReader.h        |  175 ++
 .../components/vp8/V4L2VP8Decoder.h           |   87 +
 .../v4l2_codec2/components/vp8/VP8Decoder.h   |  140 ++
 .../components/vp8/parser/ByteReader.h        |   49 +
 .../components/vp8/parser/VP8BoolDecoder.h    |   84 +
 .../components/vp8/parser/VP8Parser.h         |  724 +++++++
 .../components/vp8/parser/VP8Picture.h        |   46 +
 .../components/vp8/parser/VP8RangeDecoder.h   |   54 +
 components/vp8/V4L2VP8Decoder.cpp             |  309 +++
 components/vp8/VP8Decoder.cpp                 |  275 +++
 components/vp8/parser/ByteReader.cpp          |  134 ++
 components/vp8/parser/VP8BoolDecoder.cpp      |  135 ++
 components/vp8/parser/VP8Parser.cpp           |  455 ++++
 components/vp8/parser/VP8RangeDecoder.cpp     |   68 +
 plugin_store/Android.bp                       |    2 +-
 45 files changed, 11011 insertions(+), 366 deletions(-)
 create mode 100644 common/MediaDevice.cpp
 create mode 100644 common/include/v4l2_codec2/common/MediaDevice.h
 create mode 100644 components/LICENSE
 create mode 100644 components/V4L2Device.cpp
 create mode 100644 components/h264/H264Decoder.cpp
 create mode 100644 components/h264/V4L2H264Decoder.cpp
 create mode 100644 components/h264/parser/H264DPB.cpp
 create mode 100644 components/h264/parser/H264Parser.cpp
 create mode 100644 components/h264/parser/NalReader.cpp
 create mode 100644 components/include/v4l2_codec2/components/h264/H264Decoder.h
 create mode 100644 components/include/v4l2_codec2/components/h264/V4L2H264Decoder.h
 create mode 100644 components/include/v4l2_codec2/components/h264/parser/H264DPB.h
 create mode 100644 components/include/v4l2_codec2/components/h264/parser/H264NalUnit.h
 create mode 100644 components/include/v4l2_codec2/components/h264/parser/H264PPS.h
 create mode 100644 components/include/v4l2_codec2/components/h264/parser/H264Parser.h
 create mode 100644 components/include/v4l2_codec2/components/h264/parser/H264Picture.h
 create mode 100644 components/include/v4l2_codec2/components/h264/parser/H264SEIMessage.h
 create mode 100644 components/include/v4l2_codec2/components/h264/parser/H264SPS.h
 create mode 100644 components/include/v4l2_codec2/components/h264/parser/H264Slice.h
 create mode 100644 components/include/v4l2_codec2/components/h264/parser/NalReader.h
 create mode 100644 components/include/v4l2_codec2/components/vp8/V4L2VP8Decoder.h
 create mode 100644 components/include/v4l2_codec2/components/vp8/VP8Decoder.h
 create mode 100644 components/include/v4l2_codec2/components/vp8/parser/ByteReader.h
 create mode 100644 components/include/v4l2_codec2/components/vp8/parser/VP8BoolDecoder.h
 create mode 100644 components/include/v4l2_codec2/components/vp8/parser/VP8Parser.h
 create mode 100644 components/include/v4l2_codec2/components/vp8/parser/VP8Picture.h
 create mode 100644 components/include/v4l2_codec2/components/vp8/parser/VP8RangeDecoder.h
 create mode 100644 components/vp8/V4L2VP8Decoder.cpp
 create mode 100644 components/vp8/VP8Decoder.cpp
 create mode 100644 components/vp8/parser/ByteReader.cpp
 create mode 100644 components/vp8/parser/VP8BoolDecoder.cpp
 create mode 100644 components/vp8/parser/VP8Parser.cpp
 create mode 100644 components/vp8/parser/VP8RangeDecoder.cpp

diff --git a/common/Android.bp b/common/Android.bp
index e9c5fe3..d96ced0 100644
--- a/common/Android.bp
+++ b/common/Android.bp
@@ -20,6 +20,7 @@ cc_library {
         "EncodeHelpers.cpp",
         "FormatConverter.cpp",
         "Fourcc.cpp",
+        "MediaDevice.cpp",
         "NalParser.cpp",
         "V4L2ComponentCommon.cpp",
         "VideoTypes.cpp",
diff --git a/common/MediaDevice.cpp b/common/MediaDevice.cpp
new file mode 100644
index 0000000..986c457
--- /dev/null
+++ b/common/MediaDevice.cpp
@@ -0,0 +1,170 @@
+/*
+ * Copyright 2023, The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "MediaDevice"
+
+#include <v4l2_codec2/common/MediaDevice.h>
+
+#include <linux/media.h>
+
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <fcntl.h>
+
+#include <cutils/properties.h>
+#include <log/log.h>
+
+namespace android {
+
+// static
+scoped_refptr<MediaRequest> MediaRequest::create(scoped_refptr<MediaDevice> dev,
+                                                 base::ScopedFD fd) {
+    ALOGV("%s()", __func__);
+
+    return new MediaRequest(std::move(dev), std::move(fd));
+}
+
+MediaRequest::MediaRequest(scoped_refptr<MediaDevice> dev, base::ScopedFD fd)
+    : mDevice(dev),
+      mFd(std::move(fd)),
+      mPending(false),
+      mFailed(false)
+{ }
+
+MediaRequest::~MediaRequest() {
+    if (reinit())
+        mDevice->returnRequest(std::move(mFd));
+}
+
+int MediaRequest::ioctl(int request, void* arg) {
+    ALOG_ASSERT(mFd.is_valid());
+    return HANDLE_EINTR(::ioctl(mFd.get(), request, arg));
+}
+
+bool MediaRequest::queue() {
+    int ret = ioctl(MEDIA_REQUEST_IOC_QUEUE, nullptr);
+    if (ret) {
+        ALOGE("MEDIA_REQUEST_IOC_QUEUE failed");
+        return false;
+    }
+
+    mPending = true;
+
+    return true;
+}
+
+bool MediaRequest::reinit() {
+    ALOGV("%s()", __func__);
+
+    int ret = ioctl(MEDIA_REQUEST_IOC_REINIT, nullptr);
+    if (ret) {
+        ALOGE("MEDIA_REQUEST_IOC_REINIT failed");
+        return false;
+    }
+
+    mPending = false;
+    mFailed = false;
+
+    return true;
+}
+
+// static
+scoped_refptr<MediaDevice> MediaDevice::create() {
+    ALOGV("%s()", __func__);
+    return scoped_refptr<MediaDevice>(new MediaDevice());
+}
+
+MediaDevice::MediaDevice()
+{ }
+
+MediaDevice::~MediaDevice() {
+    ALOGV("%s()", __func__);
+    closeDevice();
+}
+
+bool MediaDevice::open() {
+    ALOGV("%s()", __func__);
+
+    char path[PROPERTY_VALUE_MAX] = {0};
+    int res = property_get("ro.vendor.v4l2_codec2.decode.media", path, "");
+    if (res == 0) {
+        ALOGE("media device property not set for decoder !");
+        return false;
+    }
+
+    if (!openDevicePath(path)) {
+        ALOGE("Failed opening %s", path);
+        return false;
+    }
+
+    return true;
+}
+
+void MediaDevice::closeDevice() {
+    ALOGV("%s()", __func__);
+
+    mDeviceFd.reset();
+}
+
+bool MediaDevice::openDevicePath(const std::string& path) {
+    ALOGV("%s(): path = %s", __func__, path.c_str());
+
+    ALOG_ASSERT(!mDeviceFd.is_valid());
+
+    mDeviceFd.reset(HANDLE_EINTR(::open(path.c_str(), O_RDWR | O_NONBLOCK | O_CLOEXEC)));
+    if (!mDeviceFd.is_valid()) return false;
+
+    return true;
+}
+
+int MediaDevice::ioctl(int request, void* arg) {
+    ALOG_ASSERT(mDeviceFd.is_valid());
+    return HANDLE_EINTR(::ioctl(mDeviceFd.get(), request, arg));
+}
+
+scoped_refptr<MediaRequest> MediaDevice::allocRequest() {
+    base::ScopedFD sfd;
+    if (!mRequestPool.empty()) {
+        ALOGV("%s() using pool", __func__);
+
+        sfd = std::move(mRequestPool.front());
+        mRequestPool.pop();
+    } else {
+        ALOGV("%s() allocating new request", __func__);
+
+        int fd;
+        int ret = ioctl(MEDIA_IOC_REQUEST_ALLOC, &fd);
+        if (ret) {
+            ALOGE("MEDIA_IOC_REQUEST_ALLOC failed");
+            return nullptr;
+        }
+        sfd.reset(fd);
+    }
+
+    return MediaRequest::create(this, std::move(sfd));
+}
+
+void MediaDevice::returnRequest(base::ScopedFD fd) {
+    ALOGV("%s()", __func__);
+
+    if (fd.is_valid())
+        mRequestPool.push(std::move(fd));
+    else
+        ALOGV("%s(): fd not valid !", __func__);
+}
+
+} // android
diff --git a/common/V4L2Device.cpp b/common/V4L2Device.cpp
index 68a9dca..cd7d45c 100644
--- a/common/V4L2Device.cpp
+++ b/common/V4L2Device.cpp
@@ -30,6 +30,7 @@
 #include <base/posix/eintr_wrapper.h>
 #include <base/strings/stringprintf.h>
 #include <base/thread_annotations.h>
+#include <cutils/properties.h>
 #include <utils/Log.h>
 
 #include <v4l2_codec2/common/Fourcc.h>
@@ -70,6 +71,14 @@ struct v4l2_format buildV4L2Format(const enum v4l2_buf_type type, uint32_t fourc
     return format;
 }
 
+V4L2ExtCtrl::V4L2ExtCtrl(const struct v4l2_ext_control &control) {
+    ctrl = control;
+}
+
+V4L2ExtCtrl::V4L2ExtCtrl(const struct v4l2_ext_control &&control) {
+    ctrl = std::move(control);
+}
+
 V4L2ExtCtrl::V4L2ExtCtrl(uint32_t id) {
     memset(&ctrl, 0, sizeof(ctrl));
     ctrl.id = id;
@@ -143,7 +152,6 @@ V4L2Buffer::V4L2Buffer(scoped_refptr<V4L2Device> device, enum v4l2_buf_type type
     mV4l2Buffer.index = bufferId;
     mV4l2Buffer.type = type;
     mV4l2Buffer.memory = memory;
-    mV4l2Buffer.memory = V4L2_MEMORY_DMABUF;
     mPlaneMappings.resize(mV4l2Buffer.length);
 }
 
@@ -590,6 +598,20 @@ void V4L2WritableBufferRef::setPlaneDataOffset(const size_t plane, const size_t
     mBufferData->mV4l2Buffer.m.planes[plane].data_offset = dataOffset;
 }
 
+void V4L2WritableBufferRef::addFlag(uint32_t flag) {
+    DCHECK_CALLED_ON_VALID_SEQUENCE(mSequenceChecker);
+    ALOG_ASSERT(mBufferData);
+
+    mBufferData->mV4l2Buffer.flags |= flag;
+}
+
+void V4L2WritableBufferRef::setRequest(scoped_refptr<MediaRequest> request) {
+    DCHECK_CALLED_ON_VALID_SEQUENCE(mSequenceChecker);
+    ALOG_ASSERT(mBufferData);
+
+    mBufferData->mV4l2Buffer.request_fd = request->fd();
+}
+
 size_t V4L2WritableBufferRef::bufferId() const {
     DCHECK_CALLED_ON_VALID_SEQUENCE(mSequenceChecker);
     ALOG_ASSERT(mBufferData);
@@ -1098,7 +1120,10 @@ scoped_refptr<V4L2Device> V4L2Device::create() {
 bool V4L2Device::open(Type type, uint32_t v4l2PixFmt) {
     ALOGV("%s()", __func__);
 
-    std::string path = getDevicePathFor(type, v4l2PixFmt);
+    // std::string path = getDevicePathFor(type, v4l2PixFmt);
+    char pathStr[PROPERTY_VALUE_MAX] = {0};
+    /* int res = */property_get("ro.vendor.v4l2_codec2.decode.device", pathStr, "");
+    std::string path(pathStr);
 
     if (path.empty()) {
         ALOGE("No devices supporting %s for type: %u", fourccToString(v4l2PixFmt).c_str(),
@@ -1908,7 +1933,7 @@ bool V4L2Device::isCtrlExposed(uint32_t ctrlId) {
     return ioctl(VIDIOC_QUERYCTRL, &queryCtrl) == 0;
 }
 
-bool V4L2Device::setExtCtrls(uint32_t ctrlClass, std::vector<V4L2ExtCtrl> ctrls) {
+bool V4L2Device::setExtCtrls(uint32_t ctrlClass, std::vector<V4L2ExtCtrl> ctrls, scoped_refptr<MediaRequest> request) {
     DCHECK_CALLED_ON_VALID_SEQUENCE(mClientSequenceChecker);
 
     if (ctrls.empty()) return true;
@@ -1918,6 +1943,8 @@ bool V4L2Device::setExtCtrls(uint32_t ctrlClass, std::vector<V4L2ExtCtrl> ctrls)
     extCtrls.ctrl_class = ctrlClass;
     extCtrls.count = ctrls.size();
     extCtrls.controls = &ctrls[0].ctrl;
+    extCtrls.request_fd = request ? request->fd() : 0;
+    extCtrls.which = request ? V4L2_CTRL_WHICH_REQUEST_VAL : 0;
     return ioctl(VIDIOC_S_EXT_CTRLS, &extCtrls) == 0;
 }
 
diff --git a/common/include/v4l2_codec2/common/MediaDevice.h b/common/include/v4l2_codec2/common/MediaDevice.h
new file mode 100644
index 0000000..1404aff
--- /dev/null
+++ b/common/include/v4l2_codec2/common/MediaDevice.h
@@ -0,0 +1,94 @@
+/*
+ * Copyright 2023, The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef ANDROID_V4L2_CODEC2_COMMON_MEDIA_DEVICE_H
+#define ANDROID_V4L2_CODEC2_COMMON_MEDIA_DEVICE_H
+
+#include <base/files/scoped_file.h>
+#include <base/memory/ref_counted.h>
+#include <base/posix/eintr_wrapper.h>
+
+#include <queue>
+
+namespace android {
+
+class MediaRequest;
+class MediaDevice : public base::RefCountedThreadSafe<MediaDevice> {
+
+public:
+    ~MediaDevice();
+
+    static scoped_refptr<MediaDevice> create();
+
+    bool open();
+    void closeDevice();
+
+    int ioctl(int request, void* arg);
+
+    scoped_refptr<MediaRequest> allocRequest();
+    void returnRequest(base::ScopedFD fd);
+
+protected:
+    MediaDevice();
+
+private:
+    friend class base::RefCountedThreadSafe<MediaDevice>;
+
+    bool openDevicePath(const std::string& path);
+
+private:
+    // The actual device fd.
+    base::ScopedFD mDeviceFd;
+
+    // The list of unused allocated request fd
+    std::queue<base::ScopedFD> mRequestPool;
+};
+
+class MediaRequest : public base::RefCountedThreadSafe<MediaRequest>{
+public:
+    MediaRequest(MediaRequest &&other) = default;
+    MediaRequest(const MediaRequest &other) = delete;
+    ~MediaRequest();
+
+    static scoped_refptr<MediaRequest> create(scoped_refptr<MediaDevice> dev,
+                                              base::ScopedFD fd);
+
+    int fd() { return mFd.get(); }
+
+    int ioctl(int request, void* arg);
+
+    bool reinit();
+    bool queue();
+
+    void operator=(const MediaRequest &other) = delete;
+
+protected:
+    MediaRequest(scoped_refptr<MediaDevice> dev, base::ScopedFD fd);
+
+private:
+    friend class base::RefCountedThreadSafe<MediaRequest>;
+
+    scoped_refptr<MediaDevice> mDevice;
+
+    base::ScopedFD mFd;
+
+    bool mPending;
+    bool mFailed;
+};
+
+} // android
+
+#endif // ANDROID_V4L2_CODEC2_COMMON_MEDIA_DEVICE_H
diff --git a/common/include/v4l2_codec2/common/V4L2Device.h b/common/include/v4l2_codec2/common/V4L2Device.h
index 77d7ddb..785c38a 100644
--- a/common/include/v4l2_codec2/common/V4L2Device.h
+++ b/common/include/v4l2_codec2/common/V4L2Device.h
@@ -25,6 +25,7 @@
 #include <v4l2_codec2/common/Common.h>
 #include <v4l2_codec2/common/V4L2DevicePoller.h>
 #include <v4l2_codec2/common/VideoTypes.h>
+#include <v4l2_codec2/common/MediaDevice.h>
 
 namespace android {
 
@@ -35,6 +36,8 @@ class V4L2DecodeSurface;
 
 // Wrapper for the 'v4l2_ext_control' structure.
 struct V4L2ExtCtrl {
+    V4L2ExtCtrl(const struct v4l2_ext_control &control);
+    V4L2ExtCtrl(const struct v4l2_ext_control &&control);
     V4L2ExtCtrl(uint32_t id);
     V4L2ExtCtrl(uint32_t id, int32_t val);
     struct v4l2_ext_control ctrl;
@@ -93,6 +96,10 @@ public:
     size_t getPlaneBytesUsed(const size_t plane) const;
     // Set the data offset for |plane|, in bytes.
     void setPlaneDataOffset(const size_t plane, const size_t dataOffset);
+    // Add a flag to this buffer flags field.
+    void addFlag(uint32_t flag);
+    // Set the request_fd field for this buffer.
+    void setRequest(scoped_refptr<MediaRequest> request);
 
     // Return the V4L2 buffer ID of the underlying buffer.
     size_t bufferId() const;
@@ -452,7 +459,7 @@ public:
     bool isCtrlExposed(uint32_t ctrlId);
     // Set the specified list of |ctrls| for the specified |ctrlClass|, returns whether the
     // operation succeeded.
-    bool setExtCtrls(uint32_t ctrlClass, std::vector<V4L2ExtCtrl> ctrls);
+    bool setExtCtrls(uint32_t ctrlClass, std::vector<V4L2ExtCtrl> ctrls, scoped_refptr<MediaRequest> request = nullptr);
 
     // Check whether the V4L2 command with specified |commandId| is supported.
     bool isCommandSupported(uint32_t commandId);
diff --git a/components/Android.bp b/components/Android.bp
index 5bee73b..6732c32 100644
--- a/components/Android.bp
+++ b/components/Android.bp
@@ -1,10 +1,24 @@
+license {
+    name: "external_v4l2_codec2_component_license",
+    visibility: [":__subpackages__"],
+    license_kinds: [
+        "SPDX-license-identifier-BSD",
+        "SPDX-license-identifier-LGPL-2.1",
+        "legacy_unencumbered",
+    ],
+    license_text: [
+        "LICENSE",
+    ],
+}
+
 package {
     // See: http://go/android-license-faq
     // A large-scale-change added 'default_applicable_licenses' to import
     // all of the 'license_kinds' from "external_v4l2_codec2_license"
     // to get the below license kinds:
     //   SPDX-license-identifier-BSD
-    default_applicable_licenses: ["external_v4l2_codec2_license"],
+    //   SPDX-license-identifier-LGPL
+    default_applicable_licenses: ["external_v4l2_codec2_component_license"],
 }
 
 cc_library {
@@ -28,6 +42,21 @@ cc_library {
         "V4L2EncodeInterface.cpp",
         "VideoDecoder.cpp",
         "VideoEncoder.cpp",
+
+        // H264
+        "h264/H264Decoder.cpp",
+        "h264/V4L2H264Decoder.cpp",
+        "h264/parser/H264Parser.cpp",
+        "h264/parser/H264DPB.cpp",
+        "h264/parser/NalReader.cpp",
+
+        // VP8
+        "vp8/VP8Decoder.cpp",
+        "vp8/V4L2VP8Decoder.cpp",
+        "vp8/parser/ByteReader.cpp",
+        "vp8/parser/VP8BoolDecoder.cpp",
+        "vp8/parser/VP8RangeDecoder.cpp",
+        "vp8/parser/VP8Parser.cpp",
     ],
     export_include_dirs: [
         "include",
diff --git a/components/LICENSE b/components/LICENSE
new file mode 100644
index 0000000..86cd459
--- /dev/null
+++ b/components/LICENSE
@@ -0,0 +1,504 @@
+GNU LESSER GENERAL PUBLIC LICENSE
+                       Version 2.1, February 1999
+
+ Copyright (C) 1991, 1999 Free Software Foundation, Inc.
+ 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
+ Everyone is permitted to copy and distribute verbatim copies
+ of this license document, but changing it is not allowed.
+
+(This is the first released version of the Lesser GPL.  It also counts
+ as the successor of the GNU Library Public License, version 2, hence
+ the version number 2.1.)
+
+                            Preamble
+
+  The licenses for most software are designed to take away your
+freedom to share and change it.  By contrast, the GNU General Public
+Licenses are intended to guarantee your freedom to share and change
+free software--to make sure the software is free for all its users.
+
+  This license, the Lesser General Public License, applies to some
+specially designated software packages--typically libraries--of the
+Free Software Foundation and other authors who decide to use it.  You
+can use it too, but we suggest you first think carefully about whether
+this license or the ordinary General Public License is the better
+strategy to use in any particular case, based on the explanations below.
+
+  When we speak of free software, we are referring to freedom of use,
+not price.  Our General Public Licenses are designed to make sure that
+you have the freedom to distribute copies of free software (and charge
+for this service if you wish); that you receive source code or can get
+it if you want it; that you can change the software and use pieces of
+it in new free programs; and that you are informed that you can do
+these things.
+
+  To protect your rights, we need to make restrictions that forbid
+distributors to deny you these rights or to ask you to surrender these
+rights.  These restrictions translate to certain responsibilities for
+you if you distribute copies of the library or if you modify it.
+
+  For example, if you distribute copies of the library, whether gratis
+or for a fee, you must give the recipients all the rights that we gave
+you.  You must make sure that they, too, receive or can get the source
+code.  If you link other code with the library, you must provide
+complete object files to the recipients, so that they can relink them
+with the library after making changes to the library and recompiling
+it.  And you must show them these terms so they know their rights.
+
+  We protect your rights with a two-step method: (1) we copyright the
+library, and (2) we offer you this license, which gives you legal
+permission to copy, distribute and/or modify the library.
+
+  To protect each distributor, we want to make it very clear that
+there is no warranty for the free library.  Also, if the library is
+modified by someone else and passed on, the recipients should know
+that what they have is not the original version, so that the original
+author's reputation will not be affected by problems that might be
+introduced by others.
+
+  Finally, software patents pose a constant threat to the existence of
+any free program.  We wish to make sure that a company cannot
+effectively restrict the users of a free program by obtaining a
+restrictive license from a patent holder.  Therefore, we insist that
+any patent license obtained for a version of the library must be
+consistent with the full freedom of use specified in this license.
+
+  Most GNU software, including some libraries, is covered by the
+ordinary GNU General Public License.  This license, the GNU Lesser
+General Public License, applies to certain designated libraries, and
+is quite different from the ordinary General Public License.  We use
+this license for certain libraries in order to permit linking those
+libraries into non-free programs.
+
+  When a program is linked with a library, whether statically or using
+a shared library, the combination of the two is legally speaking a
+combined work, a derivative of the original library.  The ordinary
+General Public License therefore permits such linking only if the
+entire combination fits its criteria of freedom.  The Lesser General
+Public License permits more lax criteria for linking other code with
+the library.
+
+  We call this license the "Lesser" General Public License because it
+does Less to protect the user's freedom than the ordinary General
+Public License.  It also provides other free software developers Less
+of an advantage over competing non-free programs.  These disadvantages
+are the reason we use the ordinary General Public License for many
+libraries.  However, the Lesser license provides advantages in certain
+special circumstances.
+
+  For example, on rare occasions, there may be a special need to
+encourage the widest possible use of a certain library, so that it becomes
+a de-facto standard.  To achieve this, non-free programs must be
+allowed to use the library.  A more frequent case is that a free
+library does the same job as widely used non-free libraries.  In this
+case, there is little to gain by limiting the free library to free
+software only, so we use the Lesser General Public License.
+
+  In other cases, permission to use a particular library in non-free
+programs enables a greater number of people to use a large body of
+free software.  For example, permission to use the GNU C Library in
+non-free programs enables many more people to use the whole GNU
+operating system, as well as its variant, the GNU/Linux operating
+system.
+
+  Although the Lesser General Public License is Less protective of the
+users' freedom, it does ensure that the user of a program that is
+linked with the Library has the freedom and the wherewithal to run
+that program using a modified version of the Library.
+
+  The precise terms and conditions for copying, distribution and
+modification follow.  Pay close attention to the difference between a
+"work based on the library" and a "work that uses the library".  The
+former contains code derived from the library, whereas the latter must
+be combined with the library in order to run.
+
+                  GNU LESSER GENERAL PUBLIC LICENSE
+   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION
+
+  0. This License Agreement applies to any software library or other
+program which contains a notice placed by the copyright holder or
+other authorized party saying it may be distributed under the terms of
+this Lesser General Public License (also called "this License").
+Each licensee is addressed as "you".
+
+  A "library" means a collection of software functions and/or data
+prepared so as to be conveniently linked with application programs
+(which use some of those functions and data) to form executables.
+
+  The "Library", below, refers to any such software library or work
+which has been distributed under these terms.  A "work based on the
+Library" means either the Library or any derivative work under
+copyright law: that is to say, a work containing the Library or a
+portion of it, either verbatim or with modifications and/or translated
+straightforwardly into another language.  (Hereinafter, translation is
+included without limitation in the term "modification".)
+
+  "Source code" for a work means the preferred form of the work for
+making modifications to it.  For a library, complete source code means
+all the source code for all modules it contains, plus any associated
+interface definition files, plus the scripts used to control compilation
+and installation of the library.
+
+  Activities other than copying, distribution and modification are not
+covered by this License; they are outside its scope.  The act of
+running a program using the Library is not restricted, and output from
+such a program is covered only if its contents constitute a work based
+on the Library (independent of the use of the Library in a tool for
+writing it).  Whether that is true depends on what the Library does
+and what the program that uses the Library does.
+
+  1. You may copy and distribute verbatim copies of the Library's
+complete source code as you receive it, in any medium, provided that
+you conspicuously and appropriately publish on each copy an
+appropriate copyright notice and disclaimer of warranty; keep intact
+all the notices that refer to this License and to the absence of any
+warranty; and distribute a copy of this License along with the
+Library.
+
+  You may charge a fee for the physical act of transferring a copy,
+and you may at your option offer warranty protection in exchange for a
+fee.
+
+  2. You may modify your copy or copies of the Library or any portion
+of it, thus forming a work based on the Library, and copy and
+distribute such modifications or work under the terms of Section 1
+above, provided that you also meet all of these conditions:
+
+    a) The modified work must itself be a software library.
+
+    b) You must cause the files modified to carry prominent notices
+    stating that you changed the files and the date of any change.
+
+    c) You must cause the whole of the work to be licensed at no
+    charge to all third parties under the terms of this License.
+
+    d) If a facility in the modified Library refers to a function or a
+    table of data to be supplied by an application program that uses
+    the facility, other than as an argument passed when the facility
+    is invoked, then you must make a good faith effort to ensure that,
+    in the event an application does not supply such function or
+    table, the facility still operates, and performs whatever part of
+    its purpose remains meaningful.
+
+    (For example, a function in a library to compute square roots has
+    a purpose that is entirely well-defined independent of the
+    application.  Therefore, Subsection 2d requires that any
+    application-supplied function or table used by this function must
+    be optional: if the application does not supply it, the square
+    root function must still compute square roots.)
+
+These requirements apply to the modified work as a whole.  If
+identifiable sections of that work are not derived from the Library,
+and can be reasonably considered independent and separate works in
+themselves, then this License, and its terms, do not apply to those
+sections when you distribute them as separate works.  But when you
+distribute the same sections as part of a whole which is a work based
+on the Library, the distribution of the whole must be on the terms of
+this License, whose permissions for other licensees extend to the
+entire whole, and thus to each and every part regardless of who wrote
+it.
+
+Thus, it is not the intent of this section to claim rights or contest
+your rights to work written entirely by you; rather, the intent is to
+exercise the right to control the distribution of derivative or
+collective works based on the Library.
+
+In addition, mere aggregation of another work not based on the Library
+with the Library (or with a work based on the Library) on a volume of
+a storage or distribution medium does not bring the other work under
+the scope of this License.
+
+  3. You may opt to apply the terms of the ordinary GNU General Public
+License instead of this License to a given copy of the Library.  To do
+this, you must alter all the notices that refer to this License, so
+that they refer to the ordinary GNU General Public License, version 2,
+instead of to this License.  (If a newer version than version 2 of the
+ordinary GNU General Public License has appeared, then you can specify
+that version instead if you wish.)  Do not make any other change in
+these notices.
+
+  Once this change is made in a given copy, it is irreversible for
+that copy, so the ordinary GNU General Public License applies to all
+subsequent copies and derivative works made from that copy.
+
+  This option is useful when you wish to copy part of the code of
+the Library into a program that is not a library.
+
+  4. You may copy and distribute the Library (or a portion or
+derivative of it, under Section 2) in object code or executable form
+under the terms of Sections 1 and 2 above provided that you accompany
+it with the complete corresponding machine-readable source code, which
+must be distributed under the terms of Sections 1 and 2 above on a
+medium customarily used for software interchange.
+
+  If distribution of object code is made by offering access to copy
+from a designated place, then offering equivalent access to copy the
+source code from the same place satisfies the requirement to
+distribute the source code, even though third parties are not
+compelled to copy the source along with the object code.
+
+  5. A program that contains no derivative of any portion of the
+Library, but is designed to work with the Library by being compiled or
+linked with it, is called a "work that uses the Library".  Such a
+work, in isolation, is not a derivative work of the Library, and
+therefore falls outside the scope of this License.
+
+  However, linking a "work that uses the Library" with the Library
+creates an executable that is a derivative of the Library (because it
+contains portions of the Library), rather than a "work that uses the
+library".  The executable is therefore covered by this License.
+Section 6 states terms for distribution of such executables.
+
+  When a "work that uses the Library" uses material from a header file
+that is part of the Library, the object code for the work may be a
+derivative work of the Library even though the source code is not.
+Whether this is true is especially significant if the work can be
+linked without the Library, or if the work is itself a library.  The
+threshold for this to be true is not precisely defined by law.
+
+  If such an object file uses only numerical parameters, data
+structure layouts and accessors, and small macros and small inline
+functions (ten lines or less in length), then the use of the object
+file is unrestricted, regardless of whether it is legally a derivative
+work.  (Executables containing this object code plus portions of the
+Library will still fall under Section 6.)
+
+  Otherwise, if the work is a derivative of the Library, you may
+distribute the object code for the work under the terms of Section 6.
+Any executables containing that work also fall under Section 6,
+whether or not they are linked directly with the Library itself.
+
+  6. As an exception to the Sections above, you may also combine or
+link a "work that uses the Library" with the Library to produce a
+work containing portions of the Library, and distribute that work
+under terms of your choice, provided that the terms permit
+modification of the work for the customer's own use and reverse
+engineering for debugging such modifications.
+
+  You must give prominent notice with each copy of the work that the
+Library is used in it and that the Library and its use are covered by
+this License.  You must supply a copy of this License.  If the work
+during execution displays copyright notices, you must include the
+copyright notice for the Library among them, as well as a reference
+directing the user to the copy of this License.  Also, you must do one
+of these things:
+
+    a) Accompany the work with the complete corresponding
+    machine-readable source code for the Library including whatever
+    changes were used in the work (which must be distributed under
+    Sections 1 and 2 above); and, if the work is an executable linked
+    with the Library, with the complete machine-readable "work that
+    uses the Library", as object code and/or source code, so that the
+    user can modify the Library and then relink to produce a modified
+    executable containing the modified Library.  (It is understood
+    that the user who changes the contents of definitions files in the
+    Library will not necessarily be able to recompile the application
+    to use the modified definitions.)
+
+    b) Use a suitable shared library mechanism for linking with the
+    Library.  A suitable mechanism is one that (1) uses at run time a
+    copy of the library already present on the user's computer system,
+    rather than copying library functions into the executable, and (2)
+    will operate properly with a modified version of the library, if
+    the user installs one, as long as the modified version is
+    interface-compatible with the version that the work was made with.
+
+    c) Accompany the work with a written offer, valid for at
+    least three years, to give the same user the materials
+    specified in Subsection 6a, above, for a charge no more
+    than the cost of performing this distribution.
+
+    d) If distribution of the work is made by offering access to copy
+    from a designated place, offer equivalent access to copy the above
+    specified materials from the same place.
+
+    e) Verify that the user has already received a copy of these
+    materials or that you have already sent this user a copy.
+
+  For an executable, the required form of the "work that uses the
+Library" must include any data and utility programs needed for
+reproducing the executable from it.  However, as a special exception,
+the materials to be distributed need not include anything that is
+normally distributed (in either source or binary form) with the major
+components (compiler, kernel, and so on) of the operating system on
+which the executable runs, unless that component itself accompanies
+the executable.
+
+  It may happen that this requirement contradicts the license
+restrictions of other proprietary libraries that do not normally
+accompany the operating system.  Such a contradiction means you cannot
+use both them and the Library together in an executable that you
+distribute.
+
+  7. You may place library facilities that are a work based on the
+Library side-by-side in a single library together with other library
+facilities not covered by this License, and distribute such a combined
+library, provided that the separate distribution of the work based on
+the Library and of the other library facilities is otherwise
+permitted, and provided that you do these two things:
+
+    a) Accompany the combined library with a copy of the same work
+    based on the Library, uncombined with any other library
+    facilities.  This must be distributed under the terms of the
+    Sections above.
+
+    b) Give prominent notice with the combined library of the fact
+    that part of it is a work based on the Library, and explaining
+    where to find the accompanying uncombined form of the same work.
+
+  8. You may not copy, modify, sublicense, link with, or distribute
+the Library except as expressly provided under this License.  Any
+attempt otherwise to copy, modify, sublicense, link with, or
+distribute the Library is void, and will automatically terminate your
+rights under this License.  However, parties who have received copies,
+or rights, from you under this License will not have their licenses
+terminated so long as such parties remain in full compliance.
+
+  9. You are not required to accept this License, since you have not
+signed it.  However, nothing else grants you permission to modify or
+distribute the Library or its derivative works.  These actions are
+prohibited by law if you do not accept this License.  Therefore, by
+modifying or distributing the Library (or any work based on the
+Library), you indicate your acceptance of this License to do so, and
+all its terms and conditions for copying, distributing or modifying
+the Library or works based on it.
+
+  10. Each time you redistribute the Library (or any work based on the
+Library), the recipient automatically receives a license from the
+original licensor to copy, distribute, link with or modify the Library
+subject to these terms and conditions.  You may not impose any further
+restrictions on the recipients' exercise of the rights granted herein.
+You are not responsible for enforcing compliance by third parties with
+this License.
+
+  11. If, as a consequence of a court judgment or allegation of patent
+infringement or for any other reason (not limited to patent issues),
+conditions are imposed on you (whether by court order, agreement or
+otherwise) that contradict the conditions of this License, they do not
+excuse you from the conditions of this License.  If you cannot
+distribute so as to satisfy simultaneously your obligations under this
+License and any other pertinent obligations, then as a consequence you
+may not distribute the Library at all.  For example, if a patent
+license would not permit royalty-free redistribution of the Library by
+all those who receive copies directly or indirectly through you, then
+the only way you could satisfy both it and this License would be to
+refrain entirely from distribution of the Library.
+
+If any portion of this section is held invalid or unenforceable under any
+particular circumstance, the balance of the section is intended to apply,
+and the section as a whole is intended to apply in other circumstances.
+
+It is not the purpose of this section to induce you to infringe any
+patents or other property right claims or to contest validity of any
+such claims; this section has the sole purpose of protecting the
+integrity of the free software distribution system which is
+implemented by public license practices.  Many people have made
+generous contributions to the wide range of software distributed
+through that system in reliance on consistent application of that
+system; it is up to the author/donor to decide if he or she is willing
+to distribute software through any other system and a licensee cannot
+impose that choice.
+
+This section is intended to make thoroughly clear what is believed to
+be a consequence of the rest of this License.
+
+  12. If the distribution and/or use of the Library is restricted in
+certain countries either by patents or by copyrighted interfaces, the
+original copyright holder who places the Library under this License may add
+an explicit geographical distribution limitation excluding those countries,
+so that distribution is permitted only in or among countries not thus
+excluded.  In such case, this License incorporates the limitation as if
+written in the body of this License.
+
+  13. The Free Software Foundation may publish revised and/or new
+versions of the Lesser General Public License from time to time.
+Such new versions will be similar in spirit to the present version,
+but may differ in detail to address new problems or concerns.
+
+Each version is given a distinguishing version number.  If the Library
+specifies a version number of this License which applies to it and
+"any later version", you have the option of following the terms and
+conditions either of that version or of any later version published by
+the Free Software Foundation.  If the Library does not specify a
+license version number, you may choose any version ever published by
+the Free Software Foundation.
+
+  14. If you wish to incorporate parts of the Library into other free
+programs whose distribution conditions are incompatible with these,
+write to the author to ask for permission.  For software which is
+copyrighted by the Free Software Foundation, write to the Free
+Software Foundation; we sometimes make exceptions for this.  Our
+decision will be guided by the two goals of preserving the free status
+of all derivatives of our free software and of promoting the sharing
+and reuse of software generally.
+
+                            NO WARRANTY
+
+  15. BECAUSE THE LIBRARY IS LICENSED FREE OF CHARGE, THERE IS NO
+WARRANTY FOR THE LIBRARY, TO THE EXTENT PERMITTED BY APPLICABLE LAW.
+EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR
+OTHER PARTIES PROVIDE THE LIBRARY "AS IS" WITHOUT WARRANTY OF ANY
+KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE
+LIBRARY IS WITH YOU.  SHOULD THE LIBRARY PROVE DEFECTIVE, YOU ASSUME
+THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.
+
+  16. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN
+WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY
+AND/OR REDISTRIBUTE THE LIBRARY AS PERMITTED ABOVE, BE LIABLE TO YOU
+FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR
+CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE
+LIBRARY (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING
+RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A
+FAILURE OF THE LIBRARY TO OPERATE WITH ANY OTHER SOFTWARE), EVEN IF
+SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH
+DAMAGES.
+
+                     END OF TERMS AND CONDITIONS
+
+           How to Apply These Terms to Your New Libraries
+
+  If you develop a new library, and you want it to be of the greatest
+possible use to the public, we recommend making it free software that
+everyone can redistribute and change.  You can do so by permitting
+redistribution under these terms (or, alternatively, under the terms of the
+ordinary General Public License).
+
+  To apply these terms, attach the following notices to the library.  It is
+safest to attach them to the start of each source file to most effectively
+convey the exclusion of warranty; and each file should have at least the
+"copyright" line and a pointer to where the full notice is found.
+
+    {description}
+    Copyright (C) {year} {fullname}
+
+    This library is free software; you can redistribute it and/or
+    modify it under the terms of the GNU Lesser General Public
+    License as published by the Free Software Foundation; either
+    version 2.1 of the License, or (at your option) any later version.
+
+    This library is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+    Lesser General Public License for more details.
+
+    You should have received a copy of the GNU Lesser General Public
+    License along with this library; if not, write to the Free Software
+    Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301
+    USA
+
+Also add information on how to contact you by electronic and paper mail.
+
+You should also get your employer (if you work as a programmer) or your
+school, if any, to sign a "copyright disclaimer" for the library, if
+necessary.  Here is a sample; alter the names:
+
+  Yoyodyne, Inc., hereby disclaims all copyright interest in the
+  library `Frob' (a library for tweaking knobs) written by James Random
+  Hacker.
+
+  {signature of Ty Coon}, 1 April 1990
+  Ty Coon, President of Vice
+
+That's all there is to it!
\ No newline at end of file
diff --git a/components/V4L2DecodeComponent.cpp b/components/V4L2DecodeComponent.cpp
index 456f3c4..612b206 100644
--- a/components/V4L2DecodeComponent.cpp
+++ b/components/V4L2DecodeComponent.cpp
@@ -32,6 +32,10 @@
 #include <v4l2_codec2/components/VideoFramePool.h>
 #include <v4l2_codec2/plugin_store/C2VdaBqBlockPool.h>
 
+#include <v4l2_codec2/components/h264/V4L2H264Decoder.h>
+#include <v4l2_codec2/components/vp8/V4L2VP8Decoder.h>
+
+
 namespace android {
 namespace {
 
@@ -40,6 +44,7 @@ namespace {
 // input buffers, CCodec may timeout due to waiting for a available output buffer.
 // This function returns the minimum number of output buffers to prevent the buffers from being
 // exhausted before CCBC pauses sending input buffers.
+/*
 size_t getMinNumOutputBuffers(VideoCodec codec) {
     // The constant values copied from CCodecBufferChannel.cpp.
     // (b/184020290): Check the value still sync when seeing error message from CCodec:
@@ -56,6 +61,7 @@ size_t getMinNumOutputBuffers(VideoCodec codec) {
     return V4L2DecodeInterface::getOutputDelay(codec) + kSmoothnessFactor + kRenderingDepth +
            kExtraNumOutputBuffersForDecoder;
 }
+*/
 
 // Mask against 30 bits to avoid (undefined) wraparound on signed integer.
 int32_t frameIndexToBitstreamId(c2_cntr64_t frameIndex) {
@@ -228,26 +234,49 @@ void V4L2DecodeComponent::startTask(c2_status_t* status, ::base::WaitableEvent*
         return;
     }
     const size_t inputBufferSize = mIntfImpl->getInputBufferSize();
-    const size_t minNumOutputBuffers = getMinNumOutputBuffers(*codec);
-
-    // ::base::Unretained(this) is safe here because |mDecoder| is always destroyed before
-    // |mDecoderThread| is stopped, so |*this| is always valid during |mDecoder|'s lifetime.
-    mDecoder = V4L2Decoder::Create(*codec, inputBufferSize, minNumOutputBuffers,
-                                   ::base::BindRepeating(&V4L2DecodeComponent::getVideoFramePool,
-                                                         ::base::Unretained(this)),
-                                   ::base::BindRepeating(&V4L2DecodeComponent::onOutputFrameReady,
-                                                         ::base::Unretained(this)),
-                                   ::base::BindRepeating(&V4L2DecodeComponent::reportError,
-                                                         ::base::Unretained(this), C2_CORRUPTED),
-                                   mDecoderTaskRunner);
+    // const size_t minNumOutputBuffers = getMinNumOutputBuffers(*codec);
+
+    switch (*codec) {
+        case VideoCodec::H264:
+            // ::base::Unretained(this) is safe here because |mDecoder| is always destroyed before
+            // |mDecoderThread| is stopped, so |*this| is always valid during |mDecoder|'s lifetime.
+            mDecoder = V4L2H264Decoder::Create(inputBufferSize,
+                    ::base::BindRepeating(&V4L2DecodeComponent::getVideoFramePool,
+                        ::base::Unretained(this)),
+                    ::base::BindRepeating(&V4L2DecodeComponent::onOutputFrameReady,
+                        ::base::Unretained(this)),
+                    ::base::BindRepeating(&V4L2DecodeComponent::reportError,
+                        ::base::Unretained(this), C2_CORRUPTED),
+                    mDecoderTaskRunner);
+
+            break;
+        case VideoCodec::VP8:
+            // ::base::Unretained(this) is safe here because |mDecoder| is always destroyed before
+            // |mDecoderThread| is stopped, so |*this| is always valid during |mDecoder|'s lifetime.
+            mDecoder = V4L2VP8Decoder::Create(inputBufferSize,
+                    ::base::BindRepeating(&V4L2DecodeComponent::getVideoFramePool,
+                        ::base::Unretained(this)),
+                    ::base::BindRepeating(&V4L2DecodeComponent::onOutputFrameReady,
+                        ::base::Unretained(this)),
+                    ::base::BindRepeating(&V4L2DecodeComponent::reportError,
+                        ::base::Unretained(this), C2_CORRUPTED),
+                    mDecoderTaskRunner);
+
+            break;
+        default:
+            ALOGE("Video format not handled");
+            return;
+    }
+
     if (!mDecoder) {
         ALOGE("Failed to create V4L2Decoder for %s", VideoCodecToString(*codec));
         return;
     }
 
     // Get default color aspects on start.
-    if (!mIsSecure && *codec == VideoCodec::H264) {
-        if (mIntfImpl->queryColorAspects(&mCurrentColorAspects) != C2_OK) return;
+    if (!mIsSecure) {
+        if (mIntfImpl->queryColorAspects(&mCurrentColorAspects) != C2_OK)
+            return;
         mPendingColorAspectsChange = false;
     }
 
@@ -280,6 +309,10 @@ std::unique_ptr<VideoFramePool> V4L2DecodeComponent::getVideoFramePool(const ui:
     ALOGI("Using C2BlockPool ID = %" PRIu64 " for allocating output buffers", poolId);
     std::shared_ptr<C2BlockPool> blockPool;
     auto status = GetCodec2BlockPool(poolId, std::move(sharedThis), &blockPool);
+    if (status != C2_OK) {
+        ALOGI("C2BlockPool ID = %" PRIu64 " not found, create a new block pool", poolId);
+        status = CreateCodec2BlockPool(mIntfImpl->getOutputAllocatorId(), nullptr, &blockPool);
+    }
     if (status != C2_OK) {
         ALOGE("Graphic block allocator is invalid: %d", status);
         reportError(status);
@@ -428,8 +461,8 @@ void V4L2DecodeComponent::queueTask(std::unique_ptr<C2Work> work) {
         if ((work->input.flags & C2FrameData::FLAG_END_OF_STREAM) == 0 &&
             (work->input.flags & C2FrameData::FLAG_CODEC_CONFIG) == 0) {
             ALOGE("Invalid work: work with no input buffer should be EOS or CSD.");
-            reportError(C2_BAD_VALUE);
-            return;
+            //reportError(C2_BAD_VALUE);
+            //return;
         }
 
         // Emplace a nullptr to unify the check for work done.
@@ -473,7 +506,7 @@ void V4L2DecodeComponent::pumpPendingWorks() {
             ALOG_ASSERT(linearBlock.size() > 0u, "Input buffer of work(%d) is empty.", bitstreamId);
 
             // Try to parse color aspects from bitstream for CSD work of non-secure H264 codec.
-            if (isCSDWork && !mIsSecure && (mIntfImpl->getVideoCodec() == VideoCodec::H264)) {
+            if (!mIsSecure && (mIntfImpl->getVideoCodec() == VideoCodec::H264)) {
                 C2StreamColorAspectsInfo::input codedAspects = {0u};
                 if (parseCodedColorAspects(linearBlock, &codedAspects)) {
                     std::vector<std::unique_ptr<C2SettingResult>> failures;
@@ -495,6 +528,7 @@ void V4L2DecodeComponent::pumpPendingWorks() {
             std::unique_ptr<ConstBitstreamBuffer> buffer = std::make_unique<ConstBitstreamBuffer>(
                     bitstreamId, linearBlock, linearBlock.offset(), linearBlock.size());
             if (!buffer) {
+                ALOGE("Couldn't get a buffer");
                 reportError(C2_CORRUPTED);
                 return;
             }
@@ -506,9 +540,17 @@ void V4L2DecodeComponent::pumpPendingWorks() {
             mDecoder->drain(::base::BindOnce(&V4L2DecodeComponent::onDrainDone, mWeakThis));
             mIsDraining = true;
         }
+        if (isEmptyWork) {
+            // Directly report the empty CSD work as finished.
+            if (isCSDWork) {
+                reportWorkIfFinished(bitstreamId);
+            }
+            else if (!isEOSWork) {
+                work->worklets.front()->output.flags = C2FrameData::FLAG_DROP_FRAME;
+                onDecodeDone(bitstreamId, VideoDecoder::DecodeStatus::kAborted);
+            }
+        }
 
-        // Directly report the empty CSD work as finished.
-        if (isCSDWork && isEmptyWork) reportWorkIfFinished(bitstreamId);
     }
 }
 
diff --git a/components/V4L2DecodeInterface.cpp b/components/V4L2DecodeInterface.cpp
index 4bc4121..465323b 100644
--- a/components/V4L2DecodeInterface.cpp
+++ b/components/V4L2DecodeInterface.cpp
@@ -239,7 +239,7 @@ V4L2DecodeInterface::V4L2DecodeInterface(const std::string& name,
     const C2Allocator::id_t outputAllocators[] = {V4L2AllocatorId::V4L2_BUFFERPOOL};
     const C2Allocator::id_t surfaceAllocator =
             secureMode ? V4L2AllocatorId::SECURE_GRAPHIC : V4L2AllocatorId::V4L2_BUFFERQUEUE;
-    const C2BlockPool::local_id_t outputBlockPools[] = {C2BlockPool::BASIC_GRAPHIC};
+    const C2BlockPool::local_id_t outputBlockPools[] = { static_cast<C2BlockPool::local_id_t>(-1) };
 
     addParameter(
             DefineParam(mInputAllocatorIds, C2_PARAMKEY_INPUT_ALLOCATORS)
diff --git a/components/V4L2Decoder.cpp b/components/V4L2Decoder.cpp
index aa59e91..47fa8d8 100644
--- a/components/V4L2Decoder.cpp
+++ b/components/V4L2Decoder.cpp
@@ -20,12 +20,14 @@
 #include <v4l2_codec2/common/Common.h>
 #include <v4l2_codec2/common/Fourcc.h>
 
+#include <sys/mman.h>
+
 namespace android {
 namespace {
 
-constexpr size_t kNumInputBuffers = 16;
+constexpr size_t kNumInputBuffers = 2;
 // Extra buffers for transmitting in the whole video pipeline.
-constexpr size_t kNumExtraOutputBuffers = 4;
+constexpr size_t kNumOutputBuffers = 10;
 
 // Currently we only support flexible pixel 420 format YCBCR_420_888 in Android.
 // Here is the list of flexible 420 format.
@@ -37,30 +39,16 @@ constexpr std::initializer_list<uint32_t> kSupportedOutputFourccs = {
 uint32_t VideoCodecToV4L2PixFmt(VideoCodec codec) {
     switch (codec) {
     case VideoCodec::H264:
-        return V4L2_PIX_FMT_H264;
+        return V4L2_PIX_FMT_H264_SLICE;
     case VideoCodec::VP8:
-        return V4L2_PIX_FMT_VP8;
+        return V4L2_PIX_FMT_VP8_FRAME;
     case VideoCodec::VP9:
-        return V4L2_PIX_FMT_VP9;
+        return V4L2_PIX_FMT_VP9_FRAME;
     }
 }
 
 }  // namespace
 
-// static
-std::unique_ptr<VideoDecoder> V4L2Decoder::Create(
-        const VideoCodec& codec, const size_t inputBufferSize, const size_t minNumOutputBuffers,
-        GetPoolCB getPoolCb, OutputCB outputCb, ErrorCB errorCb,
-        scoped_refptr<::base::SequencedTaskRunner> taskRunner) {
-    std::unique_ptr<V4L2Decoder> decoder =
-            ::base::WrapUnique<V4L2Decoder>(new V4L2Decoder(taskRunner));
-    if (!decoder->start(codec, inputBufferSize, minNumOutputBuffers, std::move(getPoolCb),
-                        std::move(outputCb), std::move(errorCb))) {
-        return nullptr;
-    }
-    return decoder;
-}
-
 V4L2Decoder::V4L2Decoder(scoped_refptr<::base::SequencedTaskRunner> taskRunner)
       : mTaskRunner(std::move(taskRunner)) {
     ALOGV("%s()", __func__);
@@ -92,13 +80,13 @@ V4L2Decoder::~V4L2Decoder() {
 }
 
 bool V4L2Decoder::start(const VideoCodec& codec, const size_t inputBufferSize,
-                        const size_t minNumOutputBuffers, GetPoolCB getPoolCb, OutputCB outputCb,
+                        GetPoolCB getPoolCb, OutputCB outputCb,
                         ErrorCB errorCb) {
-    ALOGV("%s(codec=%s, inputBufferSize=%zu, minNumOutputBuffers=%zu)", __func__,
-          VideoCodecToString(codec), inputBufferSize, minNumOutputBuffers);
+    ALOGV("%s(codec=%s, inputBufferSize=%zu)", __func__,
+          VideoCodecToString(codec), inputBufferSize);
     ALOG_ASSERT(mTaskRunner->RunsTasksInCurrentSequence());
 
-    mMinNumOutputBuffers = minNumOutputBuffers;
+    mInputBufferSize = inputBufferSize;
     mGetPoolCb = std::move(getPoolCb);
     mOutputCb = std::move(outputCb);
     mErrorCb = std::move(errorCb);
@@ -108,10 +96,15 @@ bool V4L2Decoder::start(const VideoCodec& codec, const size_t inputBufferSize,
         return false;
     }
 
+    mMedia = MediaDevice::create();
+    if (!mMedia->open()) {
+        ALOGE("Failed to open media device for %s", VideoCodecToString(codec));
+        return false;
+    }
     mDevice = V4L2Device::create();
 
-    const uint32_t inputPixelFormat = VideoCodecToV4L2PixFmt(codec);
-    if (!mDevice->open(V4L2Device::Type::kDecoder, inputPixelFormat)) {
+    mInputPixelFormat = VideoCodecToV4L2PixFmt(codec);
+    if (!mDevice->open(V4L2Device::Type::kDecoder, mInputPixelFormat)) {
         ALOGE("Failed to open device for %s", VideoCodecToString(codec));
         return false;
     }
@@ -121,23 +114,6 @@ bool V4L2Decoder::start(const VideoCodec& codec, const size_t inputBufferSize,
         return false;
     }
 
-    struct v4l2_decoder_cmd cmd;
-    memset(&cmd, 0, sizeof(cmd));
-    cmd.cmd = V4L2_DEC_CMD_STOP;
-    if (mDevice->ioctl(VIDIOC_TRY_DECODER_CMD, &cmd) != 0) {
-        ALOGE("Device does not support flushing (V4L2_DEC_CMD_STOP)");
-        return false;
-    }
-
-    // Subscribe to the resolution change event.
-    struct v4l2_event_subscription sub;
-    memset(&sub, 0, sizeof(sub));
-    sub.type = V4L2_EVENT_SOURCE_CHANGE;
-    if (mDevice->ioctl(VIDIOC_SUBSCRIBE_EVENT, &sub) != 0) {
-        ALOGE("ioctl() failed: VIDIOC_SUBSCRIBE_EVENT: V4L2_EVENT_SOURCE_CHANGE");
-        return false;
-    }
-
     // Create Input/Output V4L2Queue, and setup input queue.
     mInputQueue = mDevice->getQueue(V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE);
     mOutputQueue = mDevice->getQueue(V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE);
@@ -145,10 +121,6 @@ bool V4L2Decoder::start(const VideoCodec& codec, const size_t inputBufferSize,
         ALOGE("Failed to create V4L2 queue.");
         return false;
     }
-    if (!setupInputFormat(inputPixelFormat, inputBufferSize)) {
-        ALOGE("Failed to setup input format.");
-        return false;
-    }
 
     if (!mDevice->startPolling(::base::BindRepeating(&V4L2Decoder::serviceDeviceTask, mWeakThis),
                                ::base::BindRepeating(&V4L2Decoder::onError, mWeakThis))) {
@@ -160,28 +132,28 @@ bool V4L2Decoder::start(const VideoCodec& codec, const size_t inputBufferSize,
     return true;
 }
 
-bool V4L2Decoder::setupInputFormat(const uint32_t inputPixelFormat, const size_t inputBufferSize) {
-    ALOGV("%s(inputPixelFormat=%u, inputBufferSize=%zu)", __func__, inputPixelFormat,
-          inputBufferSize);
+bool V4L2Decoder::setupInputFormat(const ui::Size &size) {
+    ALOGV("%s(inputPixelFormat=0x%08x, size=%s, inputBufferSize=%zu)", __func__,
+            mInputPixelFormat, toString(size).c_str(), mInputBufferSize);
     ALOG_ASSERT(mTaskRunner->RunsTasksInCurrentSequence());
 
     // Check if the format is supported.
     std::vector<uint32_t> formats =
             mDevice->enumerateSupportedPixelformats(V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE);
-    if (std::find(formats.begin(), formats.end(), inputPixelFormat) == formats.end()) {
+    if (std::find(formats.begin(), formats.end(), mInputPixelFormat) == formats.end()) {
         ALOGE("Input codec s not supported by device.");
         return false;
     }
 
     // Setup the input format.
-    auto format = mInputQueue->setFormat(inputPixelFormat, ui::Size(), inputBufferSize, 0);
+    auto format = mInputQueue->setFormat(mInputPixelFormat, size, mInputBufferSize, 0);
     if (!format) {
         ALOGE("Failed to call IOCTL to set input format.");
         return false;
     }
-    ALOG_ASSERT(format->fmt.pix_mp.pixelformat == inputPixelFormat);
+    ALOG_ASSERT(format->fmt.pix_mp.pixelformat == mInputPixelFormat);
 
-    if (mInputQueue->allocateBuffers(kNumInputBuffers, V4L2_MEMORY_DMABUF) == 0) {
+    if (mInputQueue->allocateBuffers(kNumInputBuffers, V4L2_MEMORY_MMAP) == 0) {
         ALOGE("Failed to allocate input buffer.");
         return false;
     }
@@ -217,7 +189,7 @@ void V4L2Decoder::drain(DecodeCB drainCb) {
 
     switch (mState) {
     case State::Idle:
-        ALOGV("Nothing need to drain, ignore.");
+        ALOGI("Nothing needs to drain, ignore.");
         mTaskRunner->PostTask(
                 FROM_HERE, ::base::BindOnce(std::move(drainCb), VideoDecoder::DecodeStatus::kOk));
         return;
@@ -243,72 +215,150 @@ void V4L2Decoder::pumpDecodeRequest() {
     if (mState != State::Decoding) return;
 
     while (!mDecodeRequests.empty()) {
+        // Wait for previous work to finish:
+        //  - input/ouptut buffer queued in the v4l2 decoder
+        //  - sending back an output buffer to the client
+        if (mInputQueue->queuedBuffersCount() > 0 ||
+            mOutputQueue->queuedBuffersCount() > 0 ||
+            !mFrameToOutput.empty())
+            return;
+
+        DecodeRequest &request = mDecodeRequests.front();
+
         // Drain the decoder.
-        if (mDecodeRequests.front().buffer == nullptr) {
+        if (request.buffer == nullptr) {
             ALOGV("Get drain request.");
-            // Send the flush command after all input buffers are dequeued. This makes
-            // sure all previous resolution changes have been handled because the
-            // driver must hold the input buffer that triggers resolution change. The
-            // driver cannot decode data in it without new output buffers. If we send
-            // the flush now and a queued input buffer triggers resolution change
-            // later, the driver will send an output buffer that has
-            // V4L2_BUF_FLAG_LAST. But some queued input buffer have not been decoded
-            // yet. Also, V4L2VDA calls STREAMOFF and STREAMON after resolution
-            // change. They implicitly send a V4L2_DEC_CMD_STOP and V4L2_DEC_CMD_START
-            // to the decoder.
-            if (mInputQueue->queuedBuffersCount() > 0) {
-                ALOGV("Wait for all input buffers dequeued.");
-                return;
-            }
 
             auto request = std::move(mDecodeRequests.front());
             mDecodeRequests.pop();
 
-            if (!sendV4L2DecoderCmd(false)) {
+            if (!drainInternal()) {
+                ALOGE("drainInternal failed");
                 std::move(request.decodeCb).Run(VideoDecoder::DecodeStatus::kError);
                 onError();
                 return;
             }
-            mDrainCb = std::move(request.decodeCb);
-            setState(State::Draining);
+
+            if (mFrameToOutput.empty()) {
+                std::move(request.decodeCb).Run(VideoDecoder::DecodeStatus::kOk);
+                setState(State::Idle);
+            } else {
+                mDrainCb = std::move(request.decodeCb);
+                setState(State::Draining);
+            }
             return;
         }
 
-        // Pause if no free input buffer. We resume decoding after dequeueing input buffers.
-        auto inputBuffer = mInputQueue->getFreeBuffer();
-        if (!inputBuffer) {
-            ALOGV("There is no free input buffer.");
-            return;
+        bool res = decode(std::move(request.buffer));
+        if (res) {
+            std::move(request.decodeCb).Run(VideoDecoder::DecodeStatus::kOk);
+        } else {
+            ALOGE("decode failed");
+            std::move(request.decodeCb).Run(VideoDecoder::DecodeStatus::kError);
+            onError();
         }
 
-        auto request = std::move(mDecodeRequests.front());
         mDecodeRequests.pop();
+    }
+}
 
-        const int32_t bitstreamId = request.buffer->id;
-        ALOGV("QBUF to input queue, bitstreadId=%d", bitstreamId);
-        inputBuffer->setTimeStamp({.tv_sec = bitstreamId});
-        size_t planeSize = inputBuffer->getPlaneSize(0);
-        if (request.buffer->size > planeSize) {
-            ALOGE("The input size (%zu) is not enough, we need %zu", planeSize,
-                  request.buffer->size);
-            onError();
-            return;
-        }
+bool V4L2Decoder::ensureInputBuffer() {
+    if (!mInputBuffer)
+        mInputBuffer = mInputQueue->getFreeBuffer();
 
-        ALOGV("Set bytes_used=%zu, offset=%zu", request.buffer->offset + request.buffer->size,
-              request.buffer->offset);
-        inputBuffer->setPlaneDataOffset(0, request.buffer->offset);
-        inputBuffer->setPlaneBytesUsed(0, request.buffer->offset + request.buffer->size);
-        std::vector<int> fds;
-        fds.push_back(std::move(request.buffer->dmabuf.handle()->data[0]));
-        if (!std::move(*inputBuffer).queueDMABuf(fds)) {
-            ALOGE("%s(): Failed to QBUF to input queue, bitstreamId=%d", __func__, bitstreamId);
-            onError();
-            return;
+    return mInputBuffer.has_value();
+}
+
+V4L2Decoder::RequestHandle V4L2Decoder::allocRequest(int bitstreamId) {
+    std::shared_ptr<V4L2Request> req = std::make_shared<V4L2Request>();
+
+    req->frameNum = bitstreamId;
+    req->result = nullptr;
+    req->request = mMedia->allocRequest();
+    if (!req->request) {
+        ALOGE("%s(): Failed to allocated a media request object", __func__);
+        onError();
+        return nullptr;
+    }
+
+    return std::move(req);
+}
+
+V4L2Decoder::RequestHandle V4L2Decoder::allocSubRequest(ResultHandle previous) {
+    std::shared_ptr<V4L2Request> req = std::make_shared<V4L2Request>();
+    std::shared_ptr<V4L2Result> res = std::static_pointer_cast<V4L2Result>(previous);
+
+    req->frameNum = res->frameNum;
+    req->result = res;
+    req->request = mMedia->allocRequest();
+    if (!req->request) {
+        ALOGE("%s(): Failed to allocated a media request object", __func__);
+        onError();
+        return nullptr;
+    }
+
+    return std::move(req);
+}
+
+V4L2Decoder::ResultHandle V4L2Decoder::submitRequest(RequestHandle reqHandle,
+        std::vector<V4L2ExtCtrl> &controls, uint32_t flags) {
+    ALOGV("%s()", __func__);
+    ALOG_ASSERT(mTaskRunner->RunsTasksInCurrentSequence());
+
+    std::shared_ptr<V4L2Request> req = std::static_pointer_cast<V4L2Request>(reqHandle);
+    std::optional<V4L2WritableBufferRef> outputBuffer;
+
+    if (!mInputBuffer) {
+        ALOGW("No input buffer");
+        goto error;
+    }
+
+    if (!req->result) {
+        outputBuffer = mOutputQueue->getFreeBuffer();
+        if (!outputBuffer) {
+            ALOGE("%s(): Failed to get output buffer", __func__);
+            goto error;
+        }
+        if (!std::move(*outputBuffer).queueMMap()) {
+            ALOGE("%s(): Failed to QBUF to output queue", __func__);
+            goto error;
         }
+    }
 
-        mPendingDecodeCbs.insert(std::make_pair(bitstreamId, std::move(request.decodeCb)));
+    mInputBuffer->addFlag(V4L2_BUF_FLAG_REQUEST_FD | flags);
+    mInputBuffer->setTimeStamp({ .tv_usec = req->frameNum });
+    mInputBuffer->setRequest(req->request);
+    if (!std::move(*mInputBuffer).queueMMap()) {
+        ALOGE("%s(): Failed to QBUF to input queue", __func__);
+        goto error;
     }
+
+    if (!mDevice->setExtCtrls(0, controls, req->request)) {
+        ALOGE("%s(): Driver did not accept the bitrstream parameters.", __func__);
+        goto error;
+    }
+
+    if (!req->request->queue()) {
+        ALOGE("%s(): Failed to QUEUE request", __func__);
+        goto error;
+    }
+    mInputBuffer = std::nullopt;
+
+    mPendingRequest.push(req);
+
+    if (!req->result) {
+        req->result = std::make_shared<V4L2Result>();
+        req->result->frameNum = req->frameNum;
+        mPendingResult.push(req->result);
+    }
+
+    return req->result;
+
+error:
+    ALOGE("sumbitRequest failed");
+    onError();
+    mInputBuffer = std::nullopt;
+    return nullptr;
 }
 
 void V4L2Decoder::flush() {
@@ -324,35 +374,54 @@ void V4L2Decoder::flush() {
         return;
     }
 
-    // Call all pending callbacks.
-    for (auto& item : mPendingDecodeCbs) {
-        std::move(item.second).Run(VideoDecoder::DecodeStatus::kAborted);
+    // Abort request in the todo queue
+    while (!mDecodeRequests.empty()) {
+        DecodeRequest request = std::move(mDecodeRequests.front());
+        std::move(request.decodeCb).Run(VideoDecoder::DecodeStatus::kAborted);
+        mDecodeRequests.pop();
     }
-    mPendingDecodeCbs.clear();
-    if (mDrainCb) {
+
+    if (mDrainCb)
         std::move(mDrainCb).Run(VideoDecoder::DecodeStatus::kAborted);
-    }
 
     // Streamoff both V4L2 queues to drop input and output buffers.
     const bool isOutputStreaming = mOutputQueue->isStreaming();
     mDevice->stopPolling();
     mOutputQueue->streamoff();
-    mFrameAtDevice.clear();
     mInputQueue->streamoff();
 
+    mInputBuffer = std::nullopt;
+
+    // Clear the pending queues
+    while (!mPendingRequest.empty())
+        mPendingRequest.pop();
+    while (!mPendingResult.empty())
+        mPendingResult.pop();
+    // Clear the queue of frames to output
+    while (!mFrameToOutput.empty())
+        mFrameToOutput.pop();
+
+    // Recycle video frames before loosing them
+    for (auto &p : mCompletedFrames)
+        mVideoFrames.push(std::move(p.second));
+    mCompletedFrames.clear();
+
+    // Unused frame pool can now be released safely
+    for (auto it = mVideoFramePools.cbegin(); it != mVideoFramePools.cend();) {
+        if (!it->active)
+            it = mVideoFramePools.erase(it);
+        else
+            ++it;
+    }
+
+    flushInternal();
+
     // Streamon both V4L2 queues.
     mInputQueue->streamon();
     if (isOutputStreaming) {
         mOutputQueue->streamon();
     }
 
-    // If there is no free buffer at mOutputQueue, tryFetchVideoFrame() should be triggerred after
-    // a buffer is DQBUF from output queue. Now all the buffers are dropped at mOutputQueue, we
-    // have to trigger tryFetchVideoFrame() here.
-    if (mVideoFramePool) {
-        tryFetchVideoFrame();
-    }
-
     if (!mDevice->startPolling(::base::BindRepeating(&V4L2Decoder::serviceDeviceTask, mWeakThis),
                                ::base::BindRepeating(&V4L2Decoder::onError, mWeakThis))) {
         ALOGE("Failed to start polling V4L2 device.");
@@ -375,7 +444,7 @@ void V4L2Decoder::serviceDeviceTask(bool event) {
 
     if (mState == State::Error) return;
 
-    // Dequeue output and input queue.
+    // Dequeue input queue.
     bool inputDequeued = false;
     while (mInputQueue->queuedBuffersCount() > 0) {
         bool success;
@@ -386,84 +455,73 @@ void V4L2Decoder::serviceDeviceTask(bool event) {
             onError();
             return;
         }
-        if (!dequeuedBuffer) break;
+        if (!dequeuedBuffer) continue;
 
         inputDequeued = true;
 
-        // Run the corresponding decode callback.
-        int32_t id = dequeuedBuffer->getTimeStamp().tv_sec;
-        ALOGV("DQBUF from input queue, bitstreamId=%d", id);
-        auto it = mPendingDecodeCbs.find(id);
-        if (it == mPendingDecodeCbs.end()) {
-            ALOGW("Callback is already abandoned.");
-            continue;
+        std::shared_ptr<V4L2Request> req = std::move(mPendingRequest.front());
+        mPendingRequest.pop();
+
+        const int32_t bitstreamId = static_cast<int32_t>(dequeuedBuffer->getTimeStamp().tv_usec);
+        if (bitstreamId != req->frameNum) {
+            ALOGE("Needed frame %d, but driver returned frame %d", req->frameNum, bitstreamId);
+            onError();
+            return;
         }
-        std::move(it->second).Run(VideoDecoder::DecodeStatus::kOk);
-        mPendingDecodeCbs.erase(it);
     }
 
+    // Dequeue output queue.
     bool outputDequeued = false;
-    while (mOutputQueue->queuedBuffersCount() > 0) {
+    while (!mVideoFrames.empty() && mOutputQueue->queuedBuffersCount() > 0) {
         bool success;
         V4L2ReadableBufferRef dequeuedBuffer;
         std::tie(success, dequeuedBuffer) = mOutputQueue->dequeueBuffer();
         if (!success) {
             ALOGE("Failed to dequeue buffer from output queue.");
+        // Workaround(b/168750131): If the buffer is not enqueued before the next drain is done,
+        // then the driver will fail to notify EOS. So we recycle the buffer immediately.
             onError();
             return;
         }
-        if (!dequeuedBuffer) break;
+        if (!dequeuedBuffer) continue;
 
         outputDequeued = true;
 
-        const size_t bufferId = dequeuedBuffer->bufferId();
-        const int32_t bitstreamId = static_cast<int32_t>(dequeuedBuffer->getTimeStamp().tv_sec);
+        const int32_t bitstreamId = static_cast<int32_t>(dequeuedBuffer->getTimeStamp().tv_usec);
         const size_t bytesUsed = dequeuedBuffer->getPlaneBytesUsed(0);
-        const bool isLast = dequeuedBuffer->isLast();
-        ALOGV("DQBUF from output queue, bufferId=%zu, bitstreamId=%d, bytesused=%zu, isLast=%d",
-              bufferId, bitstreamId, bytesUsed, isLast);
 
-        // Get the corresponding VideoFrame of the dequeued buffer.
-        auto it = mFrameAtDevice.find(bufferId);
-        ALOG_ASSERT(it != mFrameAtDevice.end(), "buffer %zu is not found at mFrameAtDevice",
-                    bufferId);
-        auto frame = std::move(it->second);
-        mFrameAtDevice.erase(it);
+        std::shared_ptr<V4L2Result> res = mPendingResult.front();
+        mPendingResult.pop();
 
-        if (bytesUsed > 0) {
-            ALOGV("Send output frame(bitstreamId=%d) to client", bitstreamId);
-            frame->setBitstreamId(bitstreamId);
-            frame->setVisibleRect(mVisibleRect);
-            mOutputCb.Run(std::move(frame));
-        } else {
-            // Workaround(b/168750131): If the buffer is not enqueued before the next drain is done,
-            // then the driver will fail to notify EOS. So we recycle the buffer immediately.
-            ALOGV("Recycle empty buffer %zu back to V4L2 output queue.", bufferId);
-            dequeuedBuffer.reset();
-            auto outputBuffer = mOutputQueue->getFreeBuffer(bufferId);
-            ALOG_ASSERT(outputBuffer, "V4L2 output queue slot %zu is not freed.", bufferId);
-
-            if (!std::move(*outputBuffer).queueDMABuf(frame->getFDs())) {
-                ALOGE("%s(): Failed to recycle empty buffer to output queue.", __func__);
-                onError();
-                return;
-            }
-            mFrameAtDevice.insert(std::make_pair(bufferId, std::move(frame)));
+        if (bitstreamId != res->frameNum) {
+            ALOGE("Needed frame %d, but driver returned frame %d", res->frameNum, bitstreamId);
+            onError();
+            return;
         }
 
-        if (mDrainCb && isLast) {
-            ALOGV("All buffers are drained.");
-            sendV4L2DecoderCmd(true);
-            std::move(mDrainCb).Run(VideoDecoder::DecodeStatus::kOk);
-            setState(State::Idle);
-        }
-    }
+        if (bytesUsed > 0) {
+            ALOGV("buffer %d completed", bitstreamId);
+            res->outputBuffer = dequeuedBuffer;
 
-    // Handle resolution change event.
-    if (event && dequeueResolutionChangeEvent()) {
-        if (!changeResolution()) {
-            onError();
-            return;
+            // Unwrap our arguments.
+            std::unique_ptr<VideoFrame> frame = std::move(mVideoFrames.front());
+            mVideoFrames.pop();
+
+            // Map the client buffer
+            std::shared_ptr<C2GraphicBlock> block = frame->graphicBlock();
+            C2GraphicView view = block->map().get();
+            uint8_t *dst = view.data()[0];
+
+            // Map the v4l2 buffer
+            const void *src = dequeuedBuffer->getPlaneMapping(0);
+
+            // copy the v4l2 buffer into the client buffer
+            memcpy(dst, src, mCodedSize.width * mCodedSize.height * 3/2);
+
+            frame->setBitstreamId(bitstreamId);
+            frame->setVisibleRect(Rect(mCodedSize.width, mCodedSize.height));
+
+            mCompletedFrames[bitstreamId] = std::move(frame);
         }
     }
 
@@ -472,38 +530,46 @@ void V4L2Decoder::serviceDeviceTask(bool event) {
         mTaskRunner->PostTask(FROM_HERE,
                               ::base::BindOnce(&V4L2Decoder::pumpDecodeRequest, mWeakThis));
     }
-    // We free some output buffers, try to get VideoFrame.
+    // We have completed buffers, check if it must be finished now.
     if (outputDequeued) {
         mTaskRunner->PostTask(FROM_HERE,
-                              ::base::BindOnce(&V4L2Decoder::tryFetchVideoFrame, mWeakThis));
+                              ::base::BindOnce(&V4L2Decoder::tryOutputFrame, mWeakThis));
     }
 }
 
-bool V4L2Decoder::dequeueResolutionChangeEvent() {
-    ALOGV("%s()", __func__);
-    ALOG_ASSERT(mTaskRunner->RunsTasksInCurrentSequence());
+void V4L2Decoder::finish(int id) {
+    ALOGV("%s() id: %d", __func__, id);
+    mFrameToOutput.push(id);
 
-    struct v4l2_event ev;
-    memset(&ev, 0, sizeof(ev));
-    while (mDevice->ioctl(VIDIOC_DQEVENT, &ev) == 0) {
-        if (ev.type == V4L2_EVENT_SOURCE_CHANGE &&
-            ev.u.src_change.changes & V4L2_EVENT_SRC_CH_RESOLUTION) {
-            return true;
-        }
-    }
-    return false;
+    // try output the frame if it is already dequeued from v4l2
+    tryOutputFrame();
 }
 
-bool V4L2Decoder::changeResolution() {
+bool V4L2Decoder::changeResolution(const ui::Size &size, std::vector<V4L2ExtCtrl> &controls) {
     ALOGV("%s()", __func__);
     ALOG_ASSERT(mTaskRunner->RunsTasksInCurrentSequence());
 
+    mOutputQueue->streamoff();
+    mOutputQueue->deallocateBuffers();
+
+    mInputQueue->streamoff();
+    mInputQueue->deallocateBuffers();
+
+    if (!setupInputFormat(size)) {
+        ALOGE("Failed to setup input format.");
+        return false;
+    }
+
+    if (!mDevice->setExtCtrls(0, controls, nullptr)) {
+        ALOGE("Driver does not support the selected stream.");
+        return false;
+    }
+
     const std::optional<struct v4l2_format> format = getFormatInfo();
-    std::optional<size_t> numOutputBuffers = getNumOutputBuffers();
+    std::optional<size_t> numOutputBuffers = kNumOutputBuffers;
     if (!format || !numOutputBuffers) {
         return false;
     }
-    *numOutputBuffers = std::max(*numOutputBuffers, mMinNumOutputBuffers);
 
     const ui::Size codedSize(format->fmt.pix_mp.width, format->fmt.pix_mp.height);
     if (!setupOutputFormat(codedSize)) {
@@ -515,22 +581,16 @@ bool V4L2Decoder::changeResolution() {
         return false;
     }
     mCodedSize.set(adjustedFormat->fmt.pix_mp.width, adjustedFormat->fmt.pix_mp.height);
-    mVisibleRect = getVisibleRect(mCodedSize);
 
-    ALOGI("Need %zu output buffers. coded size: %s, visible rect: %s", *numOutputBuffers,
-          toString(mCodedSize).c_str(), toString(mVisibleRect).c_str());
+    ALOGI("Need %zu output buffers. coded size: %s", *numOutputBuffers,
+          toString(mCodedSize).c_str());
     if (isEmpty(mCodedSize)) {
         ALOGE("Failed to get resolution from V4L2 driver.");
         return false;
     }
 
-    mOutputQueue->streamoff();
-    mOutputQueue->deallocateBuffers();
-    mFrameAtDevice.clear();
-    mBlockIdToV4L2Id.clear();
-
     const size_t adjustedNumOutputBuffers =
-            mOutputQueue->allocateBuffers(*numOutputBuffers, V4L2_MEMORY_DMABUF);
+            mOutputQueue->allocateBuffers(*numOutputBuffers, V4L2_MEMORY_MMAP);
     if (adjustedNumOutputBuffers == 0) {
         ALOGE("Failed to allocate output buffer.");
         return false;
@@ -541,17 +601,29 @@ bool V4L2Decoder::changeResolution() {
         return false;
     }
 
-    // Release the previous VideoFramePool before getting a new one to guarantee only one pool
-    // exists at the same time.
-    mVideoFramePool.reset();
+    // Set last frame pool inactive and number of frames before it must be
+    // deleted
+    if (!mVideoFramePools.empty()) {
+        VideoFramePoolInfo &poolInfo = mVideoFramePools.front();
+        poolInfo.active = false;
+        poolInfo.deleteDelay = mCompletedFrames.size();
+    }
+
+    // Release fetched video frames from old frame pool
+    while (!mVideoFrames.empty())
+        mVideoFrames.pop();
+
     // Always use flexible pixel 420 format YCBCR_420_888 in Android.
-    mVideoFramePool =
+    std::unique_ptr<VideoFramePool> pool =
             mGetPoolCb.Run(mCodedSize, HalPixelFormat::YCBCR_420_888, adjustedNumOutputBuffers);
-    if (!mVideoFramePool) {
+    if (!pool) {
         ALOGE("Failed to get block pool with size: %s", toString(mCodedSize).c_str());
         return false;
     }
 
+    // Store the new frame pool to the back of the list
+    mVideoFramePools.push_front({ .pool = std::move(pool), .active = true, .deleteDelay = 0 });
+
     tryFetchVideoFrame();
     return true;
 }
@@ -574,22 +646,60 @@ bool V4L2Decoder::setupOutputFormat(const ui::Size& size) {
     return false;
 }
 
+void V4L2Decoder::tryOutputFrame() {
+    while (!mFrameToOutput.empty()) {
+        int bitstreamId = mFrameToOutput.front();
+        auto it = mCompletedFrames.find(bitstreamId);
+        if (it == mCompletedFrames.end()) {
+            ALOGV("the frame is not yet completed and can't be finished, ignore.");
+            break;
+        }
+        mFrameToOutput.pop();
+
+        mOutputCb.Run(std::move(it->second));
+        mCompletedFrames.erase(it);
+
+        // Check if there is still an unused frame pool that can be released
+        VideoFramePoolInfo &poolInfo = mVideoFramePools.back();
+        if (!poolInfo.active) {
+            --poolInfo.deleteDelay;
+            if (poolInfo.deleteDelay == 0) {
+                // It is safe to delete the old frame pool now
+                mVideoFramePools.pop_back();
+            }
+        }
+    }
+
+    // Check if we were draining
+    if (mDrainCb && mFrameToOutput.empty()) {
+        ALOGV("All buffers are drained.");
+        std::move(mDrainCb).Run(VideoDecoder::DecodeStatus::kOk);
+        setState(State::Idle);
+    }
+
+    // Check if some video frames can be fetched
+    tryFetchVideoFrame();
+
+    // Continue the decoding process
+    mTaskRunner->PostTask(FROM_HERE,
+                          ::base::BindOnce(&V4L2Decoder::pumpDecodeRequest, mWeakThis));
+}
+
 void V4L2Decoder::tryFetchVideoFrame() {
     ALOGV("%s()", __func__);
     ALOG_ASSERT(mTaskRunner->RunsTasksInCurrentSequence());
 
-    if (!mVideoFramePool) {
+    if (mVideoFramePools.empty() || !mVideoFramePools.front().active) {
         ALOGE("mVideoFramePool is null, failed to get the instance after resolution change?");
         onError();
         return;
     }
 
-    if (mOutputQueue->freeBuffersCount() == 0) {
-        ALOGV("No free V4L2 output buffers, ignore.");
+    if (mVideoFrames.size() >= mOutputQueue->freeBuffersCount())
         return;
-    }
 
-    if (!mVideoFramePool->getVideoFrame(
+    std::unique_ptr<VideoFramePool> &pool = mVideoFramePools.front().pool;
+    if (!pool->getVideoFrame(
                 ::base::BindOnce(&V4L2Decoder::onVideoFrameReady, mWeakThis))) {
         ALOGV("%s(): Previous callback is running, ignore.", __func__);
     }
@@ -611,65 +721,14 @@ void V4L2Decoder::onVideoFrameReady(
     uint32_t blockId;
     std::tie(frame, blockId) = std::move(*frameWithBlockId);
 
-    std::optional<V4L2WritableBufferRef> outputBuffer;
-    // Find the V4L2 buffer that is associated with this block.
-    auto iter = mBlockIdToV4L2Id.find(blockId);
-    if (iter != mBlockIdToV4L2Id.end()) {
-        // If we have met this block in the past, reuse the same V4L2 buffer.
-        outputBuffer = mOutputQueue->getFreeBuffer(iter->second);
-    } else if (mBlockIdToV4L2Id.size() < mOutputQueue->allocatedBuffersCount()) {
-        // If this is the first time we see this block, give it the next
-        // available V4L2 buffer.
-        const size_t v4l2BufferId = mBlockIdToV4L2Id.size();
-        mBlockIdToV4L2Id.emplace(blockId, v4l2BufferId);
-        outputBuffer = mOutputQueue->getFreeBuffer(v4l2BufferId);
-    } else {
-        // If this happens, this is a bug in VideoFramePool. It should never
-        // provide more blocks than we have V4L2 buffers.
-        ALOGE("Got more different blocks than we have V4L2 buffers for.");
-    }
-
-    if (!outputBuffer) {
-        ALOGE("V4L2 buffer not available. blockId=%u", blockId);
-        onError();
-        return;
-    }
-
-    uint32_t v4l2Id = outputBuffer->bufferId();
-    ALOGV("QBUF to output queue, blockId=%u, V4L2Id=%u", blockId, v4l2Id);
+    mVideoFrames.push(std::move(frame));
 
-    if (!std::move(*outputBuffer).queueDMABuf(frame->getFDs())) {
-        ALOGE("%s(): Failed to QBUF to output queue, blockId=%u, V4L2Id=%u", __func__, blockId,
-              v4l2Id);
-        onError();
-        return;
-    }
-    if (mFrameAtDevice.find(v4l2Id) != mFrameAtDevice.end()) {
-        ALOGE("%s(): V4L2 buffer %d already enqueued.", __func__, v4l2Id);
-        onError();
-        return;
-    }
-    mFrameAtDevice.insert(std::make_pair(v4l2Id, std::move(frame)));
+    // Check if there is output buffers to dequeue
+    serviceDeviceTask(false);
 
     tryFetchVideoFrame();
 }
 
-std::optional<size_t> V4L2Decoder::getNumOutputBuffers() {
-    ALOGV("%s()", __func__);
-    ALOG_ASSERT(mTaskRunner->RunsTasksInCurrentSequence());
-
-    struct v4l2_control ctrl;
-    memset(&ctrl, 0, sizeof(ctrl));
-    ctrl.id = V4L2_CID_MIN_BUFFERS_FOR_CAPTURE;
-    if (mDevice->ioctl(VIDIOC_G_CTRL, &ctrl) != 0) {
-        ALOGE("ioctl() failed: VIDIOC_G_CTRL");
-        return std::nullopt;
-    }
-    ALOGV("%s() V4L2_CID_MIN_BUFFERS_FOR_CAPTURE returns %u", __func__, ctrl.value);
-
-    return ctrl.value + kNumExtraOutputBuffers;
-}
-
 std::optional<struct v4l2_format> V4L2Decoder::getFormatInfo() {
     ALOGV("%s()", __func__);
     ALOG_ASSERT(mTaskRunner->RunsTasksInCurrentSequence());
@@ -685,63 +744,6 @@ std::optional<struct v4l2_format> V4L2Decoder::getFormatInfo() {
     return format;
 }
 
-Rect V4L2Decoder::getVisibleRect(const ui::Size& codedSize) {
-    ALOGV("%s()", __func__);
-    ALOG_ASSERT(mTaskRunner->RunsTasksInCurrentSequence());
-
-    struct v4l2_rect* visible_rect = nullptr;
-    struct v4l2_selection selection_arg;
-    memset(&selection_arg, 0, sizeof(selection_arg));
-    selection_arg.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
-    selection_arg.target = V4L2_SEL_TGT_COMPOSE;
-
-    if (mDevice->ioctl(VIDIOC_G_SELECTION, &selection_arg) == 0) {
-        ALOGV("VIDIOC_G_SELECTION is supported");
-        visible_rect = &selection_arg.r;
-    } else {
-        ALOGV("Fallback to VIDIOC_G_CROP");
-        struct v4l2_crop crop_arg;
-        memset(&crop_arg, 0, sizeof(crop_arg));
-        crop_arg.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
-
-        if (mDevice->ioctl(VIDIOC_G_CROP, &crop_arg) != 0) {
-            ALOGW("ioctl() VIDIOC_G_CROP failed");
-            return Rect(codedSize.width, codedSize.height);
-        }
-        visible_rect = &crop_arg.c;
-    }
-
-    Rect rect(visible_rect->left, visible_rect->top, visible_rect->left + visible_rect->width,
-              visible_rect->top + visible_rect->height);
-    ALOGV("visible rectangle is %s", toString(rect).c_str());
-    if (!contains(Rect(codedSize.width, codedSize.height), rect)) {
-        ALOGW("visible rectangle %s is not inside coded size %s", toString(rect).c_str(),
-              toString(codedSize).c_str());
-        return Rect(codedSize.width, codedSize.height);
-    }
-    if (rect.isEmpty()) {
-        ALOGW("visible size is empty");
-        return Rect(codedSize.width, codedSize.height);
-    }
-
-    return rect;
-}
-
-bool V4L2Decoder::sendV4L2DecoderCmd(bool start) {
-    ALOGV("%s(start=%d)", __func__, start);
-    ALOG_ASSERT(mTaskRunner->RunsTasksInCurrentSequence());
-
-    struct v4l2_decoder_cmd cmd;
-    memset(&cmd, 0, sizeof(cmd));
-    cmd.cmd = start ? V4L2_DEC_CMD_START : V4L2_DEC_CMD_STOP;
-    if (mDevice->ioctl(VIDIOC_DECODER_CMD, &cmd) != 0) {
-        ALOGE("ioctl() VIDIOC_DECODER_CMD failed: start=%d", start);
-        return false;
-    }
-
-    return true;
-}
-
 void V4L2Decoder::onError() {
     ALOGV("%s()", __func__);
     ALOG_ASSERT(mTaskRunner->RunsTasksInCurrentSequence());
diff --git a/components/V4L2Device.cpp b/components/V4L2Device.cpp
new file mode 100644
index 0000000..e42b524
--- /dev/null
+++ b/components/V4L2Device.cpp
@@ -0,0 +1,29 @@
+#include "V4L2Device.h"
+
+#include <cstring>
+
+std::shared_ptr<V4L2Request> V4L2Decoder::allocSubRequest(V4L2Request *prevRequest, ) {
+    int ret;
+
+    std::shared_ptr<V4L2Request> request = mRequestPool.front();
+    mRequestPool.pop();
+
+    if (!request) {
+        request = std::make_shared<V4L2Request>();
+
+        ret = ioctl(mMediaFD, MEDIA_IOC_REQUEST_ALLOC, request->fd);
+        if (ret < 0) {
+            ALOGE("MEDIA_IOC_REQUEST_ALLOC failed: %s", std::strerror(errno));
+            return nullptr;
+        }
+    }
+
+    request->decoder = this;
+    request->bitstream = bitstream;
+    request->picBuf = prevRequest->picBuf;
+    request->frameNum = prevRequest->frameNum;
+    request->subRequest = true;
+    request->refCount = 1;
+
+    return request;
+}
diff --git a/components/VideoFramePool.cpp b/components/VideoFramePool.cpp
index 665ff73..9e0b971 100644
--- a/components/VideoFramePool.cpp
+++ b/components/VideoFramePool.cpp
@@ -82,7 +82,7 @@ std::unique_ptr<VideoFramePool> VideoFramePool::Create(
         usage |= C2MemoryUsage::READ_PROTECTED;
     } else if (blockPool->getAllocatorId() == android::V4L2AllocatorId::V4L2_BUFFERPOOL) {
         // CPU access to buffers is only required in byte buffer mode.
-        usage |= C2MemoryUsage::CPU_READ;
+        usage |= (C2MemoryUsage::CPU_READ | C2MemoryUsage::CPU_WRITE);
     }
     const C2MemoryUsage memoryUsage(usage);
 
diff --git a/components/h264/H264Decoder.cpp b/components/h264/H264Decoder.cpp
new file mode 100644
index 0000000..2888ae4
--- /dev/null
+++ b/components/h264/H264Decoder.cpp
@@ -0,0 +1,1910 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * GStreamer
+ * Copyright (C) 2019 Seungha Yang <seungha.yang@navercorp.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ *
+ * NOTE: some of implementations are copied/modified from Chromium code
+ *
+ * Copyright 2015 The Chromium Authors. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *    * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *    * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *    * Neither the name of Google Inc. nor the names of its
+ * contributors may be used to endorse or promote products derived from
+ * this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "H264Decoder"
+
+#include <v4l2_codec2/components/h264/H264Decoder.h>
+
+#include <stdint.h>
+
+#include <algorithm>
+#include <vector>
+
+#include <base/bind.h>
+#include <base/files/scoped_file.h>
+#include <base/memory/ptr_util.h>
+#include <log/log.h>
+
+#include <v4l2_codec2/common/Common.h>
+#include <v4l2_codec2/common/Fourcc.h>
+
+#define N_ELEMENTS(arr) (sizeof (arr) / sizeof ((arr)[0]))
+
+#define UPDATE_FLOW_RET(ret, new_ret) \
+    do { \
+        if (ret) \
+            ret = new_ret; \
+    } while (0)
+
+namespace android {
+
+// static
+H264Decoder::H264Decoder()
+    : mCompliance(Compliance::Strict), // FIXME
+      mIsLive(true),
+      mActiveSPS(nullptr),
+      mActivePPS(nullptr)
+{
+    ALOGV("%s()", __func__);
+}
+
+H264Decoder::~H264Decoder() {
+    ALOGV("%s()", __func__);
+}
+
+bool H264Decoder::decode(std::unique_ptr<ConstBitstreamBuffer> buffer) {
+    ALOGV("%s()", __func__);
+
+    mCurrentFrame = std::move(buffer);
+    std::optional<C2ReadView> view = mCurrentFrame->dmabuf.map().get();
+
+    bool ret = true;
+    H264NalUnit nalu;
+    H264Parser::Result pres = mParser.identifyNalu(view->data(), 0, view->capacity(), &nalu);
+
+    if (pres == H264Parser::NoNalEnd)
+        pres = H264Parser::Ok;
+
+    while (ret && pres == H264Parser::Ok) {
+        switch (nalu.type) {
+            case H264NalUnit::SPS:
+                ret = parseSPS(nalu);
+                break;
+            case H264NalUnit::PPS:
+                ret = parsePPS(nalu);
+                break;
+            case H264NalUnit::Slice:
+            case H264NalUnit::SliceDPA:
+            case H264NalUnit::SliceDPB:
+            case H264NalUnit::SliceDPC:
+            case H264NalUnit::SliceIDR:
+            case H264NalUnit::SliceExt:
+                ret = parseSlice(nalu);
+                break;
+            default:
+                break;
+        }
+
+        pres = mParser.identifyNalu(view->data(),
+                                    nalu.offset + nalu.size,
+                                    view->capacity(),
+                                    &nalu);
+
+        if (pres == H264Parser::NoNalEnd)
+            pres = H264Parser::Ok;
+    }
+
+    // unmap the buffer
+    view = std::nullopt;
+
+    if (!ret) {
+        mCurrentPicture = nullptr;
+        mCurrentFrame = nullptr;
+        return false;
+    }
+
+    ret = finishCurrentPicture();
+    mCurrentFrame = nullptr;
+
+    return ret;
+}
+
+void H264Decoder::flush() {
+    clearDPB();
+}
+
+bool H264Decoder::drain() {
+    /* dpb will be cleared by this method */
+    return drainInternal();
+}
+
+bool H264Decoder::parseSPS(const H264NalUnit &nalu) {
+    H264SPS sps = H264SPS();
+    H264Parser::Result res = mParser.parseSPS(nalu, &sps);
+
+    if (res != H264Parser::Ok) {
+        ALOGW("Failed to parse SPS, result: %d", res);
+        return false;
+    }
+
+    ALOGI("SPS parsed (id: %d)", sps.id);
+
+    if (!processSPS(sps)) {
+        ALOGW("Failed to process SPS");
+        return false;
+    } else if (mParser.updateSPS(sps) != H264Parser::Ok) {
+        ALOGW("Failed to update SPS");
+        return false;
+    }
+
+    return true;
+}
+
+struct LevelLimits {
+    H264Parser::Level level;
+    uint32_t maxMbps;
+    uint32_t maxFs;
+    uint32_t maxDpbMbs;
+    uint32_t maxMainBr;
+};
+
+static const LevelLimits levelLimitsMap[] = {
+    { H264Parser::LevelL1, 1485, 99, 396, 64 },
+    { H264Parser::LevelL1B, 1485, 99, 396, 128 },
+    { H264Parser::LevelL1_1, 3000, 396, 900, 192 },
+    { H264Parser::LevelL1_2, 6000, 396, 2376, 384 },
+    { H264Parser::LevelL1_3, 11800, 396, 2376, 768 },
+    { H264Parser::LevelL2, 11880, 396, 2376, 2000 },
+    { H264Parser::LevelL2_1, 19800, 792, 4752, 4000 },
+    { H264Parser::LevelL2_2, 20250, 1620, 8100, 4000 },
+    { H264Parser::LevelL3, 40500, 1620, 8100, 10000 },
+    { H264Parser::LevelL3_1, 108000, 3600, 18000, 14000 },
+    { H264Parser::LevelL3_2, 216000, 5120, 20480, 20000 },
+    { H264Parser::LevelL4, 245760, 8192, 32768, 20000 },
+    { H264Parser::LevelL4_1, 245760, 8192, 32768, 50000 },
+    { H264Parser::LevelL4_2, 522240, 8704, 34816, 50000 },
+    { H264Parser::LevelL5, 589824, 22080, 110400, 135000 },
+    { H264Parser::LevelL5_1, 983040, 36864, 184320, 240000 },
+    { H264Parser::LevelL5_2, 2073600, 36864, 184320, 240000 },
+    { H264Parser::LevelL6, 4177920, 139264, 696320, 240000 },
+    { H264Parser::LevelL6_1, 8355840, 139264, 696320, 480000 },
+    { H264Parser::LevelL6_2, 16711680, 139264, 696320, 800000 }
+};
+
+static int levelToMaxDpbMbs(H264Parser::Level level) {
+    int i;
+    for (i = 0; i < N_ELEMENTS(levelLimitsMap); i++) {
+        if (level == levelLimitsMap[i].level)
+            return levelLimitsMap[i].maxDpbMbs;
+    }
+
+    return 0;
+}
+
+int H264Decoder::getMaxNumReorderFrames(const H264SPS &sps, int maxDpbSize) {
+    if (sps.vuiParametersPresentFlag &&
+            sps.vuiParameters.bitstreamRestrictionFlag) {
+        if (sps.vuiParameters.numReorderFrames > maxDpbSize) {
+            ALOGW("max_num_reorder_frames present, but larger than MaxDpbFrames (%d > %d)",
+                    sps.vuiParameters.numReorderFrames, maxDpbSize);
+            return maxDpbSize;
+        }
+
+        return sps.vuiParameters.numReorderFrames;
+    } else if (sps.constraintSet3Flag) {
+        /* If max_num_reorder_frames is not present, if profile id is equal to
+         * 44, 86, 100, 110, 122 or 244 and constraint_set3_flag is equal to 1,
+         * max_num_reorder_frames shall be inferred to be equal to 0 */
+        switch (sps.profileIDC) {
+        case 44:
+        case 86:
+        case 100:
+        case 110:
+        case 122:
+        case 244:
+            return 0;
+        default:
+            break;
+        }
+    }
+
+    /* Relaxed conditions (undefined by spec) */
+    if (mCompliance != Strict && (sps.profileIDC == 66 || sps.profileIDC == 83)) {
+        /* baseline, constrained baseline and scalable-baseline profiles
+         * only contain I/P frames. */
+        return 0;
+    }
+
+    return maxDpbSize;
+}
+
+bool H264Decoder::processSPS(const H264SPS &sps) {
+    int maxDpbMbs;
+    uint8_t level;
+    int widthMb, heightMb;
+    uint32_t maxDpbFrames;
+    int maxDpbSize;
+    int prevMaxDpbSize;
+    int maxReorderFrames;
+    int prevMaxReorderFrames;
+    bool prevInterlaced;
+    bool interlaced;
+
+    if (sps.mbAdaptiveFrameFieldFlag) {
+        ALOGI("mb_adaptive_frame_field_flag == 1, MBAFF sequence");
+    } else {
+        ALOGI("mb_adaptive_frame_field_flag == 0, PAFF sequence");
+    }
+
+    interlaced = !sps.frameMBSOnlyFlag;
+
+    /* Spec A.3.1 and A.3.2
+     * For Baseline, Constrained Baseline and Main profile, the indicated level is
+     * Level 1b if level_idc is equal to 11 and constraint_set3_flag is equal to 1
+     */
+    level = sps.levelIDC;
+    if (level == 11 && (sps.profileIDC == 66 || sps.profileIDC == 77) &&
+        sps.constraintSet3Flag) {
+        /* Level 1b */
+        level = 9;
+    }
+
+    maxDpbMbs = levelToMaxDpbMbs(static_cast<H264Parser::Level>(level));
+    if (!maxDpbMbs)
+        return false;
+
+    widthMb = sps.width / 16;
+    heightMb = sps.height / 16;
+
+    maxDpbFrames = std::min(maxDpbMbs / (widthMb * heightMb), H264_DPB_MAX_SIZE);
+
+    if (sps.vuiParametersPresentFlag &&
+            sps.vuiParameters.bitstreamRestrictionFlag) {
+        maxDpbFrames = std::max((uint32_t)1, sps.vuiParameters.maxDecFrameBuffering);
+    }
+
+    /* Case 1) There might be some non-conforming streams that require more DPB
+     * size than that of specified one by SPS
+     * Case 2) If bitstream_restriction_flag is not present,
+     * max_dec_frame_buffering should be inferred
+     * to be equal to MaxDpbFrames, then MaxDpbFrames can exceed num_ref_frames
+     * See https://chromium-review.googlesource.com/c/chromium/src/+/760276/
+     */
+    maxDpbSize = std::max(maxDpbFrames, sps.numRefFrames);
+    if (maxDpbSize > H264_DPB_MAX_SIZE) {
+        ALOGW("Too large calculated DPB size %d", maxDpbSize);
+        maxDpbSize = H264_DPB_MAX_SIZE;
+    }
+
+    prevMaxDpbSize = mDPB.getMaxNumFrames();
+    prevInterlaced = mDPB.getInterlaced();
+
+    prevMaxReorderFrames = mDPB.getMaxNumReorderFrames();
+    maxReorderFrames = getMaxNumReorderFrames(sps, maxDpbSize);
+
+    if (mWidth != sps.width  || mHeight != sps.height ||
+        prevMaxDpbSize != maxDpbSize || prevInterlaced != interlaced ||
+        prevMaxReorderFrames != maxReorderFrames) {
+        ALOGI("SPS updated, resolution: %dx%d -> %dx%d, dpb size: %d -> %d, "
+              "interlaced %d -> %d, max_reorder_frames: %d -> %d",
+                mWidth, mHeight, sps.width, sps.height,
+                prevMaxDpbSize, maxDpbSize, prevInterlaced, interlaced,
+                prevMaxReorderFrames, maxReorderFrames);
+
+        mPreferredOutputDelay = getPreferredOutputDelay(mIsLive);
+
+        bool ret = newSequence(sps, maxDpbSize + mPreferredOutputDelay);
+        if (!ret) {
+            ALOGW("subclass does not want accept new sequence");
+            return ret;
+        }
+
+        mProfileIDC = sps.profileIDC;
+        mWidth = sps.width;
+        mHeight = sps.height;
+
+        mDPB.setMaxNumFrames(maxDpbSize);
+        mDPB.setInterlaced(interlaced);
+        mDPB.setMaxNumReorderFrames(maxReorderFrames);
+    }
+
+    return true;
+}
+
+bool H264Decoder::parsePPS(const H264NalUnit &nalu) {
+    H264PPS pps = H264PPS();
+    H264Parser::Result res = mParser.parsePPS(nalu, &pps);
+
+    if (res != H264Parser::Ok) {
+        ALOGW("Failed to parse PPS, result %d", res);
+        return false;
+    }
+
+    ALOGI("PPS parsed");
+
+    if (pps.numSliceGroupsMinus1 > 0) {
+        ALOGW("FMO is not supported");
+        return false;
+    } else if (mParser.updatePPS(pps) != H264Parser::Ok) {
+        ALOGW("Failed to update PPS");
+        return false;
+    }
+
+    return true;
+}
+
+bool H264Decoder::preprocessSlice(const H264Slice &slice) {
+    if (!mCurrentPicture) {
+        if (slice.header.firstMBInSlice != 0) {
+            ALOGE("Invalid stream, first_mb_in_slice %d",
+                    slice.header.firstMBInSlice);
+            return false;
+        }
+    }
+
+    return true;
+}
+
+int H264Decoder::picNumF(const H264PicturePtr &picture) {
+    if (picture->ref != H264Picture::LongTerm)
+        return picture->picNum;
+
+    return mMaxPicNum;
+}
+
+int H264Decoder::longTermPicNumF(const H264PicturePtr &picture) {
+    if (picture->ref == H264Picture::LongTerm)
+        return picture->longTermPicNum;
+
+    return 2 * (mMaxLongTermFrameIdx + 1);
+}
+
+/* This can process either ref_pic_list0 or ref_pic_list1, depending on the list
+ * argument. Set up pointers to proper list to be processed here. */
+bool H264Decoder::modifyRefPicList(int list) {
+    const H264SliceHdr *sliceHdr = &mCurrentSlice.header;
+    const H264RefPicListModification *listMod;
+    std::list<H264PicturePtr> refPicListX;
+    bool refPicListModificationFlagLX;
+    int numRefIdxLXActiveMinus1;
+    unsigned int numRefPicListModifications;
+
+    if (list == 0) {
+        refPicListX = mRefPicList0;
+        refPicListModificationFlagLX = sliceHdr->refPicListModificationFlagL0;
+        numRefPicListModifications = sliceHdr->nRefPicListModificationL0;
+        numRefIdxLXActiveMinus1 = sliceHdr->numRefIdxL0ActiveMinus1;
+        listMod = sliceHdr->refPicListModificationL0;
+    } else {
+        refPicListX = mRefPicList1;
+        refPicListModificationFlagLX = sliceHdr->refPicListModificationFlagL1;
+        numRefPicListModifications = sliceHdr->nRefPicListModificationL1;
+        numRefIdxLXActiveMinus1 = sliceHdr->numRefIdxL1ActiveMinus1;
+        listMod = sliceHdr->refPicListModificationL1;
+    }
+
+    /* Resize the list to the size requested in the slice header.
+     *
+     * Note that per 8.2.4.2 it's possible for num_ref_idx_lx_active_minus1 to
+     * indicate there should be more ref pics on list than we constructed. Those
+     * superfluous ones should be treated as non(reference and whill be
+     * initialized to null, which mist be handled by clients */
+    ALOG_ASSERT(numRefIdxLXActiveMinus1 >= 0);
+    if (refPicListX.size() > numRefIdxLXActiveMinus1 + 1)
+        refPicListX.resize(numRefIdxLXActiveMinus1 + 1);
+
+    if (!refPicListModificationFlagLX)
+        return true;
+
+    /* Spec 8.2.4.3:
+     * Reorder pictures on the list in a way specified in the stream. */
+    int picNumLXPred = mCurrentPicture->picNum;
+    auto refIdxLX = refPicListX.cbegin();
+    bool done = false;
+    for (int i = 0; i < numRefPicListModifications && !done; ++i) {
+        switch (listMod->modificationOfPicNumsIDC) {
+        /* 8.2.4.3.1 - Modify short reference picture position. */
+        case 0:
+        case 1:
+        {
+            int picNumLXNoWrap;
+
+            /* 8-34 */
+            if (listMod->modificationOfPicNumsIDC == 0) {
+                /* Substract given value from predicted PicNum. */
+                picNumLXNoWrap = picNumLXPred - (listMod->value.absDiffPicNumMinus1 + 1);
+                /* Wrap around max_pic_num if it becomes < 0 as result of
+                 * substraction */
+                if (picNumLXNoWrap < 0)
+                    picNumLXNoWrap += mMaxPicNum;
+            } else {
+                /* Add given value to predicted PicNum. */
+                picNumLXNoWrap = picNumLXPred + (listMod->value.absDiffPicNumMinus1 + 1);
+                /* Wrap around max_pic_num if it becomes >= max_pic_num as
+                 * result of addition */
+                if (picNumLXNoWrap >= mMaxPicNum)
+                    picNumLXNoWrap -= mMaxPicNum;
+            }
+
+            /* For use in next iteration */
+            picNumLXPred = picNumLXNoWrap;
+
+            /* 8-36 */
+            int picNumLX;
+            if (picNumLXNoWrap > mCurrentPicture->picNum)
+                picNumLX = picNumLXNoWrap - mMaxPicNum;
+            else
+                picNumLX = picNumLXNoWrap;
+
+            /* 8-37 */
+            ALOG_ASSERT(numRefIdxLXActiveMinus1 + 1 < 32);
+            H264PicturePtr pic = mDPB.getShortRefByPicNum(picNumLX);
+            if (!pic) {
+                ALOGW("Malformed stream, no pic num %d", picNumLX);
+                break;
+            }
+
+            refPicListX.resize(numRefIdxLXActiveMinus1 + 1);
+            refPicListX.insert(refIdxLX, std::move(pic));
+            ++refIdxLX;
+
+            for (auto src = refIdxLX, dst = refIdxLX;
+                    src != refPicListX.cend(); ++src) {
+                int srcPicNumLX = *src ? picNumF(*src) : -1;
+                if (srcPicNumLX != picNumLX) {
+                    dst = refPicListX.erase(dst);
+                    refPicListX.insert(dst, *src);
+                }
+            }
+
+           break;
+        }
+
+        /* 8.2.4.3.2 - Lon-term reference pictures */
+        case 2:
+        {
+            /* (8-38) */
+            ALOG_ASSERT(numRefIdxLXActiveMinus1 + 1 < 32);
+            H264PicturePtr pic = mDPB.getLongRefByLongTermPicNum(listMod->value.longTermPicNum);
+            if (!pic) {
+                ALOGW("Malformed stream, no pic num %d", listMod->value.longTermPicNum);
+                break;
+            }
+
+            refPicListX.resize(numRefIdxLXActiveMinus1 + 1);
+            refPicListX.insert(refIdxLX, std::move(pic));
+            ++refIdxLX;
+
+            for (auto src = refIdxLX, dst = refIdxLX;
+                    src != refPicListX.cend(); ++src) {
+                int srcPicNumLX = *src ? longTermPicNumF(*src) : -1;
+                if (srcPicNumLX != listMod->value.longTermPicNum) {
+                    dst = refPicListX.erase(dst);
+                    refPicListX.insert(dst, *src);
+                }
+            }
+
+            break;
+        }
+        /* End of modification list */
+        case 3:
+            done = true;
+            break;
+
+        default:
+            /* may be recoverable */
+            ALOGW("Invalid modification_of_pic_nums_idc = %d", listMod->modificationOfPicNumsIDC);
+            break;
+        }
+
+        ++listMod;
+    }
+
+    /* Per NOTE 2 in 8.2.4.3.2, the ref_pic_listx in the above loop is
+     * temporarily made on element longer than the required final list.
+     * Resize the list back to its required size. */
+    if (refPicListX.size() > numRefIdxLXActiveMinus1 + 1)
+        refPicListX.resize(numRefIdxLXActiveMinus1 + 1);
+
+    return true;
+}
+
+bool H264Decoder::modifyRefPicLists() {
+    H264SliceHdr *sliceHdr = &mCurrentSlice.header;
+
+    mRefPicList0.clear();
+    mRefPicList1.clear();
+
+    if (sliceHdr->is(H264SliceHdr::P) || sliceHdr->is(H264SliceHdr::SP)) {
+        /* 8.2.4 fill reference picture list RefPicList0 for P or SP slice */
+        mRefPicList0 = mRefPicListP0;
+        return modifyRefPicList(0);
+    } else if (sliceHdr->is(H264SliceHdr::B)) {
+        /* 8.2.4 fill reference picture list RefPicList0 and RefPicList1 for B slice */
+        mRefPicList0 = mRefPicListB0;
+        mRefPicList1 = mRefPicListB1;
+        return modifyRefPicList(0) && modifyRefPicList(1);
+    }
+
+    return true;
+}
+
+bool H264Decoder::decodeSlice() {
+    if (!mCurrentPicture) {
+        ALOGE("No current picture");
+        return false;
+    }
+    const H264PicturePtr &picture = mCurrentPicture;
+
+    ALOGI("Decode picture %p (frame_num %d, poc %d)", mCurrentPicture.get(),
+            mCurrentPicture->frameNum, mCurrentPicture->picOrderCnt);
+
+    mMaxPicNum = mCurrentSlice.header.maxPicNum;
+
+    bool ret = true;
+    std::list<H264PicturePtr> refPicList0;
+    std::list<H264PicturePtr> refPicList1;
+
+    if (mProcessRefPicLists) {
+        if (!modifyRefPicLists()) {
+            ret = false;
+            goto beach;
+        }
+
+        refPicList0 = mRefPicList0;
+        refPicList1 = mRefPicList1;
+    }
+
+    ret = decodeSlice(picture, mCurrentSlice, refPicList0, refPicList1);
+    if (!ret) {
+        ALOGW("Subclass didn't want to decode picture %p (frame_num %d, poc %d)",
+                picture.get(), picture->frameNum, picture->picOrderCnt);
+    }
+
+beach:
+    mRefPicList0.clear();
+    mRefPicList1.clear();
+
+    return ret;
+}
+
+
+void H264Decoder::clearRefPicLists() {
+    mRefPicListP0.clear();
+    mRefPicListB0.clear();
+    mRefPicListB1.clear();
+}
+
+bool H264Decoder::handleMemoryManagementOpt(const H264PicturePtr &picture) {
+    for (int i = 0; i < N_ELEMENTS(picture->decRefPicMarking.refPicMarking); ++i) {
+        const H264RefPicMarking &refPicMarking =
+            picture->decRefPicMarking.refPicMarking[i];
+
+        uint8_t type = refPicMarking.memoryManagementControlOperation;
+
+        ALOGI("memory management operation %d, type %d", i, type);
+
+        /* Normal end of operations' specification */
+        if (type == 0)
+            return true;
+
+        switch (type) {
+        case 4:
+            mMaxLongTermFrameIdx = refPicMarking.maxLongTermFrameIdxPlus1 - 1;
+            break;
+        case 5:
+            mMaxLongTermFrameIdx = -1;
+            break;
+        default:
+            break;
+        }
+
+        if (!mDPB.performMemoryManagementControlOperation(refPicMarking, picture)) {
+            ALOGW("memory management operation type %d failed", type);
+            /* Most likely our implementation fault, but let's just perform next
+             * MMCO if any */
+        }
+    }
+
+    return true;
+}
+
+bool H264Decoder::slidingWindowPictureMarking(const H264PicturePtr &picture) {
+    const H264SPS *sps = mActiveSPS;
+    int numRefPics;
+    int maxNumRefFrames;
+
+    /* Skip this for the second field */
+    if (picture->secondField)
+        return true;
+
+    if (!sps) {
+        ALOGE("No active sps");
+        return false;
+    }
+
+    /* 8.2.5.3. Ensure the DPB doesn't overflow by discarding the oldest picture */
+    numRefPics = mDPB.numRefFrames();
+    maxNumRefFrames = std::max((uint32_t)1, sps->numRefFrames);
+
+    if (numRefPics < maxNumRefFrames)
+        return true;
+
+    /* In theory, num_ref_pics shouldn't be larger than max_num_ref_frames
+     * but it could happen if our implementation is wrong somehow or so.
+     * Just try to remove reference pictures as many as possible in order to
+     * avoid DPB overflow.
+     */
+    while (numRefPics >= maxNumRefFrames) {
+        /* Max number of reference pics reached, need to remove one of the short
+         * term ones. Find smallest frame_num_wrap short reference picture and
+         * mark it as unused */
+        std::shared_ptr<H264Picture> toUnmark = mDPB.getLowestFrameNumShortRef();
+
+        if (numRefPics > maxNumRefFrames) {
+            ALOGW("num_ref_pics %d is larger than allowed maximum %d",
+                    numRefPics, maxNumRefFrames);
+        }
+
+        if (!toUnmark) {
+            ALOGW("Could not find a short ref picture to unmark");
+            return false;
+        }
+
+        ALOGI("Unmark reference flag of picture %p (frame_num %d, poc %d)",
+                toUnmark.get(), toUnmark->frameNum, toUnmark->picOrderCnt);
+
+        toUnmark->setReference(H264Picture::None, true);
+
+        --numRefPics;
+    }
+
+    return true;
+}
+
+bool H264Decoder::referencePictureMarking(const H264PicturePtr &picture) {
+    /* If the current picture is an IDR, all reference pictures are unmarked */
+    if (picture->idr) {
+        mDPB.markAllNonRef();
+
+        if (picture->decRefPicMarking.longTermReferenceFlag) {
+            picture->setReference(H264Picture::LongTerm, false);
+            picture->longTermFrameIdx = 0;
+            mMaxLongTermFrameIdx = 0;
+        } else {
+            picture->setReference(H264Picture::ShortTerm, false);
+            mMaxLongTermFrameIdx = -1;
+        }
+
+        return true;
+    }
+
+    /* Not an IDR. If the stream contains instructions on how to discard
+     * pictures from DPB and how to mark/unmark existing reference pictures, do
+     * so.
+     * Otherwise, fall back to default sliding window process */
+    if (picture->decRefPicMarking.adaptiveRefPicMarkingModeFlag) {
+        if (picture->nonexisting) {
+            ALOGW("Invalid memory management operation for non-existing picture "
+                  "%p (frame_num %d, poc %d", picture.get(), picture->frameNum,
+                    picture->picOrderCnt);
+        }
+
+        return handleMemoryManagementOpt(picture);
+    }
+
+    return slidingWindowPictureMarking(picture);
+}
+
+H264DPB::BumpMode H264Decoder::getBumpLevel() const {
+    /* User set the mode explicitly. */
+    switch (mCompliance) {
+    case Compliance::Strict:
+        return H264DPB::NormalLatency;
+    case Compliance::Normal:
+        return H264DPB::LowLatency;
+    case Compliance::Flexible:
+        return H264DPB::VeryLowLatency;
+    default:
+        break;
+    }
+
+    /* ComplianceAuto case. */
+
+    if (mIsLive) {
+        /* The baseline and constrained-baseline profiles do not have B frames
+         * and do not use the picture reorder, sage to use the higher bump
+         * level. */
+        if (mProfileIDC == H264Parser::Baseline)
+            return H264DPB::VeryLowLatency;
+
+        return H264DPB::LowLatency;
+    }
+
+    return H264DPB::NormalLatency;
+}
+
+bool H264Decoder::doOutputPicture(const H264PicturePtr &picture) {
+    uint32_t lastOutputPoc;
+
+    ALOGI("Outputting picture %p (frame_num %d, poc %d)",
+            picture.get(), picture->frameNum, picture->picOrderCnt);
+
+    lastOutputPoc = mDPB.getLastOutputPoc();
+    if (picture->picOrderCnt < lastOutputPoc) {
+        ALOGW("Outputing out of order %d -> %d, likely a broken stream",
+                lastOutputPoc, picture->picOrderCnt);
+    }
+
+    mOutputQueue.push(picture);
+
+    return  drainOutputQueue(mPreferredOutputDelay);
+}
+
+bool H264Decoder::bumpDPB(H264DPB::BumpMode bumpLevel,
+        const H264PicturePtr &currentPicture) {
+    bool res = true;
+
+    while (mDPB.needsBump(currentPicture, bumpLevel)) {
+        const H264PicturePtr &toOutput = mDPB.bump(false);
+
+        if (!toOutput) {
+            ALOGW("Bumping is needed but no picture to output");
+            break;
+        }
+
+        res = doOutputPicture(toOutput);
+    }
+
+    return res;
+}
+
+H264PicturePtr H264Decoder::splitFrame(const H264PicturePtr &picture) {
+    ALOG_ASSERT(picture->field == H264Picture::Frame);
+
+    H264PicturePtr otherField = newFieldPicture(picture);
+    if (!otherField) {
+        ALOGW("Couldn't split frame into complementary field pair");
+        return nullptr;
+    }
+
+    ALOGV("Split picture %p, poc %d, frame num %d",
+            picture.get(), picture->picOrderCnt, picture->frameNum);
+
+    /* FIXME: enhance TFF decision by using picture timeing SEI */
+    if (picture->topFieldOrderCnt < picture->bottomFieldOrderCnt) {
+        picture->field = H264Picture::Top;
+        picture->picOrderCnt = picture->topFieldOrderCnt;
+
+        otherField->field = H264Picture::Bottom;
+        otherField->picOrderCnt = picture->bottomFieldOrderCnt;
+    } else {
+        picture->field = H264Picture::Bottom;
+        picture->picOrderCnt = picture->bottomFieldOrderCnt;
+
+        otherField->field = H264Picture::Top;
+        otherField->picOrderCnt = picture->topFieldOrderCnt;
+    }
+
+    otherField->topFieldOrderCnt = picture->topFieldOrderCnt;
+    otherField->bottomFieldOrderCnt = picture->bottomFieldOrderCnt;
+    otherField->frameNum = picture->frameNum;
+    otherField->ref = picture->ref;
+    otherField->nonexisting = picture->nonexisting;
+    otherField->systemFrameNumber = picture->systemFrameNumber;
+    otherField->fieldPicFlag = picture->fieldPicFlag;
+
+    return otherField;
+}
+
+bool H264Decoder::outputPictureDirectly(const H264PicturePtr &picture) {
+    bool ret = true;
+    H264PicturePtr outPic = nullptr;
+
+    if (picture->field == H264Picture::Frame) {
+        ALOG_ASSERT(mLastField == nullptr);
+        outPic = picture;
+        goto output;
+    }
+
+    if (mLastField == nullptr) {
+        if (picture->secondField) {
+            ALOGW("Set the last output %p poc:%d, without first field",
+                    picture.get(), picture->picOrderCnt);
+
+            ret = false;
+            goto output;
+        }
+
+        /* Just cache the first field. */
+        mLastField = picture;
+    } else {
+        if (!picture->secondField || !picture->otherField ||
+               picture->otherField != mLastField) {
+            ALOGW("The last field %p poc:%d is not the pair of the "
+                  "current field %p poc:%d",
+                    mLastField.get(), mLastField->picOrderCnt,
+                    picture.get(), picture->picOrderCnt);
+
+            mLastField = nullptr;
+            ret = false;
+            goto output;
+        }
+
+        ALOGI("Pair the last field %p poc:%d and the current field %p poc:%d",
+                mLastField.get(), mLastField->picOrderCnt,
+                picture.get(), picture->picOrderCnt);
+
+        outPic = mLastField;
+        mLastField = nullptr;
+        outPic->otherField = picture;
+    }
+
+output:
+    if (outPic) {
+        mDPB.setLastOutput(outPic);
+        bool aux = doOutputPicture(outPic);
+        UPDATE_FLOW_RET(ret, aux);
+    }
+
+    return ret;
+}
+
+bool H264Decoder::finishPicture(const H264PicturePtr &picture) {
+    H264DPB::BumpMode bumpLevel = getBumpLevel();
+
+    /* Finish processing the picture.
+     * Start by storing previous picture data for later use */
+    if (picture->ref) {
+        referencePictureMarking(picture);
+        mPrevRefHasMemMgmnt5 = picture->memMgmt5;
+        mPrevRefTopFieldOrderCnt = picture->topFieldOrderCnt;
+        mPrevRefPicOrderCntMsb = picture->picOrderCntMSB;
+        mPrevRefPicOrderCntLsb = picture->picOrderCntLSB;
+        mPrevRefField = picture->field;
+        mPrevRefFrameNum = picture->frameNum;
+    }
+
+    mPrevFrameNum = picture->frameNum;
+    mPrevHasMemMgmnt5 = picture->memMgmt5;
+    mPrevFrameNumOffset = picture->frameNumOffset;
+
+    /*  Remove unused (for reference or later output) pictures from DPB, marking
+     *  them as such */
+    mDPB.deleteUnused();
+
+       /* C.4.4 */
+    bool res = true;
+    bool aux = true;
+    if (picture->memMgmt5) {
+        ALOGI("Memory management type 5, drain the DPB");
+
+        aux = drainInternal();
+        UPDATE_FLOW_RET(res, aux);
+    }
+
+    aux = bumpDPB(bumpLevel, picture);
+    UPDATE_FLOW_RET(res, aux);
+
+    /* C.4.5.1, C.4.5.2
+     * - If the current decoded picture is the second field of a complementary
+     *   reference field pair, add to DPB.
+     * C.4.5.1
+     * For A reference decoded picture, the "bumping" process is invoked
+     * repeatedly until there is an empty frame buffer, then add to DPB:
+     * C.4.5.2
+     * For a non-reference decoded picture, if there is empty frame buffer after
+     * bumping the smaller POC, add to DPB.
+     * Otherwise, output directly. */
+    if ((picture->secondField && picture->otherField && picture->otherField->ref) ||
+            picture->ref || mDPB.hasEmptyFrameBuffer()) {
+        /* Split frame into top/bottom field pictures for reference picture
+         * marking process. Even if current picture has field_Pic_flag equal to
+         * zero, if next picture is a field picture, complementary field pair of
+         * reference frame should have individual pic_num and long_term_pic_num.
+         */
+        if (mDPB.getInterlaced() && picture->field == H264Picture::Frame) {
+            const H264PicturePtr &otherField = splitFrame(picture);
+
+            addPictureToDPB(picture);
+            if (!otherField) {
+                ALOGW("Couldn't split frame into complementary field pair");
+                /* Keep decoding anyway */
+            } else {
+                addPictureToDPB(otherField);
+            }
+        } else {
+            addPictureToDPB(picture);
+        }
+    } else {
+        aux = outputPictureDirectly(picture);
+        UPDATE_FLOW_RET(res, aux);
+    }
+
+    ALOGV("Finishing picture %p (frame_num %d, poc %d), entries in DPB %d",
+            picture.get(), picture->frameNum, picture->picOrderCnt, mDPB.getSize());
+
+    /* For low-latency output, we try to bump here to avoid waiting for another
+     * decoding circle. */
+    if (bumpLevel != H264DPB::NormalLatency) {
+        aux = bumpDPB(bumpLevel, nullptr);
+        UPDATE_FLOW_RET(res, aux);
+    }
+
+    return res;
+}
+
+bool H264Decoder::finishCurrentPicture() {
+    if (!mCurrentPicture)
+        return true;
+
+    bool res = endPicture(mCurrentPicture);
+    if (!res) {
+        ALOGW("end picture failed, marking picture %p non-existing "
+              "(frame_num %d, poc %d)", mCurrentPicture.get(),
+                mCurrentPicture->frameNum, mCurrentPicture->picOrderCnt);
+        mCurrentPicture->nonexisting = true;
+    }
+
+    /* We no longer need the per frame reference lists */
+    clearRefPicLists();
+
+    bool aux = finishPicture(mCurrentPicture);
+    mCurrentPicture = nullptr;
+
+    UPDATE_FLOW_RET(res, aux);
+
+    return res;
+}
+
+void H264Decoder::updatePicNums(const H264PicturePtr &currentPicture,
+        int frameNum) {
+    const std::list<H264PicturePtr> &dpb = mDPB.getPicturesAll();
+
+    for (auto it = dpb.cbegin(); it != dpb.cend(); ++it) {
+        H264PicturePtr picture = *it;
+
+        if (picture->ref == H264Picture::None)
+            continue;
+
+        if (picture->ref == H264Picture::LongTerm) {
+            if (currentPicture->field == H264Picture::Frame)
+                picture->longTermPicNum = picture->longTermFrameIdx;
+            else if (currentPicture->field == picture->field)
+                picture->longTermPicNum = 2 * picture->longTermFrameIdx + 1;
+            else
+                picture->longTermPicNum = 2 * picture->longTermFrameIdx;
+        } else {
+            if (picture->frameNum > frameNum)
+                picture->frameNumWrap = picture->frameNum - mMaxFrameNum;
+            else
+                picture->frameNumWrap = picture->frameNum;
+
+            if (currentPicture->field == H264Picture::Frame)
+                picture->picNum = picture->frameNumWrap;
+            else if (picture->field == currentPicture->field)
+                picture->picNum = 2 * picture->frameNumWrap + 1;
+            else
+                picture->picNum = 2 * picture->frameNumWrap;
+        }
+    }
+}
+
+void H264Decoder::addPictureToDPB(const H264PicturePtr &picture) {
+    if (!mDPB.getInterlaced()) {
+        ALOG_ASSERT(mLastField == nullptr);
+        mDPB.add(picture);
+        return;
+    }
+
+    /* The first field of the last picture may not be able to enter the
+     * DPB if it is a non ref, but if the second field enters the DPB, we
+     * need to add both of them. */
+    if (mLastField && picture->otherField == mLastField) {
+        mDPB.add(mLastField);
+        mLastField = nullptr;
+    }
+
+    mDPB.add(picture);
+}
+
+void H264Decoder::clearDPB() {
+    mOutputQueue = std::queue<H264PicturePtr>();
+    clearRefPicLists();
+    mLastField = nullptr;
+    mDPB.clear();
+}
+
+bool H264Decoder::initGapPicture(const H264PicturePtr &picture, int frameNum) {
+    picture->nonexisting = true;
+    picture->nalRefIDC = 1;
+    picture->frameNum = frameNum;
+    picture->picNum = frameNum;
+    picture->decRefPicMarking.adaptiveRefPicMarkingModeFlag = false;
+    picture->ref = H264Picture::ShortTerm;
+    picture->refPic = true;
+    picture->decRefPicMarking.longTermReferenceFlag = false;
+    picture->field = H264Picture::Frame;
+
+    return calculatePOC(picture);
+}
+
+bool H264Decoder::handleFrameNumGap(int frameNum) {
+    if (!mActiveSPS) {
+        ALOGE("No active SPS");
+        return false;
+    }
+
+    if (mPrevRefFrameNum == frameNum) {
+        ALOGI("frame_num == PrevRefFrameNum (%d), not a gap", frameNum);
+        return true;
+    }
+
+    if (((mPrevRefFrameNum + 1) % mMaxFrameNum) == frameNum) {
+        ALOGI("frame_num == (PrevRefFrameNum + 1) %% MaxFramNum (%d), not a gap",
+                frameNum);
+        return true;
+    }
+
+    if (mDPB.getSize() == 0) {
+        ALOGI("DPB is empty, not a gap");
+        return true;
+    }
+
+    if (mActiveSPS->gapsInFrameNumValueAllowedFlag) {
+        /* This is likely the case where some frames were dropped.
+         * Then we need to keep decoding without error out */
+        ALOGW("Invalid frame num %d, maybe frame drop", frameNum);
+
+        return true;
+    }
+
+    ALOGI("Handling frame num gap %d -> %d (MaxFramNum: %d)",
+            mPrevRefFrameNum, frameNum, mMaxFrameNum);
+
+    /* 7.4.3/7-23 */
+    int unusedShortTermFrameNum = (mPrevRefFrameNum + 1) % mMaxFrameNum;
+    while (unusedShortTermFrameNum != frameNum) {
+        H264PicturePtr picture = std::make_shared<H264Picture>();
+
+        if (!initGapPicture(picture, unusedShortTermFrameNum))
+            return false;
+
+        updatePicNums(picture, unusedShortTermFrameNum);
+
+        /* C.2.1 */
+        if (!slidingWindowPictureMarking(picture)) {
+            ALOGE("Couldn't perform sliding window picture marking");
+            return false;
+        }
+
+        mDPB.deleteUnused();
+
+        bool ret = bumpDPB(H264DPB::NormalLatency, picture);
+        if (!ret)
+            return ret;
+
+        /* the picture is short term ref, add to DPB */
+        if (mDPB.getInterlaced()) {
+            const H264PicturePtr &otherField = splitFrame(picture);
+
+            addPictureToDPB(picture);
+            addPictureToDPB(otherField);
+        } else {
+            addPictureToDPB(picture);
+        }
+
+        ++unusedShortTermFrameNum;
+        unusedShortTermFrameNum %= mMaxFrameNum;
+    }
+
+    return true;
+}
+
+void H264Decoder::constructRefPicListsP(
+        const H264PicturePtr & /* currentPicture */) {
+    /* RefPicList0 (8.2.4.2.1) [[1] [2]], where:
+     * [1] shortterm ref pics sorted by descending pic_num,
+     * [2] longterm ref pics by ascending long_term_pic_num.
+     */
+    mRefPicListP0.clear();
+    mDPB.getPicturesShortTermRef(true, false, mRefPicListP0);
+    mRefPicListP0.sort([](const H264PicturePtr &a, const H264PicturePtr &b) {
+        return a->picNum > b->picNum;
+    });
+
+    std::list<H264PicturePtr> aux;
+    mDPB.getPicturesLongTermRef(false, aux);
+    aux.sort([](const H264PicturePtr &a, const H264PicturePtr &b) {
+        return a->longTermPicNum < b->longTermPicNum;
+    });
+
+    mRefPicListP0.splice(mRefPicListP0.cend(), aux);
+}
+
+void H264Decoder::constructRefPicListsB(
+        const H264PicturePtr &currentPicture) {
+    /* RefPicList0 (8.2.4.2.3) [[1] [2] [3]], where:
+     * [1] shortterm ref pics with POC < currentPicture's POC sorted by
+     *     descending POC,
+     * [2] shortterm ref pics with POC > currentPicture's POC by ascending POC,
+     * [3] longterm ref pics by ascending longTermPicNum.
+     */
+
+    /* 8.2.4.2.3
+     * When pic_order_cnt_type is equal to 0, reference pictures that are marked
+     * as "non-existing" as specified in clause 8.2.5.2 are not included in
+     * either RefPicList0 of RefPicList1
+     */
+    std::list<H264PicturePtr> aux;
+    mDPB.getPicturesShortTermRef(currentPicture->picOrderCntType != 0, false, aux);
+
+    /* First sort ascending, this will put [1] in right place and finish [2]. */
+    aux.sort([](const H264PicturePtr &a, const H264PicturePtr &b) {
+        return a->picOrderCnt < b->picOrderCnt;
+    });
+
+    /* Find first with POC > currentPicture's POC to get first element in [2]... */
+    auto it = std::find_if(aux.cbegin(), aux.cend(),
+        [&currentPicture](const H264PicturePtr &picture) {
+        return picture->picOrderCnt > currentPicture->picOrderCnt;
+    });
+
+    /* and sort [1] descending, this finishing sequence [1] [2]. */
+    mRefPicListB0.clear();
+    mRefPicListB0.splice(mRefPicListB0.cbegin(), aux, aux.cbegin(), it);
+    mRefPicListB0.reverse();
+    mRefPicListB0.splice(mRefPicListB0.cend(), aux, aux.cbegin(), aux.cend());
+
+    /* Now add [3] and sort by ascending long_term_pic_num */
+    aux.clear();
+    mDPB.getPicturesLongTermRef(false, aux);
+    aux.sort([](const H264PicturePtr &a, const H264PicturePtr &b) {
+        return a->longTermPicNum < b->longTermPicNum;
+    });
+    mRefPicListB0.splice(mRefPicListB0.cend(), aux);
+
+    /* RefPicList1 (8.2.4.2.4) [[1] [2] [3]], where:
+     * [1] shortterm ref pics with POC > curr_pic's POC sorted by ascending POC,
+     * [2] shortterm ref pics with POC < curr_pic's POC by descending POC,
+     * [3] longterm ref pics by ascending longTermPicNum.
+     */
+    aux.clear();
+
+    mDPB.getPicturesShortTermRef(currentPicture->picOrderCntType != 0, false, aux);
+
+    /* First sort by descending POC. */
+    aux.sort([](const H264PicturePtr &a, const H264PicturePtr &b) {
+        return a->picOrderCnt > b->picOrderCnt;
+    });
+
+    /* Split at first with POC < current_picture's POC to get first element in
+     * [2]... */
+    it = std::find_if(aux.cbegin(), aux.cend(),
+        [&currentPicture](const H264PicturePtr &picture) {
+        return picture->picOrderCnt < currentPicture->picOrderCnt;
+    });
+
+    /* and sort [1] ascending. */
+    mRefPicListB1.clear();
+    mRefPicListB1.splice(mRefPicListB1.cbegin(), aux, aux.cbegin(), it);
+    mRefPicListB1.reverse();
+    mRefPicListB1.splice(mRefPicListB1.cend(), aux, aux.cbegin(), aux.cend());
+
+    /* Now add [3] and sort by ascending in long_term_pic_num */
+    aux.clear();
+    mDPB.getPicturesLongTermRef(false, aux);
+    aux.sort([](const H264PicturePtr &a, const H264PicturePtr &b) {
+        return a->longTermPicNum < b->longTermPicNum;
+    });
+    mRefPicListB1.splice(mRefPicListB1.cend(), aux);
+
+    /* If lists identical, swap first two entries in RefPicListB1 (spec
+     * 8.2.4.2.3) */
+    if (mRefPicListB1.size() > 1 && mRefPicListB0 == mRefPicListB1) {
+        /* swap */
+        std::iter_swap(mRefPicListB1.begin(), std::next(mRefPicListB1.begin()));
+    }
+}
+
+static void initPictureRefsFields1(const H264Picture::Field &field,
+        const std::list<H264PicturePtr> &refFrameList,
+        std::list<H264PicturePtr> &refPicListX) {
+    auto it1 = refFrameList.cbegin();
+    auto it2 = it1;
+    do {
+        for (; it1 != refFrameList.cend(); ++it1) {
+            if ((*it1)->field == field) {
+                refPicListX.push_back(*it1);
+                ++it1;
+                break;
+            }
+        }
+
+        for (; it2 != refFrameList.cend(); ++it2) {
+            if ((*it2)->field != field) {
+                refPicListX.push_back(*it2);
+                ++it2;
+                break;
+            }
+        }
+    } while (it1 != refFrameList.cend() || it2 != refFrameList.cend());
+}
+
+void H264Decoder::constructRefFieldPicListsP(const H264PicturePtr &currentPicture) {
+    mRefPicListP0.clear();
+    std::list<H264PicturePtr> refFrameList0ShortTerm;
+    std::list<H264PicturePtr> refFrameListLongTerm;
+
+    /* 8.2.4.2.2, 8.2.4.2.5 refFrameList0ShortTerm:
+     * short-term ref pictures sorted by descending frame_num_wrap.
+     */
+    mDPB.getPicturesShortTermRef(true, true, refFrameList0ShortTerm);
+    refFrameList0ShortTerm.sort([](const H264PicturePtr &a, const H264PicturePtr &b) {
+        return a->frameNumWrap > b->frameNumWrap;
+    });
+
+    /* 8.2.4.2.2 refFrameList0LongTerm:
+     * long-term ref pictures sorted by ascending long_term_frame_idx.
+     */
+    mDPB.getPicturesLongTermRef(true, refFrameListLongTerm);
+    refFrameListLongTerm.sort([](const H264PicturePtr &a, const H264PicturePtr &b) {
+        return a->longTermFrameIdx < b->longTermFrameIdx;
+    });
+
+    /* 8.2.4.2.5 */
+    initPictureRefsFields1(currentPicture->field, refFrameList0ShortTerm, mRefPicListP0);
+    initPictureRefsFields1(currentPicture->field, refFrameListLongTerm, mRefPicListP0);
+}
+
+void H264Decoder::constructRefFieldPicListsB(const H264PicturePtr &currentPicture) {
+    /* refFrameList0ShortTerm (8.2.4.2.4) [[1] [2]], where:
+     * [1] shortterm ref pics with POC < currentPicture's POC sorted by descending POC,
+     * [2] shortterm ref pics with POC > currentPicture's POC by ascending POC.
+     */
+
+    /* 8.2.4.2.4
+     * When pic_order_cnt_type is equal to 0, reference picture that are marked
+     * as "non-existing' as specified in clause 8.2.5.2 are not included in
+     * either RefPicList0 or RefPicList1
+     */
+    std::list<H264PicturePtr> aux;
+    mDPB.getPicturesShortTermRef(currentPicture->picOrderCntType != 0, true, aux);
+
+    /* First sort ascending, this will put [1] in right place and finish [2]. */
+    aux.sort([](const H264PicturePtr &a, const H264PicturePtr &b) {
+        return a->picOrderCnt < b->picOrderCnt;
+    });
+
+    /* Find first with POC > currentPicture's POC to get first element in [2]... */
+    auto it = std::find_if(aux.cbegin(), aux.cend(),
+            [&currentPicture](const H264PicturePtr &picture) {
+        return picture->picOrderCnt > currentPicture->picOrderCnt;
+    });
+
+    /* and sort [1] descending, this finishing sequence [1] [2]. */
+    std::list<H264PicturePtr> refFrameList0ShortTerm;
+    refFrameList0ShortTerm.splice(refFrameList0ShortTerm.cbegin(), aux, aux.cbegin(), it);
+    refFrameList0ShortTerm.reverse();
+    refFrameList0ShortTerm.splice(refFrameList0ShortTerm.cend(), aux, aux.cbegin(), aux.cend());
+
+    /* refFrameList1ShortTerm (8.2.4.2.4) [[1] [2]], where:
+     * [1] shortterm ref pics with POC > currentPicture's POC sorted by ascending POC,
+     * [2] shortterm ref pics with POC < currentPicture's POC by descending POC.
+     */
+    aux.clear();
+    mDPB.getPicturesShortTermRef(currentPicture->picOrderCntType != 0, true, aux);
+
+    /* First sort by descending POC. */
+    aux.sort([](const H264PicturePtr &a, const H264PicturePtr &b) {
+        return a->picOrderCnt > b->picOrderCnt;
+    });
+
+    /* Split at first with POC < currentPicture's POC to get first element in [2]... */
+    it = std::find_if(aux.cbegin(), aux.cend(),
+            [&currentPicture](const H264PicturePtr &picture) {
+        return picture->picOrderCnt < currentPicture->picOrderCnt;
+    });
+
+    /* and sort [1] ascending. */
+    std::list<H264PicturePtr> refFrameList1ShortTerm;
+    refFrameList1ShortTerm.splice(refFrameList1ShortTerm.cbegin(), aux, aux.cbegin(), it);
+    refFrameList1ShortTerm.reverse();
+    refFrameList1ShortTerm.splice(refFrameList1ShortTerm.cend(), aux, aux.cbegin(), aux.cend());
+
+    /* 8.2.4.2.2 refFrameList0LongTerm:
+     * long-term ref pictures sorted by ascending longTermFrameIdx.
+     */
+    std::list<H264PicturePtr> refFrameListLongTerm;
+    mDPB.getPicturesLongTermRef(true, refFrameListLongTerm);
+    refFrameListLongTerm.sort([](const H264PicturePtr &a, const H264PicturePtr &b) {
+        return a->longTermFrameIdx < b->longTermFrameIdx;
+    });
+
+    /* 8.2.4.2.5 RefPicListB0 */
+    mRefPicListB0.clear();
+    initPictureRefsFields1(currentPicture->field, refFrameList0ShortTerm, mRefPicListB0);
+    initPictureRefsFields1(currentPicture->field, refFrameListLongTerm, mRefPicListB0);
+
+    /* 8.2.4.2.5 RefPicList1 */
+    mRefPicListB1.clear();
+    initPictureRefsFields1(currentPicture->field, refFrameList1ShortTerm, mRefPicListB1);
+    initPictureRefsFields1(currentPicture->field, refFrameListLongTerm, mRefPicListB1);
+
+    /* If lists identical, swap first two entries in RefPicListB1 (spec
+     * 8.2.4.2.5) */
+    if (mRefPicListB1.size() > 1 && mRefPicListB0 == mRefPicListB1) {
+        /* swap */
+        std::iter_swap(mRefPicListB1.begin(), std::next(mRefPicListB1.begin()));
+    }
+}
+
+void H264Decoder::prepareRefPicLists(const H264PicturePtr &currentPicture) {
+    bool constructList = false;
+    const std::list<std::shared_ptr<H264Picture>> dpb = mDPB.getPicturesAll();
+
+    /* 8.2.4.2.1 ~ 8.2.4.2.4
+     * When this process is invoked, there shall be at least one reference entry
+     * that is currently marked as "used for reference"
+     * (i.E., as "used for short-term reference" or "used for long-term
+     * reference") and is not marked as 'non-existing"
+     */
+    for (auto it = dpb.cbegin(); it != dpb.cend(); ++it) {
+        std::shared_ptr<H264Picture> picture = *it;
+        if (picture->ref != H264Picture::None && !picture->nonexisting) {
+            constructList = true;
+            break;
+        }
+    }
+
+    if (!constructList) {
+        clearRefPicLists();
+        return;
+    }
+
+    if (currentPicture->field == H264Picture::Frame) {
+        constructRefPicListsP(currentPicture);
+        constructRefPicListsB(currentPicture);
+    } else {
+        constructRefFieldPicListsP(currentPicture);
+        constructRefFieldPicListsB(currentPicture);
+    }
+}
+
+bool H264Decoder::fillPictureFromSlice(const H264Slice &slice,
+        const H264PicturePtr &picture) {
+    const H264SliceHdr *sliceHdr = &slice.header;
+
+    const H264PPS *pps = sliceHdr->pps;
+    if (!pps) {
+        ALOGE("No pps in slice header");
+        return false;
+    }
+
+    const H264SPS *sps = pps->sequence;
+    if (!sps) {
+        ALOGE("No sps in pps");
+        return false;
+    }
+
+    picture->idr = slice.nalu.idrPicFlag;
+    picture->decRefPicMarking = sliceHdr->decRefPicMarking;
+    picture->fieldPicFlag = sliceHdr->fieldPicFlag;
+
+    if (picture->idr)
+        picture->idrPicId = sliceHdr->idrPicId;
+
+    if (sliceHdr->fieldPicFlag) {
+        picture->field = sliceHdr->bottomFieldFlag ?
+            H264Picture::Bottom : H264Picture::Top;
+    } else {
+        picture->field = H264Picture::Frame;
+    }
+
+    picture->nalRefIDC = slice.nalu.refIDC;
+    if (slice.nalu.refIDC != 0)
+        picture->setReference(H264Picture::ShortTerm, false);
+
+    picture->frameNum = sliceHdr->frameNum;
+
+    /* 7.4.3 */
+    if (!sliceHdr->fieldPicFlag)
+        picture->picNum = sliceHdr->frameNum;
+    else
+        picture->picNum = 2 * sliceHdr->frameNum + 1;
+
+    picture->picOrderCntType = sps->picOrderCntType;
+    switch (picture->picOrderCntType) {
+    case 0:
+        picture->picOrderCntLSB = sliceHdr->picOrderCntLSB;
+        picture->deltaPicOrderCntBottom = sliceHdr->deltaPicOrderCntBottom;
+        break;
+    case 1:
+        picture->deltaPicOrderCnt0 = sliceHdr->deltaPicOrderCnt[0];
+        picture->deltaPicOrderCnt1 = sliceHdr->deltaPicOrderCnt[1];
+        break;
+    case 2:
+        break;
+    default:
+        LOG_FATAL("Should not end up here");
+        return false;
+    }
+
+    return true;
+}
+
+bool H264Decoder::calculatePOC(const H264PicturePtr &picture) {
+    const H264SPS *sps = mActiveSPS;
+
+    if (!sps) {
+        ALOGE("No active SPS");
+        return false;
+    }
+
+    switch (picture->picOrderCntType) {
+    case 0:
+    {
+        /* See spec 8.2.1.1 */
+        int prevPicOrderCntMSB;
+        int prevPicOrderCntLSB;
+        int maxPicOrderCntLSB;
+
+        if (picture->idr) {
+            prevPicOrderCntMSB = 0;
+            prevPicOrderCntLSB = 0;
+        } else {
+            if (mPrevRefHasMemMgmnt5) {
+                if (mPrevRefField != H264Picture::Bottom) {
+                    prevPicOrderCntMSB = 0;
+                    prevPicOrderCntLSB = mPrevRefTopFieldOrderCnt;
+                } else {
+                    prevPicOrderCntMSB = 0;
+                    prevPicOrderCntLSB = 0;
+                }
+            } else {
+                prevPicOrderCntMSB = mPrevRefPicOrderCntMsb;
+                prevPicOrderCntLSB = mPrevRefPicOrderCntLsb;
+            }
+        }
+
+        maxPicOrderCntLSB = 1 << (sps->log2MaxPicOrderCntLSBMinus4 + 4);
+
+        if ((picture->picOrderCntLSB < prevPicOrderCntLSB) &&
+            (prevPicOrderCntLSB - picture->picOrderCntLSB >= maxPicOrderCntLSB / 2)) {
+            picture->picOrderCntMSB = prevPicOrderCntMSB + maxPicOrderCntLSB;
+        } else if ((picture->picOrderCntLSB > prevPicOrderCntLSB) &&
+                    (picture->picOrderCntLSB - prevPicOrderCntLSB > maxPicOrderCntLSB / 2)) {
+            picture->picOrderCntMSB = prevPicOrderCntMSB - maxPicOrderCntLSB;
+        } else {
+            picture->picOrderCntMSB = prevPicOrderCntMSB;
+        }
+
+        if (picture->field != H264Picture::Bottom) {
+            picture->topFieldOrderCnt = picture->picOrderCntMSB + picture->picOrderCntLSB;
+        }
+
+        int poc = picture->picOrderCntMSB + picture->picOrderCntLSB;
+        switch (picture->field) {
+        case H264Picture::Frame:
+            picture->topFieldOrderCnt = poc;
+            picture->bottomFieldOrderCnt = picture->topFieldOrderCnt + picture->deltaPicOrderCntBottom;
+            break;
+        case H264Picture::Top:
+            picture->topFieldOrderCnt = poc;
+            break;
+        case H264Picture::Bottom:
+            picture->bottomFieldOrderCnt = poc;
+            break;
+        }
+        break;
+    }
+
+    case 1:
+    {
+        int expectedPicOrderCnt = 0;
+
+        /* See spec 8.2.1.2 */
+        if (mPrevHasMemMgmnt5)
+            mPrevFrameNumOffset = 0;
+
+        if (picture->idr)
+            picture->frameNumOffset = 0;
+        else if (mPrevFrameNum > picture->frameNum)
+            picture->frameNumOffset = mPrevFrameNumOffset + mMaxFrameNum;
+        else
+            picture->frameNumOffset = mPrevFrameNumOffset;
+
+        int absFrameNum = 0;
+        if (sps->numRefFramesInPicOrderCntCycle != 0)
+            absFrameNum = picture->frameNumOffset + picture->frameNum;
+
+        if (picture->nalRefIDC == 0 && absFrameNum > 0)
+            --absFrameNum;
+
+        if (absFrameNum > 0) {
+            if (sps->numRefFramesInPicOrderCntCycle == 0) {
+                ALOGW("Invalid num_ref_frames_in_pic_order_cnt_cycle in stream");
+                return false;
+            }
+
+            int picOrderCntCycleCnt = (absFrameNum - 1) / sps->numRefFramesInPicOrderCntCycle;
+            int frameNumInPicOrderCntCycle = (absFrameNum - 1) % sps->numRefFramesInPicOrderCntCycle;
+
+            int expectedDeltaPerPicOrderCntCycle = 0;
+            for (int i = 0; i < sps->numRefFramesInPicOrderCntCycle; ++i)
+                expectedDeltaPerPicOrderCntCycle += sps->offsetForRefFrame[i];
+
+            expectedPicOrderCnt = picOrderCntCycleCnt * expectedDeltaPerPicOrderCntCycle;
+            /* frame_num_in_pic_order_cnt_cycle is verified < 255 in parser */
+            for (int i = 0; i < frameNumInPicOrderCntCycle; ++i)
+                expectedPicOrderCnt += sps->offsetForRefFrame[i];
+        }
+
+        if (!picture->nalRefIDC)
+            expectedPicOrderCnt += sps->offsetForNonRefPic;
+
+        if (picture->field == H264Picture::Frame) {
+            picture->topFieldOrderCnt = expectedPicOrderCnt + picture->deltaPicOrderCnt0;
+            picture->bottomFieldOrderCnt = picture->topFieldOrderCnt +
+                sps->offsetForTopToBottomField + picture->deltaPicOrderCnt1;
+        } else if (picture->field != H264Picture::Bottom) {
+            picture->topFieldOrderCnt = expectedPicOrderCnt + picture->deltaPicOrderCnt0;
+        } else {
+            picture->bottomFieldOrderCnt = expectedPicOrderCnt +
+                sps->offsetForTopToBottomField + picture->deltaPicOrderCnt0;
+        }
+        break;
+    }
+
+    case 2:
+    {
+        /* See spec 8.2.1.3 */
+        if (mPrevHasMemMgmnt5)
+            mPrevFrameNumOffset = 0;
+
+        if (picture->idr)
+            picture->frameNumOffset = 0;
+        else if (mPrevFrameNum > picture->frameNum)
+            picture->frameNumOffset = mPrevFrameNumOffset + mMaxFrameNum;
+        else
+            picture->frameNumOffset = mPrevFrameNumOffset;
+
+        int tempPicOrderCnt;
+        if (picture->idr)
+            tempPicOrderCnt = 0;
+        else if (!picture->nalRefIDC)
+            tempPicOrderCnt = 2 * (picture->frameNumOffset + picture->frameNum) - 1;
+        else
+            tempPicOrderCnt = 2 * (picture->frameNumOffset + picture->frameNum);
+
+        if (picture->field == H264Picture::Frame) {
+            picture->topFieldOrderCnt = tempPicOrderCnt;
+            picture->bottomFieldOrderCnt = tempPicOrderCnt;
+        } else if (picture->field == H264Picture::Bottom) {
+            picture->bottomFieldOrderCnt = tempPicOrderCnt;
+        } else {
+            picture->topFieldOrderCnt = tempPicOrderCnt;
+        }
+        break;
+    }
+
+    default:
+        ALOGW("Invalid pic_order_cnt_type: %d", sps->picOrderCntType);
+        break;
+    }
+
+    switch (picture->field) {
+    case H264Picture::Frame:
+        picture->picOrderCnt = std::min(picture->topFieldOrderCnt, picture->bottomFieldOrderCnt);
+        break;
+    case H264Picture::Top:
+        picture->picOrderCnt = picture->topFieldOrderCnt;
+        break;
+    case H264Picture::Bottom:
+        picture->picOrderCnt = picture->bottomFieldOrderCnt;
+        break;
+    default:
+        LOG_FATAL("Should not end up here");
+        return false;
+    }
+
+    return true;
+}
+
+bool H264Decoder::initCurrentPicture() {
+    if (!fillPictureFromSlice(mCurrentSlice, mCurrentPicture))
+        return false;
+
+    if (!calculatePOC(mCurrentPicture))
+        return false;
+
+
+    /* If the slice header indicates we will have to preform reference marking
+     * process after this picture is decoded, store required data for that
+     * purpose */
+    if (mCurrentSlice.header.decRefPicMarking.adaptiveRefPicMarkingModeFlag) {
+        mCurrentPicture->decRefPicMarking = mCurrentSlice.header.decRefPicMarking;
+    }
+
+    return true;
+}
+
+bool H264Decoder::startCurrentPicture() {
+    ALOG_ASSERT(mCurrentPicture);
+    ALOG_ASSERT(mActiveSPS);
+    ALOG_ASSERT(mActivePPS);
+
+    mMaxFrameNum = mActiveSPS->maxFrameNum;
+
+    int frameNum = mCurrentSlice.header.frameNum;
+    if (mCurrentSlice.nalu.idrPicFlag)
+        mPrevRefFrameNum = 0;
+
+    bool ret = handleFrameNumGap(frameNum);
+    if (!ret)
+        return ret;
+
+    if (!initCurrentPicture())
+        return false;
+
+    /* If the new picture is an IDR, flush DPB */
+    if (mCurrentPicture->idr) {
+        if (!mCurrentPicture->decRefPicMarking.noOutputOfPriorPicsFlag) {
+            ret = drainInternal();
+            if (!ret)
+                return ret;
+        } else {
+            /* C.4.4 Removal of pictures from the DPB before possible insertion
+             * of the current picture
+             *
+             * If decoded picture is IDR and no_output_of_prior_pics_flag is
+             * equal to 1 or is inferred to be equal to 1, all frame buffers in
+             * the DPB are emptied without output of the pictures they contain,
+             * and DPB fullness is set to 0.
+             */
+            clearDPB();
+        }
+    }
+
+    updatePicNums(mCurrentPicture, frameNum);
+
+    if (mProcessRefPicLists)
+        prepareRefPicLists(mCurrentPicture);
+
+    ret = startPicture(mCurrentPicture, mCurrentSlice, mDPB);
+    if (!ret) {
+        ALOGW("subclass does not want to start picture");
+        return ret;
+    }
+
+    return true;
+}
+
+H264PicturePtr H264Decoder::newFieldPicture(const H264PicturePtr &picture) {
+
+    const H264PicturePtr &newPicture = std::make_shared<H264Picture>();
+
+    /*don't confuse by non-existing picture */
+    if (!picture->nonexisting) {
+        bool res = newFieldPicture(picture, newPicture);
+        if (!res) {
+            ALOGW("Subclass couldn't handle new field picture");
+            return nullptr;
+        }
+    }
+
+    newPicture->otherField = picture;
+    newPicture->secondField = true;
+
+    return newPicture;
+}
+
+bool H264Decoder::findFirstFieldPicture(const H264Slice &slice,
+        H264PicturePtr &firstField) {
+    H264PicturePtr prevField;
+    bool inDPB;
+
+    if (mDPB.getInterlaced()) {
+        if (mLastField) {
+            prevField = mLastField;
+            inDPB = false;
+        } else if (mDPB.getSize() > 0) {
+            const std::list<H264PicturePtr> &pictures = mDPB.getPicturesAll();
+            H264PicturePtr prevPicture = pictures.back();
+
+            /* Previous picture was a field picture. */
+            if (prevPicture->field != H264Picture::Frame &&
+                    !prevPicture->otherField) {
+                prevField = prevPicture;
+                inDPB = true;
+            }
+        }
+    } else {
+        ALOG_ASSERT(mLastField == nullptr);
+    }
+
+    const H264SliceHdr &sliceHdr = slice.header;
+    /* This is not a field picture */
+    if (!sliceHdr.fieldPicFlag) {
+        if (!prevField)
+            return true;
+
+        ALOGW("Previous picture %p (poc %d) is not complete",
+                prevField.get(), prevField->picOrderCnt);
+        goto error;
+    }
+
+    /* OK, this is the first field. */
+    if (!prevField)
+        return true;
+
+    if (prevField->frameNum != sliceHdr.frameNum) {
+        ALOGW("Previous picture %p (poc %d) is not complete",
+                prevField.get(), prevField->picOrderCnt);
+        goto error;
+    } else {
+        H264Picture::Field currentField = sliceHdr.bottomFieldFlag ?
+            H264Picture::Bottom : H264Picture::Top;
+
+        if (currentField == prevField->field) {
+            ALOGW("Current picture and previous picture have identical field %d",
+                    currentField);
+            goto error;
+        }
+    }
+
+    firstField = prevField;
+    return true;
+
+error:
+    if (!inDPB) {
+        mLastField = nullptr;
+    } else {
+        /* FIXME: implement fill gap field picture if it is already in DPB */
+    }
+
+    return false;
+}
+
+bool H264Decoder::parseSlice(const H264NalUnit &nalu) {
+    bool ret = true;
+    mCurrentSlice.header = H264SliceHdr();
+    H264Parser::Result res = mParser.parseSliceHdr(nalu, &mCurrentSlice.header,
+                                                   true, true);
+    if (res != H264Parser::Ok) {
+        ALOGE("Failed to parse slice header, ret: %d", res);
+        mCurrentSlice = H264Slice();
+        return false;
+    }
+
+    mCurrentSlice.nalu = nalu;
+
+    if (!preprocessSlice(mCurrentSlice))
+        return false;
+
+    mActivePPS = mCurrentSlice.header.pps;
+    mActiveSPS = mActivePPS->sequence;
+
+    /* Check whether field picture boundary within given codec frame.
+     * This might happen in case that upstream sent buffer per frame unit,
+     * not picture unit (i.e., AU unit).
+     * If AU baoundary is detected, then finish first field picture we decoded
+     * in this chain, we should finish the current picture and start new field
+     * picture decoding */
+    if (mDPB.getInterlaced() && mCurrentPicture &&
+            mCurrentPicture->field == H264Picture::Frame &&
+            !mCurrentPicture->secondField) {
+        H264Picture::Field prevField = mCurrentPicture->field;
+        H264Picture::Field curField = H264Picture::Frame;
+        if (mCurrentSlice.header.fieldPicFlag) {
+            curField = mCurrentSlice.header.bottomFieldFlag ?
+                H264Picture::Bottom : H264Picture::Top;
+        }
+
+        if (curField != prevField) {
+            ALOGI("Found new field picture, finishing the first field picture");
+            ret = finishCurrentPicture();
+        }
+    }
+
+    if (!mCurrentPicture) {
+        std::shared_ptr<H264Picture> picture;
+        std::shared_ptr<H264Picture> firstField;
+
+        if (!findFirstFieldPicture(mCurrentSlice, firstField)) {
+            ALOGE("Couldn't find or determine first picture");
+            return false;
+        }
+
+        if (firstField) {
+            picture = newFieldPicture(firstField);
+            if (!picture) {
+                ALOGE("Couldn't duplicate the first field picture");
+                return false;
+            }
+        } else {
+            picture = std::make_shared<H264Picture>();
+        }
+
+        picture->systemFrameNumber = mCurrentFrame->id;
+        mCurrentPicture = picture;
+
+        ret = startCurrentPicture();
+        if (!ret) {
+            ALOGW("start picture failed");
+            return ret;
+        }
+    }
+
+    return decodeSlice();
+}
+
+bool H264Decoder::drainOutputQueue(unsigned int num) {
+    bool ret = true;
+
+    while (mOutputQueue.size() > num) {
+        bool aux = outputPicture(std::move(mOutputQueue.front()));
+        UPDATE_FLOW_RET(ret, aux);
+        mOutputQueue.pop();
+    }
+
+    return ret;
+}
+
+bool H264Decoder::drainInternal() {
+    bool res = true;
+    H264PicturePtr picture;
+
+    while ((picture = mDPB.bump(true)) != nullptr) {
+        res = doOutputPicture(picture);
+    }
+
+    res = drainOutputQueue(0);
+    mLastField = nullptr;
+    mDPB.clear();
+
+    return res;
+}
+
+
+}  // namespace android
diff --git a/components/h264/V4L2H264Decoder.cpp b/components/h264/V4L2H264Decoder.cpp
new file mode 100644
index 0000000..9b46e60
--- /dev/null
+++ b/components/h264/V4L2H264Decoder.cpp
@@ -0,0 +1,716 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * GStreamer
+ * Copyright (C) 2020 Nicolas Dufresne <nicolas.dufresne@collabora.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "V4L2Decoder"
+
+#include <v4l2_codec2/components/h264/V4L2H264Decoder.h>
+
+#include <base/memory/ptr_util.h>
+
+#include <sys/mman.h>
+
+using namespace std::chrono_literals;
+
+#define N_ELEMENTS(arr) (sizeof (arr) / sizeof ((arr)[0]))
+
+namespace android {
+
+ // static
+std::unique_ptr<VideoDecoder> V4L2H264Decoder::Create(
+        const size_t inputBufferSize,
+        GetPoolCB getPoolCb, OutputCB outputCb, ErrorCB errorCb,
+        scoped_refptr<::base::SequencedTaskRunner> taskRunner) {
+    std::unique_ptr<V4L2H264Decoder> decoder =
+            ::base::WrapUnique<V4L2H264Decoder>(new V4L2H264Decoder(taskRunner));
+    if (!decoder->start(VideoCodec::H264, inputBufferSize, std::move(getPoolCb),
+                        std::move(outputCb), std::move(errorCb))) {
+        return nullptr;
+    }
+
+    return decoder;
+}
+
+V4L2H264Decoder::V4L2H264Decoder(scoped_refptr<::base::SequencedTaskRunner> taskRunner)
+    : V4L2Decoder(taskRunner)
+{ }
+
+V4L2H264Decoder::~V4L2H264Decoder()
+{ }
+
+bool V4L2H264Decoder::start(const VideoCodec &codec, size_t inputBufferSize,
+                            GetPoolCB getPoolCb, OutputCB outputCb, ErrorCB errorCb) {
+    if (!V4L2Decoder::start(codec, inputBufferSize, getPoolCb, outputCb, errorCb))
+        return false;
+
+    struct v4l2_ext_control control[] = {
+        {
+            .id = V4L2_CID_STATELESS_H264_DECODE_MODE,
+        },
+        {
+            .id = V4L2_CID_STATELESS_H264_START_CODE,
+        },
+    };
+
+    struct v4l2_ext_controls controls = {
+        .controls = control,
+        .count = N_ELEMENTS(control)
+    };
+
+    if (mDevice->ioctl(VIDIOC_G_EXT_CTRLS, &controls) != 0) {
+        ALOGE("%s(): ioctl VIDIOC_G_EXT_CTRLS failed", __func__);
+        return false;
+    }
+
+    mDecodeMode = static_cast<enum v4l2_stateless_h264_decode_mode>(control[0].value);
+    mStartCode = static_cast<enum v4l2_stateless_h264_start_code>(control[1].value);
+
+    ALOGV("Opened H264 %s decoder %s",
+        mDecodeMode == V4L2_STATELESS_H264_DECODE_MODE_SLICE_BASED ? "slice based" : "frame based",
+        mStartCode == V4L2_STATELESS_H264_START_CODE_ANNEX_B ? "using start-codes" : "without start-codes");
+
+    H264Decoder::setProcessRefPicLists(mDecodeMode == V4L2_STATELESS_H264_DECODE_MODE_SLICE_BASED);
+
+    return true;
+}
+
+bool V4L2H264Decoder::decode(std::unique_ptr<ConstBitstreamBuffer> buffer) {
+    return H264Decoder::decode(std::move(buffer));
+}
+
+void V4L2H264Decoder::flushInternal() {
+    H264Decoder::flush();
+}
+
+bool V4L2H264Decoder::drainInternal() {
+    return H264Decoder::drain();
+}
+
+void V4L2H264Decoder::fillSequence(const H264SPS &sps) {
+    mSPS = (struct v4l2_ctrl_h264_sps) {
+        .profile_idc = sps.profileIDC,
+        .constraint_set_flags = static_cast<uint8_t>((sps.constraintSet0Flag) |
+            (sps.constraintSet1Flag << 1) | (sps.constraintSet2Flag << 2) |
+            (sps.constraintSet3Flag << 3) | (sps.constraintSet4Flag << 4) |
+            (sps.constraintSet5Flag << 5)),
+        .level_idc = sps.levelIDC,
+        .seq_parameter_set_id = static_cast<uint8_t>(sps.id),
+        .chroma_format_idc = sps.chromaFormatIDC,
+        .bit_depth_luma_minus8 = sps.bitDepthLumaMinus8,
+        .bit_depth_chroma_minus8 = sps.bitDepthChromaMinus8,
+        .log2_max_frame_num_minus4 = sps.log2MaxFrameNumMinus4,
+        .pic_order_cnt_type = sps.picOrderCntType,
+        .log2_max_pic_order_cnt_lsb_minus4 = sps.log2MaxPicOrderCntLSBMinus4,
+        .max_num_ref_frames = static_cast<uint8_t>(sps.numRefFrames),
+        .num_ref_frames_in_pic_order_cnt_cycle = sps.numRefFramesInPicOrderCntCycle,
+        .offset_for_non_ref_pic = sps.offsetForNonRefPic,
+        .offset_for_top_to_bottom_field = sps.offsetForTopToBottomField,
+        .pic_width_in_mbs_minus1 = static_cast<uint16_t>(sps.picWidthInMBSMinus1),
+        .pic_height_in_map_units_minus1 = static_cast<uint16_t>(sps.picHeightInMapUnitsMinus1),
+        .flags = static_cast<uint32_t>((sps.separateColourPlaneFlag ? V4L2_H264_SPS_FLAG_SEPARATE_COLOUR_PLANE : 0) |
+            (sps.qpprimeYZeroTransformBypassFlag ? V4L2_H264_SPS_FLAG_QPPRIME_Y_ZERO_TRANSFORM_BYPASS : 0) |
+            (sps.deltaPicOrderAlwaysZeroFlag ? V4L2_H264_SPS_FLAG_DELTA_PIC_ORDER_ALWAYS_ZERO : 0) |
+            (sps.gapsInFrameNumValueAllowedFlag ? V4L2_H264_SPS_FLAG_GAPS_IN_FRAME_NUM_VALUE_ALLOWED : 0) |
+            (sps.frameMBSOnlyFlag ? V4L2_H264_SPS_FLAG_FRAME_MBS_ONLY : 0) |
+            (sps.mbAdaptiveFrameFieldFlag ? V4L2_H264_SPS_FLAG_MB_ADAPTIVE_FRAME_FIELD : 0) |
+            (sps.direct8x8InferenceFlag ? V4L2_H264_SPS_FLAG_DIRECT_8X8_INFERENCE : 0)),
+    };
+
+    for (int i = 0; i < sps.numRefFramesInPicOrderCntCycle; ++i)
+        mSPS.offset_for_ref_frame[i] = sps.offsetForRefFrame[i];
+}
+
+void V4L2H264Decoder::fillPPS(H264PPS *pps) {
+    mPPS = (struct v4l2_ctrl_h264_pps) {
+        .pic_parameter_set_id = static_cast<uint8_t>(pps->id),
+        .seq_parameter_set_id = static_cast<uint8_t>(pps->sequence->id),
+        .num_slice_groups_minus1 = static_cast<uint8_t>(pps->numSliceGroupsMinus1),
+        .num_ref_idx_l0_default_active_minus1 = pps->numRefIdxL0ActiveMinus1,
+        .num_ref_idx_l1_default_active_minus1 = pps->numRefIdxL1ActiveMinus1,
+        .weighted_bipred_idc = pps->weightedBipredIDC,
+        .pic_init_qp_minus26 = pps->picInitQPMinus26,
+        .pic_init_qs_minus26 = pps->picInitQSMinus26,
+        .chroma_qp_index_offset = pps->chromaQPIndexOffset,
+        .second_chroma_qp_index_offset = pps->secondChromaQPIndexOffset,
+        .flags = static_cast<uint16_t>(0
+            | (pps->entropyCodingModeFlag ? V4L2_H264_PPS_FLAG_ENTROPY_CODING_MODE : 0)
+            | (pps->picOrderPresentFlag ? V4L2_H264_PPS_FLAG_BOTTOM_FIELD_PIC_ORDER_IN_FRAME_PRESENT : 0)
+            | (pps->weightedPredFlag ? V4L2_H264_PPS_FLAG_WEIGHTED_PRED : 0)
+            | (pps->deblockingFilterControlPresentFlag ? V4L2_H264_PPS_FLAG_DEBLOCKING_FILTER_CONTROL_PRESENT : 0)
+            | (pps->constrainedIntraPredFlag ? V4L2_H264_PPS_FLAG_CONSTRAINED_INTRA_PRED : 0)
+            | (pps->redundantPicCntPresentFlag ? V4L2_H264_PPS_FLAG_REDUNDANT_PIC_CNT_PRESENT : 0)
+            | (pps->transform8x8ModeFlag ? V4L2_H264_PPS_FLAG_TRANSFORM_8X8_MODE : 0)
+            | (mScalingMatrixPresent ? V4L2_H264_PPS_FLAG_SCALING_MATRIX_PRESENT : 0)),
+    };
+}
+
+static const uint8_t zigzag4x4[16] = {
+    0, 1, 4, 8,
+    5, 2, 3, 6,
+    9, 12, 13, 10,
+    7, 11, 14, 15,
+};
+
+static const uint8_t zigzag8x8[64] = {
+    0, 1, 8, 16, 9, 2, 3, 10,
+    17, 24, 32, 25, 18, 11, 4, 5,
+    12, 19, 26, 33, 40, 48, 41, 34,
+    27, 20, 13, 6, 7, 14, 21, 28,
+    35, 42, 49, 56, 57, 50, 43, 36,
+    29, 22, 15, 23, 30, 37, 44, 51,
+    58, 59, 52, 45, 38, 31, 39, 46,
+    53, 60, 61, 54, 47, 55, 62, 63
+};
+
+void V4L2H264Decoder::fillScallingMatrix(H264PPS *pps) {
+    for (int i = 0; i < N_ELEMENTS(pps->scalingLists4x4); ++i) {
+        uint8_t *out = mScalingMatrix.scaling_list_4x4[i];
+        uint8_t *src = pps->scalingLists4x4[i];
+        for (int j = 0; j < 16; ++j)
+            out[zigzag4x4[j]] = src[j];
+    }
+
+    /* Avoid uninitialize data passed into ioctl() */
+    memset(mScalingMatrix.scaling_list_8x8, 0, sizeof(mScalingMatrix.scaling_list_8x8));
+
+    /* We need the first 2 entries (Y intra and Y inter for YCbCr 4:2:2 and
+     * less, and the full 6 entries for 4:4:4, see Table 7-2 of the spec for
+     * more details */
+    int n = (pps->sequence->chromaFormatIDC == 3) ? 6 : 2;
+    for (int i = 0; i < n; ++i) {
+        uint8_t *out = mScalingMatrix.scaling_list_8x8[i];
+        uint8_t *src = pps->scalingLists8x8[i];
+        for (int j = 0; j < 64; ++j) {
+            out[zigzag8x8[j]] = src[j];
+        }
+    }
+}
+
+void V4L2H264Decoder::fillDecoderParams(const H264SliceHdr &sliceHdr,
+        const H264PicturePtr &picture, const H264DPB &dpb) {
+    mDecodeParams = (struct v4l2_ctrl_h264_decode_params) {
+        .nal_ref_idc = static_cast<uint16_t>(picture->nalRefIDC),
+        .frame_num = sliceHdr.frameNum,
+        .idr_pic_id = sliceHdr.idrPicId,
+        .pic_order_cnt_lsb = sliceHdr.picOrderCntLSB,
+        .delta_pic_order_cnt_bottom = sliceHdr.deltaPicOrderCntBottom,
+        .delta_pic_order_cnt0 = sliceHdr.deltaPicOrderCnt[0],
+        .delta_pic_order_cnt1 = sliceHdr.deltaPicOrderCnt[1],
+        .dec_ref_pic_marking_bit_size = sliceHdr.decRefPicMarking.bitSize,
+        .pic_order_cnt_bit_size = sliceHdr.picOrderCntBitSize,
+        .slice_group_change_cycle = sliceHdr.sliceGroupChangeCycle,
+        .flags = static_cast<uint32_t>((picture->idr ? V4L2_H264_DECODE_PARAM_FLAG_IDR_PIC : 0) |
+            (sliceHdr.fieldPicFlag ? V4L2_H264_DECODE_PARAM_FLAG_FIELD_PIC : 0) |
+            (sliceHdr.bottomFieldFlag ? V4L2_H264_DECODE_PARAM_FLAG_BOTTOM_FIELD : 0)),
+    };
+
+    switch (picture->field) {
+    case H264Picture::Frame:
+        mDecodeParams.top_field_order_cnt = picture->topFieldOrderCnt;
+        mDecodeParams.bottom_field_order_cnt = picture->bottomFieldOrderCnt;
+        break;
+    case H264Picture::Top:
+        mDecodeParams.top_field_order_cnt = picture->topFieldOrderCnt;
+        mDecodeParams.bottom_field_order_cnt = 0;
+        if (picture->otherField)
+            mDecodeParams.bottom_field_order_cnt = picture->otherField->bottomFieldOrderCnt;
+        break;
+    case H264Picture::Bottom:
+        mDecodeParams.top_field_order_cnt = 0;
+        if (picture->otherField)
+            mDecodeParams.top_field_order_cnt = picture->otherField->topFieldOrderCnt;
+        mDecodeParams.bottom_field_order_cnt = picture->bottomFieldOrderCnt;
+        break;
+    }
+
+
+    int entryId = 0;
+    std::list<H264PicturePtr> refs = dpb.getPicturesAll();
+    for (const H264PicturePtr &refPic : refs) {
+        int picNum = refPic->picNum;
+        int frameNum = refPic->frameNum;
+
+        /* Skip non-reference as they are not useful to decoding */
+        if (refPic->ref == H264Picture::None)
+            continue;
+
+        /* The second field picture will be handled differently */
+        if (refPic->secondField)
+            continue;
+
+        /* V4L2 uAPI uses pic_num for both PicNum and LongTermPicNum, and
+         * frame_num for both FrameNum and LongTermFramIdx */
+        if (refPic->ref == H264Picture::LongTerm) {
+            picNum = refPic->longTermPicNum;
+        }
+
+        struct v4l2_h264_dpb_entry *entry = &mDecodeParams.dpb[entryId++];
+
+        *entry = (struct v4l2_h264_dpb_entry) {
+            /*
+             * The reference is multiplied by 1000 because it's was set as micro
+             * seconds and this TS is nanosecod.
+             */
+            .reference_ts = refPic->systemFrameNumber * 1000,
+            .frame_num = static_cast<uint16_t>(frameNum),
+            .pic_num = static_cast<uint32_t>(picNum),
+            .flags = static_cast<uint32_t>(V4L2_H264_DPB_ENTRY_FLAG_VALID |
+                (refPic->ref != H264Picture::None ? V4L2_H264_DPB_ENTRY_FLAG_ACTIVE : 0) |
+                (refPic->ref == H264Picture::LongTerm ? V4L2_H264_DPB_ENTRY_FLAG_LONG_TERM : 0) |
+                (refPic->fieldPicFlag ? V4L2_H264_DPB_ENTRY_FLAG_FIELD : 0)),
+        };
+
+        switch (refPic->field) {
+        case H264Picture::Frame:
+            entry->top_field_order_cnt = refPic->topFieldOrderCnt;
+            entry->bottom_field_order_cnt = refPic->bottomFieldOrderCnt;
+            entry->fields = V4L2_H264_FRAME_REF;
+            break;
+        case H264Picture::Top:
+            entry->top_field_order_cnt = refPic->topFieldOrderCnt;
+            entry->fields = V4L2_H264_TOP_FIELD_REF;
+
+            if (refPic->otherField) {
+                entry->bottom_field_order_cnt = refPic->otherField->bottomFieldOrderCnt;
+                entry->fields |= V4L2_H264_BOTTOM_FIELD_REF;
+            }
+            break;
+        case H264Picture::Bottom:
+            entry->bottom_field_order_cnt = refPic->bottomFieldOrderCnt;
+            entry->fields = V4L2_H264_BOTTOM_FIELD_REF;
+
+            if (refPic->otherField) {
+                entry->top_field_order_cnt = refPic->otherField->topFieldOrderCnt;
+                entry->fields |= V4L2_H264_TOP_FIELD_REF;
+            }
+            break;
+        }
+    }
+}
+
+bool V4L2H264Decoder::newSequence(const H264SPS &sps, int maxDPBSize) {
+    ALOGV("%s()", __func__);
+    bool negotiationNeeded = false;
+
+    /* TODO check if CREATE_BUFS is supported, and simply grow the pool */
+    if (mMinPoolSize < maxDPBSize) {
+        mMinPoolSize = maxDPBSize;
+        negotiationNeeded = true;
+    }
+
+    int cropWidth = sps.width;
+    int cropHeight = sps.height;
+    if (sps.frameCroppingFlag) {
+        cropWidth = sps.cropRectWidth;
+        cropHeight = sps.cropRectHeight;
+    }
+
+    /* TODO Check if current buffers are large enough, and reuse them */
+    if (mDisplayWidth != cropWidth || mDisplayHeight != cropHeight ||
+            mCodedWidth != sps.width || mCodedHeight != sps.height) {
+        mDisplayWidth = cropWidth;
+        mDisplayHeight = cropHeight;
+        mCodedWidth = sps.width;
+        mCodedHeight = sps.height;
+        negotiationNeeded = true;
+        ALOGI("Resolution changed to %dx%d (%ix%i)",
+                mDisplayWidth, mDisplayHeight,
+                mCodedWidth, mCodedHeight);
+    }
+
+    bool interlaced = !sps.frameMBSOnlyFlag;
+    if (mInterlaced != interlaced) {
+        mInterlaced = interlaced;
+        negotiationNeeded = true;
+        ALOGI("Interlaced mode changed to %d", interlaced);
+    }
+
+    if (mBitdepth != sps.bitDepthLumaMinus8 + 8) {
+        mBitdepth = sps.bitDepthLumaMinus8 + 8;
+        negotiationNeeded = true;
+        ALOGI("Bitdepth changed to %u", mBitdepth);
+    }
+
+    if (mChromaFormatIDC != sps.chromaFormatIDC) {
+        mChromaFormatIDC = sps.chromaFormatIDC;
+        negotiationNeeded = true;
+        ALOGI("Chroma format changed to %i", mChromaFormatIDC);
+    }
+
+    fillSequence(sps);
+    mNeedSequence = true;
+
+    if (negotiationNeeded) {
+        if (!negotiate()) {
+            ALOGE("Failed to negotiate");
+            return false;
+        }
+    }
+
+    return true;
+}
+
+bool V4L2H264Decoder::negotiate() {
+    std::vector<V4L2ExtCtrl> controls;
+    struct v4l2_ext_control control = { };
+    control.id = V4L2_CID_STATELESS_H264_SPS;
+    control.ptr = &mSPS;
+    control.size = sizeof(mSPS);
+    controls.push_back(V4L2ExtCtrl(control));
+
+    return changeResolution(ui::Size(mCodedWidth, mCodedHeight), controls);
+}
+
+bool V4L2H264Decoder::newFieldPicture(const H264PicturePtr &firstField,
+        const H264PicturePtr &secondField) {
+    if (firstField->userData) {
+        ALOGW("First picture does not have an associated request");
+        return true;
+    }
+
+    ALOGD("Assigned request %p to second field.", firstField->userData.get());
+
+    /* Associate the previous request with the new picture so that
+     * submit_bitstream can create sub-request */
+    secondField->userData = firstField->userData;
+
+    return true;
+}
+
+bool V4L2H264Decoder::startPicture(const H264PicturePtr &picture,
+        const H264Slice &slice, const H264DPB &dpb) {
+    if (!V4L2Decoder::ensureInputBuffer())
+        return false;
+
+    /* Scaling matrix is present if there's one provided by either the SPS or
+     * the PPS. This flag must be set to true or false, before filling the PPS
+     * V4L2 control.
+     */
+    mScalingMatrixPresent =
+        slice.header.pps->sequence->scalingMatrixPresentFlag ||
+        slice.header.pps->picScalingMatrixPresentFlag;
+
+    fillPPS(slice.header.pps);
+
+    if (mScalingMatrixPresent)
+        fillScallingMatrix(slice.header.pps);
+
+    fillDecoderParams(slice.header, picture, dpb);
+
+    mFirstSlice = true;
+    mSliceParams.clear();
+
+    return true;
+}
+
+bool V4L2H264Decoder::submitBitstream(const H264PicturePtr &picture, unsigned int flags) {
+    std::vector<V4L2ExtCtrl> controls;
+    struct v4l2_ext_control control = { };
+    if (mNeedSequence) {
+        control.id = V4L2_CID_STATELESS_H264_SPS;
+        control.ptr = &mSPS;
+        control.size = sizeof(mSPS);
+        controls.push_back(V4L2ExtCtrl(control));
+        mNeedSequence = false;
+    }
+
+    if (mFirstSlice) {
+        control.id = V4L2_CID_STATELESS_H264_PPS;
+        control.ptr = &mPPS;
+        control.size = sizeof(mPPS);
+        controls.push_back(V4L2ExtCtrl(control));
+
+        if (mScalingMatrixPresent) {
+            control.id = V4L2_CID_STATELESS_H264_SCALING_MATRIX;
+            control.ptr = &mScalingMatrix;
+            control.size = sizeof(mScalingMatrix);
+            controls.push_back(V4L2ExtCtrl(control));
+        }
+
+        control.id = V4L2_CID_STATELESS_H264_DECODE_PARAMS;
+        control.ptr = &mDecodeParams;
+        control.size = sizeof(mDecodeParams);
+        controls.push_back(V4L2ExtCtrl(control));
+
+        mFirstSlice = false;
+    }
+
+    /* If it's not slice-based then it doesn't support per-slice controls. */
+    if (mDecodeMode == V4L2_STATELESS_H264_DECODE_MODE_SLICE_BASED) {
+        control.id = V4L2_CID_STATELESS_H264_SLICE_PARAMS;
+        control.ptr = mSliceParams.data();
+        control.size = sizeof(struct v4l2_ctrl_h264_slice_params) *
+            mSliceParams.size();
+        controls.push_back(V4L2ExtCtrl(control));
+
+        control.id = V4L2_CID_STATELESS_H264_PRED_WEIGHTS;
+        control.ptr = &mPredWeight;
+        control.size = sizeof(mPredWeight);
+        controls.push_back(V4L2ExtCtrl(control));
+    }
+
+    RequestHandle request;
+    if (picture->userData)
+        request = V4L2Decoder::allocSubRequest(picture->userData);
+    else
+        request = V4L2Decoder::allocRequest(picture->systemFrameNumber);
+
+    picture->userData = nullptr;
+
+    /* Keep a reference to hold the decoded data until it is not used anymore */
+    if (request)
+        picture->userData = V4L2Decoder::submitRequest(request, controls, flags);
+    else
+        ALOGE("%s() cannot allocate request", __func__);
+
+    resetPicture();
+
+    return picture->userData != nullptr;
+}
+
+void V4L2H264Decoder::resetPicture() {
+    mSliceParams.clear();
+}
+
+static unsigned int getSliceHeaderBitSize(const H264Slice &slice) {
+    return 8 * slice.nalu.headerBytes + slice.header.headerSize -
+            8 * slice.header.nEmulationPreventionBytes;
+}
+
+void V4L2H264Decoder::fillSliceParams(const H264Slice &slice) {
+    struct v4l2_ctrl_h264_slice_params params = {
+        .header_bit_size = getSliceHeaderBitSize(slice),
+        .first_mb_in_slice = slice.header.firstMBInSlice,
+        .slice_type = static_cast<uint8_t>(slice.header.type % 5),
+        .colour_plane_id = slice.header.colourPlaneId,
+        .redundant_pic_cnt = slice.header.redundantPicCnt,
+        .cabac_init_idc = slice.header.cabacInitIDC,
+        .slice_qp_delta = slice.header.sliceQPDelta,
+        .slice_qs_delta = slice.header.sliceQSDelta,
+        .disable_deblocking_filter_idc = slice.header.disableDeblockingFilterIDC,
+        .slice_alpha_c0_offset_div2 = slice.header.sliceAlphaC0OffsetDiv2,
+        .slice_beta_offset_div2 = slice.header.sliceBetaOffsetDiv2,
+        .num_ref_idx_l0_active_minus1 = slice.header.numRefIdxL0ActiveMinus1,
+        .num_ref_idx_l1_active_minus1 = slice.header.numRefIdxL1ActiveMinus1,
+        .flags = static_cast<uint32_t>((slice.header.directSpatialMVPredFlag ? V4L2_H264_SLICE_FLAG_DIRECT_SPATIAL_MV_PRED : 0) |
+                    (slice.header.spForSwitchFlag ? V4L2_H264_SLICE_FLAG_SP_FOR_SWITCH : 0)),
+    };
+
+    mSliceParams.push_back(std::move(params));
+}
+
+void V4L2H264Decoder::fillPredWeight(const H264SliceHdr &sliceHdr) {
+    mPredWeight = (struct v4l2_ctrl_h264_pred_weights) {
+        .luma_log2_weight_denom = sliceHdr.predWeightTable.lumaLog2WeightDenom,
+        .chroma_log2_weight_denom = sliceHdr.predWeightTable.chromaLog2WeightDenom,
+    };
+
+    for (int i = 0; i <= sliceHdr.numRefIdxL0ActiveMinus1; ++i) {
+        mPredWeight.weight_factors[0].luma_weight[i] =
+            sliceHdr.predWeightTable.lumaWeightL0[i];
+        mPredWeight.weight_factors[0].luma_offset[i] =
+            sliceHdr.predWeightTable.lumaOffsetL0[i];
+    }
+
+    if (sliceHdr.pps->sequence->chromaArrayType != 0) {
+        for (int i = 0; i < sliceHdr.numRefIdxL0ActiveMinus1; ++i) {
+            for (int j = 0; j < 2; ++j) {
+                mPredWeight.weight_factors[0].chroma_weight[i][j] =
+                    sliceHdr.predWeightTable.chromaWeightL0[i][j];
+                mPredWeight.weight_factors[0].chroma_offset[i][j] =
+                    sliceHdr.predWeightTable.chromaOffsetL0[i][j];
+            }
+        }
+    }
+
+    /* Skip l1 if this is not a B-Frames. */
+    if (sliceHdr.type % 5 != H264SliceHdr::B)
+        return;
+
+    for (int i = 0; i < sliceHdr.numRefIdxL1ActiveMinus1; ++i) {
+        mPredWeight.weight_factors[1].luma_weight[i] =
+            sliceHdr.predWeightTable.lumaWeightL1[i];
+        mPredWeight.weight_factors[1].luma_offset[i] =
+            sliceHdr.predWeightTable.lumaOffsetL1[i];
+    }
+
+    if (sliceHdr.pps->sequence->chromaArrayType != 0) {
+        for (int i = 0; i < sliceHdr.numRefIdxL1ActiveMinus1; ++i) {
+            for (int j = 0; j < 2; ++j) {
+                mPredWeight.weight_factors[1].chroma_weight[i][j] =
+                    sliceHdr.predWeightTable.chromaWeightL1[i][j];
+                mPredWeight.weight_factors[1].chroma_offset[i][j] =
+                    sliceHdr.predWeightTable.chromaOffsetL1[i][j];
+            }
+        }
+    }
+}
+
+static uint8_t lookupDPBIndex(struct v4l2_h264_dpb_entry dpb[16],
+                              H264PicturePtr refPic) {
+    /* Reference list may have wholes in case a ref is missing, we should mark
+     * the whole and avoid moving items in the list */
+    if (!refPic)
+        return 0xff;
+
+    /* DPB entries only stores first field in a merged fashion */
+    if (refPic->secondField && refPic->otherField)
+        refPic = refPic->otherField;
+
+    uint64_t refTs = refPic->systemFrameNumber * 1000;
+    for (int i = 0; i < 16; ++i) {
+        if (dpb[i].flags & V4L2_H264_DPB_ENTRY_FLAG_ACTIVE &&
+                dpb[i].reference_ts == refTs) {
+            return i;
+        }
+    }
+
+    return 0xff;
+}
+
+static unsigned int getV4L2FieldsRef(const H264PicturePtr &refPic, bool merge) {
+    if (merge && refPic->otherField)
+        return V4L2_H264_FRAME_REF;
+
+    switch (refPic->field) {
+    case H264Picture::Frame:
+        return V4L2_H264_FRAME_REF;
+    case H264Picture::Top:
+        return V4L2_H264_TOP_FIELD_REF;
+    case H264Picture::Bottom:
+        return V4L2_H264_BOTTOM_FIELD_REF;
+    }
+
+    return V4L2_H264_FRAME_REF;
+}
+
+void V4L2H264Decoder::fillReferences(bool curIsFrame,
+        const std::list<H264PicturePtr> &refPicList0,
+        const std::list<H264PicturePtr> &refPicList1) {
+
+    struct v4l2_ctrl_h264_slice_params &sliceParams = mSliceParams.front();
+
+    memset(sliceParams.ref_pic_list0, 0xff, sizeof(sliceParams.ref_pic_list0));
+    memset(sliceParams.ref_pic_list1, 0xff, sizeof(sliceParams.ref_pic_list1));
+
+    int i = 0;
+    for (auto it = refPicList0.cbegin(); it != refPicList0.cend(); ++i, ++it) {
+        sliceParams.ref_pic_list0[i].index = lookupDPBIndex(mDecodeParams.dpb, *it);
+        sliceParams.ref_pic_list0[i].fields = getV4L2FieldsRef(*it, curIsFrame);
+    }
+
+    i = 0;
+    for (auto it = refPicList1.cbegin(); it != refPicList1.cend(); ++i, ++it) {
+        sliceParams.ref_pic_list1[i].index = lookupDPBIndex(mDecodeParams.dpb, *it);
+        sliceParams.ref_pic_list1[i].fields = getV4L2FieldsRef(*it, curIsFrame);
+    }
+}
+
+bool V4L2H264Decoder::decodeSlice(const H264PicturePtr &picture,
+        const H264Slice &slice, const std::list<H264PicturePtr> &refPicList0,
+        const std::list<H264PicturePtr> &refPicList1) {
+    if (mDecodeMode == V4L2_STATELESS_H264_DECODE_MODE_SLICE_BASED) {
+        if (mInputBuffer->getPlaneBytesUsed(0) != 0) {
+            /* In slice mode, we submit the pending slice asking the accelerator
+             * to hold on the picture */
+            if (!submitBitstream(picture, V4L2_BUF_FLAG_M2M_HOLD_CAPTURE_BUF) ||
+                    !V4L2Decoder::ensureInputBuffer())
+                return false;
+        }
+
+        fillSliceParams(slice);
+        fillPredWeight(slice.header);
+        fillReferences(picture->field == H264Picture::Frame, refPicList0, refPicList1);
+    }
+
+    uint8_t *plane = reinterpret_cast<uint8_t *>(mInputBuffer->getPlaneMapping(0));
+    if (!plane)
+        return false;
+
+    size_t scOff = 0;
+    if (mStartCode == V4L2_STATELESS_H264_START_CODE_ANNEX_B)
+        scOff = 3;
+    size_t nalSize = scOff + slice.nalu.size;
+
+    int byteUsed = mInputBuffer->getPlaneBytesUsed(0);
+    if (byteUsed + nalSize > mInputBuffer->getPlaneSize(0)) {
+        ALOGE("Not enough space to send all slice of an H264 frame.");
+        return false;
+    }
+
+    uint8_t *bitstreamData = plane + byteUsed;
+    if (mStartCode == V4L2_STATELESS_H264_START_CODE_ANNEX_B) {
+        bitstreamData[0] = 0x00;
+        bitstreamData[1] = 0x00;
+        bitstreamData[2] = 0x01;
+    }
+
+    memcpy(bitstreamData + scOff, slice.nalu.data + slice.nalu.offset, slice.nalu.size);
+    mInputBuffer->setPlaneBytesUsed(0, byteUsed + nalSize);
+
+/* FIXME: add this line with newer kernel version
+    switch (slice.header.type % 5) {
+    case H264SliceHdr::P:
+        mDecodeParams.flags |= V4L2_H264_DECODE_PARAM_FLAG_PFRAME;
+        break;
+    case H264SliceHdr::B:
+        mDecodeParams.flags |= V4L2_H264_DECODE_PARAM_FLAG_BFRAME;
+        break;
+    }
+*/
+
+    return true;
+}
+
+bool V4L2H264Decoder::endPicture(const H264PicturePtr &picture) {
+    unsigned int flags = 0;
+
+    /* Hold on the output frame if this is first field of a pair */
+    if (picture->field != H264Picture::Frame && !picture->secondField)
+        flags = V4L2_BUF_FLAG_M2M_HOLD_CAPTURE_BUF;
+
+    if (!submitBitstream(picture, flags))
+        return false;
+
+    return true;
+}
+
+bool V4L2H264Decoder::outputPicture(const H264PicturePtr &picture) {
+    ALOGV("Output picture (frame_num %u, poc %u)", picture->frameNum, picture->picOrderCnt);
+
+    V4L2Decoder::finish(picture->systemFrameNumber);
+
+    return true;
+}
+
+unsigned int V4L2H264Decoder::getPreferredOutputDelay(bool live) {
+    unsigned int delay;
+
+    if (live)
+        delay = 0;
+    else
+        delay = 1;
+
+    return delay;
+}
+
+}  // namespace android
diff --git a/components/h264/parser/H264DPB.cpp b/components/h264/parser/H264DPB.cpp
new file mode 100644
index 0000000..3a44098
--- /dev/null
+++ b/components/h264/parser/H264DPB.cpp
@@ -0,0 +1,731 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * GStreamer
+ * Copyright (C) 2019 Seungha Yang <seungha.yang@navercorp.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "H264DPB"
+
+#include <v4l2_codec2/components/h264/parser/H264DPB.h>
+
+#include <log/log.h>
+
+#include <limits>
+
+namespace android {
+
+H264DPB::H264DPB()
+    : mNumOutputNeeded(0),
+      mLastOutputPoc(std::numeric_limits<int32_t>::min()),
+      mLastOutputNonRef(false)
+{ }
+
+void H264DPB::setMaxNumFrames(int maxNumFrames) {
+    mMaxNumFrames = maxNumFrames;
+}
+
+int H264DPB::getMaxNumFrames() const {
+    return mMaxNumFrames;
+}
+
+void H264DPB::setInterlaced(bool interlaced) {
+    mInterlaced = interlaced;
+}
+
+bool H264DPB::getInterlaced() const {
+    return mInterlaced;
+}
+
+int32_t H264DPB::getLastOutputPoc() const {
+    return mLastOutputPoc;
+}
+
+void H264DPB::clear() {
+    mPicList.clear();
+    mNumOutputNeeded = 0;
+    mLastOutputPoc = std::numeric_limits<int32_t>::min();
+    mLastOutputNonRef = false;
+}
+
+void H264DPB::setMaxNumReorderFrames(uint32_t maxNumReorderFrames) {
+    mMaxNumReorderFrames = maxNumReorderFrames;
+}
+
+uint32_t H264DPB::getMaxNumReorderFrames() const {
+    return mMaxNumReorderFrames;
+}
+
+void H264DPB::add(const H264PicturePtr &picture) {
+    /* C.4.2 Decoding of gaps in frame_num and storage of "non-existing" pictures
+     *
+     * The "non-existing" frame is stored in an empty frame buffer and is marked
+     * as "not needed for output", and the DPB fullness is incremented by one */
+    if (!picture->nonexisting) {
+        picture->neededForOutput = true;
+
+        if (picture->field == H264Picture::Frame) {
+            mNumOutputNeeded++;
+        } else {
+            /* We can do output only when filed pair are complete */
+            if (picture->secondField) {
+                mNumOutputNeeded++;
+            }
+        }
+    } else {
+        picture->neededForOutput = false;
+    }
+
+    /* Link each field */
+    if (picture->secondField && picture->otherField) {
+        picture->otherField->otherField = picture;
+    }
+
+    mPicList.push_back(picture);
+
+    if (mPicList.size() > mMaxNumFrames * (mInterlaced + 1)) {
+        ALOGE("DPB size is %zu; exceed the max size %d",
+                mPicList.size(), mMaxNumFrames * (mInterlaced + 1));
+    }
+
+    /* The IDR frame or mem_mgmt_5 */
+    if (picture->picOrderCnt == 0) {
+        ALOGD("last_output_poc reset because of IDR or mem_mgmt_5");
+        mLastOutputPoc = std::numeric_limits<int32_t>::min();
+        mLastOutputNonRef = false;
+    }
+}
+
+void H264DPB::deleteUnused() {
+    for (auto it = mPicList.begin(); it != mPicList.end();) {
+        std::shared_ptr<H264Picture> picture = *it;
+
+        if (!picture->neededForOutput && picture->ref == H264Picture::None) {
+            ALOGD("remove picture %p (frame num: %d, poc: %d, field: %d) from dpb",
+                picture.get(), picture->frameNum, picture->picOrderCnt, picture->field);
+            it = mPicList.erase(it);
+        } else {
+            ++it;
+        }
+    }
+}
+
+int H264DPB::numRefFrames() const {
+    int ret = 0;
+
+    for (auto it = mPicList.cbegin(); it != mPicList.cend(); ++it) {
+        std::shared_ptr<H264Picture> picture = *it;
+
+        /* Count frame, not field picture */
+        if (picture->secondField)
+            continue;
+
+        if (picture->ref != H264Picture::None)
+            ++ret;
+    }
+
+    return ret;
+}
+
+void H264DPB::markAllNonRef() {
+    for (auto it = mPicList.begin(); it != mPicList.end(); ++it) {
+        const std::shared_ptr<H264Picture> &picture = *it;
+
+        picture->setReference(H264Picture::None, false);
+    }
+}
+
+std::shared_ptr<H264Picture> H264DPB::getShortRefByPicNum(int picNum) const {
+    for (auto it = mPicList.cbegin(); it != mPicList.cend(); ++it) {
+        std::shared_ptr<H264Picture> picture = *it;
+
+        if (picture->ref == H264Picture::ShortTerm && picture->picNum == picNum)
+            return picture;
+    }
+
+    ALOGW("No short term reference picture for %d", picNum);
+
+    return nullptr;
+}
+
+std::shared_ptr<H264Picture> H264DPB::getLongRefByLongTermPicNum(int longTermPicNum) const {
+    for (auto it = mPicList.cbegin(); it != mPicList.cend(); ++it) {
+        const std::shared_ptr<H264Picture> &picture = *it;
+
+        if (picture->ref == H264Picture::LongTerm &&
+                picture->longTermPicNum == longTermPicNum) {
+            return picture;
+        }
+    }
+
+    ALOGW("No Long term reference picture for %d", longTermPicNum);
+
+    return nullptr;
+}
+
+std::shared_ptr<H264Picture> H264DPB::getLowestFrameNumShortRef() const {
+    std::shared_ptr<H264Picture> ret;
+
+    for (auto it = mPicList.cbegin(); it != mPicList.cend(); ++it) {
+        const std::shared_ptr<H264Picture> &picture = *it;
+
+        if (picture->ref == H264Picture::ShortTerm &&
+                (!ret || picture->frameNumWrap < ret->frameNumWrap)) {
+            ret = picture;
+        }
+    }
+
+    return ret;
+}
+
+void H264DPB::getPicturesShortTermRef(bool includeNonExisting,
+                                      bool includeSecondField,
+                                      std::list<H264PicturePtr> &out) const {
+    for (auto it = mPicList.cbegin(); it != mPicList.cend(); ++it) {
+        const H264PicturePtr &picture = *it;
+
+        if (!includeSecondField && picture->secondField)
+            continue;
+
+        if (picture->ref == H264Picture::ShortTerm &&
+                (includeNonExisting ||
+                    (!includeNonExisting && !picture->nonexisting))) {
+            out.push_back(picture);
+        }
+    }
+}
+
+void H264DPB::getPicturesLongTermRef(bool includeSecondField,
+                                     std::list<H264PicturePtr> &out) const {
+    for (auto it = mPicList.cbegin(); it != mPicList.cend(); ++it) {
+        const H264PicturePtr &picture = *it;
+
+        if (!includeSecondField && picture->secondField)
+            continue;
+
+        if (picture->ref == H264Picture::LongTerm)
+            out.push_back(picture);
+    }
+}
+
+const std::list<H264PicturePtr> &H264DPB::getPicturesAll() const {
+    return mPicList;
+}
+
+int H264DPB::getSize() const {
+    return mPicList.size();
+}
+
+std::shared_ptr<H264Picture> H264DPB::getPicture(uint32_t systemFrameNumber) const {
+    for (auto it = mPicList.cbegin(); it != mPicList.cend(); ++it) {
+
+        const std::shared_ptr<H264Picture> &picture = *it;
+        if (picture->systemFrameNumber == systemFrameNumber)
+            return picture;
+    }
+
+    return nullptr;
+}
+
+
+bool H264DPB::hasEmptyFrameBuffer() const {
+    if (!mInterlaced) {
+        if (mPicList.size() < mMaxNumFrames)
+            return true;
+    } else {
+        int count = 0;
+
+        for (auto it = mPicList.cbegin(); it != mPicList.cend(); ++it) {
+            std::shared_ptr<H264Picture> picture = *it;
+
+            if (picture->secondField)
+                continue;
+
+            if (picture->field == H264Picture::Frame || picture->otherField)
+                ++count;
+        }
+
+        if (count < mMaxNumFrames)
+            return true;
+    }
+
+    return false;
+}
+
+int H264DPB::getLowestOutputNeededPicture(bool force,
+        H264PicturePtr &picture,
+        std::list<H264PicturePtr>::const_iterator *picIt) const {
+    std::shared_ptr<H264Picture> lowest;
+    int index = -1;
+
+    int i = 0;
+    for (auto it = mPicList.cbegin(); it != mPicList.cend(); ++it, ++i) {
+        std::shared_ptr<H264Picture> pic = *it;
+
+        if (!force && !pic->neededForOutput)
+            continue;
+
+        if (pic->field != H264Picture::Frame &&
+            (!pic->otherField || pic->secondField)) {
+            continue;
+        }
+
+        if (!lowest) {
+            lowest = pic;
+            index = i;
+            if (picIt)
+                *picIt = it;
+            continue;
+        }
+
+        if (pic->picOrderCnt < lowest->picOrderCnt) {
+            lowest = pic;
+            index = i;
+            if (picIt)
+                *picIt = it;
+        }
+    }
+
+    if (lowest)
+        picture = lowest;
+
+    return index;
+}
+
+bool H264DPB::needsBump(const H264PicturePtr &toInsert, BumpMode latencyMode) const {
+    H264PicturePtr picture;
+    decltype(mPicList)::const_iterator picIt;
+    int32_t lowestPoc = std::numeric_limits<int32_t>::max();
+    bool isRefPicture = false;
+    int lowestIndex = getLowestOutputNeededPicture(false, picture, &picIt);
+
+    if (lowestIndex >= 0) {
+        lowestPoc = picture->picOrderCnt;
+        isRefPicture = picture->refPic;
+    } else {
+        goto normal_bump;
+    }
+
+    if (latencyMode  == LowLatency) {
+        /* If low latency, we shoudl not wait for the DPB becoming full.
+         *  We try to bump the picture as soon as possible without the frames
+         * disorder. The policy is frmo the safe to some risk. */
+
+        /* Do not support interlaced mode. */
+        if (mInterlaced)
+            goto normal_bump;
+
+        /* Equal to normal bump. */
+        if (hasEmptyFrameBuffer())
+            goto normal_bump;
+
+        /* In case of POC type 2, decoding order is equal to output order*/
+        if (picture->picOrderCntType == 2) {
+            ALOGD("POC type == 2, bumping");
+            return true;
+        }
+
+         /* 7.4.1.2.2: The values of picture order count for the coded pictures
+            in consecutive access units in decoding order containing non-reference
+            pictures shall be non-decreasing. Safe. */
+        if (mLastOutputNonRef && !isRefPicture) {
+            ALOGD("COntinious non-reference frame poc: %d -> %d,"
+                  " bumping for low-latency", mLastOutputPoc, lowestPoc);
+            return true;
+        }
+
+        /* num_reorder_frames indicates the maximum number of frames, that
+           precede any frame in the coded video sequence in decoding order
+           and follow it in output order. Safe. */
+       if (lowestIndex >= mMaxNumReorderFrames) {
+            unsigned int needOutput = 0;
+
+            for (auto it = mPicList.cbegin(); it != picIt; ++it) {
+                std::shared_ptr<H264Picture> p = *it;
+                if (p->neededForOutput)
+                    ++needOutput;
+            }
+
+            if (needOutput >= mMaxNumReorderFrames) {
+                ALOGD("frame with lowest poc %d has %d preced frame, already"
+                      " satisfy num_reorder_frames %d, bumping for low-latency.",
+                        mLastOutputPoc, lowestIndex, mMaxNumReorderFrames);
+                return true;
+            }
+       }
+
+       /* Bump leading picture with the negative POC if already found positive
+          POC. It's even impossible to insert another negative POC after the
+          positive POCs. Almost safe. */
+        if (toInsert && toInsert->picOrderCnt > 0 && lowestPoc < 0) {
+            ALOGD("The negative poc %d, bumping for low-latency.", lowestPoc);
+            return true;
+        }
+
+        /* There may be leading frames with negative POC following the IDR
+         * frame in decoder order, so when IDR comes, we need to check the
+         * following pictures In most cases, leading pictures are in increasing
+         * POC order. Bump and should be safe.*/
+        if (lowestPoc == 0 && getSize() <= 1) {
+            if (toInsert && toInsert->picOrderCnt > lowestPoc) {
+                ALOGD("The IDR or mem_mgmt_5 frame, bumping for low-latency.");
+                return true;
+            }
+
+            ALOGD("The IDR or mem_mgmt_5 frmae is not the first frame.");
+            goto normal_bump;
+        }
+
+        /* When non-ref frame has the lowest POC, it's unlike to insert another
+         * ref frame with very small POC. Bump and should be sage. */
+        if (!isRefPicture) {
+            ALOGD("non ref with lowest-poc: %d bumping for low-latency", lowestPoc);
+            return true;
+        }
+
+        /* When insert non-ref frame with bigger POC, it's unlike to insert
+         * another ref frame with very small POC. Bump and should be sage. */
+        if (toInsert && !toInsert->refPic && lowestPoc < toInsert->picOrderCnt) {
+            ALOGD("lowest-poc: %d < to insert non ref pic: %d, bumping "
+                  "for low-latency", lowestPoc, toInsert->picOrderCnt);
+            return true;
+        }
+
+        if (latencyMode >= LowLatency) {
+            /* PicOrderCnt increment by <=2. Not all streams meet this, but in
+                practice this condition can be used.
+                For stream with 2 poc increment like:
+                0(IDR), 2(P), 4(P), 6(P), 12(P), 8(B), 10(B)....
+                This can work well, but for streams with 1 poc increment like:
+                0(IDR), 2(P), 4(P), 1(B), 3(B) ...
+                This can cause picture disorder. Most stream in practice has the
+                2 poc increment, but this may have risk and be careful. */
+            if (lowestPoc > mLastOutputPoc && lowestPoc - mLastOutputPoc <= 2) {
+                ALOGD("lowest-poc: %d, last-output-poc: %d, diff <= 2 "
+                      "bumping for very-low-latency", lowestPoc, mLastOutputPoc);
+                return true;
+            }
+        }
+    }
+
+normal_bump:
+    /* C.4.5.3: The "bumping" process is invoked in the following cases.
+       - There is no empty frame buffer and a empty frame buffer is needed
+       for storage of an inferred "non-existing" frame.
+       - There is no empty frame buffer and an empty frame buffer is needed
+       for storage of a decoded (non-IDR) reference picture.
+       - There is no empty frame buffer and the current picture is a non-
+       reference picture that is not the second field of a complementary
+       non-reference field pair and there are pictures in the DPB that are
+       marked as "needed for output" that precede the current non-reference
+       picture in output order. */
+    if (hasEmptyFrameBuffer()) {
+        ALOGD("DPB has empty frame buffer, no need bumping");
+        return false;
+    }
+
+    if (toInsert && toInsert->refPic) {
+        ALOGD("No empty frame buffer for ref frame, need bumping");
+        return true;
+    }
+
+    if (toInsert && toInsert->picOrderCnt > lowestPoc) {
+        ALOGD("No empty frame buffer, lowest poc %d < current poc %d,"
+              " need bumping.", lowestPoc, toInsert->picOrderCnt);
+        return true;
+    }
+
+    if (toInsert) {
+        ALOGD("No empty frame buffer, but lowest poc %d > current poc %d,"
+              " no need bumping.", lowestPoc, toInsert->picOrderCnt);
+    }
+
+    return false;
+}
+
+std::shared_ptr<H264Picture> H264DPB::bump(bool drain) {
+    H264PicturePtr picture;
+    H264PicturePtr otherPicture;
+    decltype(mPicList)::const_iterator picIt;
+    bool outputNeeded = true;
+    int index = getLowestOutputNeededPicture(false, picture, &picIt);
+
+    /* Bumping is needed but has no output needed picture. Pick the smallest
+     * POC picture */
+    if (!picture && !drain) {
+        index = getLowestOutputNeededPicture(true, picture, &picIt);
+        if (picture)
+            outputNeeded = false;
+    }
+
+    if (!picture || index < 0)
+        return nullptr;
+
+    picture->neededForOutput = false;
+
+    if (outputNeeded)
+        --mNumOutputNeeded;
+
+    ALOG_ASSERT(mNumOutputNeeded >= 0);
+
+    if (picture->ref == H264Picture::None || drain || !outputNeeded) {
+        mPicList.erase(picIt);
+    }
+
+    otherPicture = picture->otherField;
+    if (otherPicture) {
+        otherPicture->neededForOutput = false;
+
+        /* At this moment, this picture should be interlaced */
+//        picture->bufferFlags |= Interlaced;
+
+        /* FIXME: need to check picture timing SEI for the case where top/bootom
+         * poc are identical */
+//        if (picture->picOrderCnt < otherPicture->picOrderCnt)
+//            picture->bufferFlags |= TFF;
+
+        if (!otherPicture->ref) {
+            for (auto it = mPicList.cbegin(); it != mPicList.cend(); ++it) {
+                std::shared_ptr<H264Picture> tmp = *it;
+
+                if (tmp == otherPicture) {
+                    mPicList.erase(it);
+                    break;
+                }
+            }
+        }
+        /* Now other field may or may not exist */
+    }
+
+    mLastOutputPoc = picture->picOrderCnt;
+    mLastOutputNonRef = !picture->refPic;
+
+    return picture;
+}
+
+void H264DPB::setLastOutput(const H264PicturePtr &picture) {
+    mLastOutputPoc = picture->picOrderCnt;
+    mLastOutputNonRef = !picture->refPic;
+}
+
+static int getPicNumX(const H264PicturePtr &picture,
+                      const H264RefPicMarking &refPicMarking) {
+    return picture->picNum - (refPicMarking.differenceOfPicNumsMinus1 + 1);
+}
+
+bool H264DPB::performMemoryManagementControlOperation(
+        const H264RefPicMarking &refPicMarking, const H264PicturePtr &picture) {
+    if (!picture)
+        return false;
+
+    uint8_t type = refPicMarking.memoryManagementControlOperation;
+
+    switch (type) {
+    case 0:
+        /* Normal end of operations' specification */
+        break;
+    case 1:
+    {
+        /* 8.2.5.4.1 Mark a short term reference picture as unused so it can be
+         * removed if outputted */
+        int picNumX = getPicNumX(picture, refPicMarking);
+        const H264PicturePtr &other = getShortRefByPicNum(picNumX);
+        if (other) {
+            other->setReference(H264Picture::None, picture->field == H264Picture::Frame);
+            ALOGD("MMCO-1: unmark short-term ref picture %p, (poc %d)",
+                    other.get(), other->picOrderCnt);
+        } else {
+            ALOGW("Invalid picNumX %d for operation type 1", picNumX);
+            return false;
+        }
+        break;
+    }
+    case 2:
+    {
+        /* 8.2.5.4.2 Mark a long term reference picture as unused so it can be
+         * removed if outputted */
+        const H264PicturePtr &other = getLongRefByLongTermPicNum(refPicMarking.longTermPicNum);
+        if (other) {
+            other->setReference(H264Picture::None, false);
+            ALOGD("MMCO-2: unmark long-term ref picture %p, (poc %d)",
+                    other.get(), other->picOrderCnt);
+        } else {
+            ALOGW("Invalid LongTermPicNum %d for operation type 2",
+                    refPicMarking.longTermPicNum);
+            return false;
+        }
+        break;
+    }
+    case 3:
+    {
+        /* 8.2.5.4.3 Mark a short term reference picture as long term reference */
+        int picNumX = getPicNumX(picture, refPicMarking);
+        const H264PicturePtr &other = getShortRefByPicNum(picNumX);
+        if (!other) {
+            ALOGW("Invalid picNumX %d for operation type 3", picNumX);
+            return false;
+        }
+
+        /* If we have long-term ref picture for LongTermFrameIdx, mark the
+         * picture as non-reference */
+        for (const H264PicturePtr &tmp : mPicList) {
+            if (tmp->ref == H264Picture::LongTerm &&
+                    tmp->longTermFrameIdx == refPicMarking.longTermFrameIdx) {
+                if (tmp->field == H264Picture::Frame) {
+                    /* When long_term_frame_idx is already assigned to a
+                     * long-term reference frame, that frame is marked as
+                     * "unused for reference"
+                     */
+                    tmp->setReference(H264Picture::None, true);
+                    ALOGD("MMCO-3: unmark old long-term frame %p (poc %d)",
+                            tmp.get(), tmp->picOrderCnt);
+                } else if (tmp->otherField &&
+                            tmp->otherField->field == H264Picture::LongTerm &&
+                            tmp->otherField->longTermFrameIdx ==
+                                refPicMarking.longTermFrameIdx) {
+                    /* When long_term_frame_idx is already assigned to a
+                     * long-term reference field pair, that complementary field
+                     * pair and both of its fields are markes as "unused for
+                     * reference"
+                     */
+                    tmp->setReference(H264Picture::None, true);
+                    ALOGD("MMCO-3: unmark old long-term field-pair %p (poc %d)",
+                            tmp.get(), tmp->picOrderCnt);
+                } else {
+                    /* When long_term_frame_idx is already assigned to a
+                     * reference field, and that reference field is not part of
+                     * a complementary field pair that includes the picture
+                     * specified by picNumX, that field is marked as "unused for
+                     * reference"
+                     */
+
+                    /* Check "tmp" (a long-term ref pic) is part of "other" (a
+                     * picture to be updated from short-term to long-term)
+                     * complementary field pair */
+
+                    /* NOTE: "other" here is short-ref, so "other" and "tmp"
+                     * must not be identical picture */
+                    if (!tmp->otherField) {
+                        tmp->setReference(H264Picture::None, false);
+                        ALOGD("MMCO-3: unmark old long-term field %p (poc %d)",
+                                tmp.get(), tmp->picOrderCnt);
+                    } else if (tmp->otherField != other &&
+                                (!other->otherField || other->otherField != tmp)) {
+                        tmp->setReference(H264Picture::None, false);
+                        ALOGD("MMCO-3: unmark old long-term field %p (poc %d)",
+                                tmp.get(), tmp->picOrderCnt);
+                    }
+                }
+                break;
+            }
+        }
+
+        other->setReference(H264Picture::LongTerm, picture->field == H264Picture::Frame);
+        other->longTermFrameIdx = refPicMarking.longTermFrameIdx;
+
+        ALOGD("MMCO-3: mark long-term ref pic %p, index %d, (poc %d)",
+                other.get(), other->longTermFrameIdx, other->picOrderCnt);
+
+        if (other->otherField && other->otherField->ref == H264Picture::LongTerm) {
+            other->otherField->longTermFrameIdx = refPicMarking.longTermFrameIdx;
+        }
+        break;
+    }
+    case 4:
+    {
+        /* 8.2.5.4.4 All pictures for which LongTermFrameIdx is greater than
+         * max_long_term_frame_idx_plus1 - 1 and that are marked as "used for
+         * long-term reference" are marked as "unused for reference */
+        int maxLongTermFrameIdx = refPicMarking.maxLongTermFrameIdxPlus1 - 1;
+
+        ALOGD("MMCO-4: max_long_term_frame_idx %d", maxLongTermFrameIdx);
+
+        for (const H264PicturePtr &other : mPicList) {
+            if (other->ref == H264Picture::LongTerm &&
+                    other->longTermFrameIdx > maxLongTermFrameIdx) {
+                other->setReference(H264Picture::None, false);
+                ALOGD("MMCO-4: unmark long-term ref pic %p, index %d, (poc %d)",
+                        other.get(), other->longTermFrameIdx, other->picOrderCnt);
+            }
+        }
+        break;
+    }
+    case 5:
+    {
+        /* 8.2.5.4.5 Unmark all reference pictures */
+        for (const H264PicturePtr &other : mPicList) {
+            other->setReference(H264Picture::None, false);
+        }
+        picture->memMgmt5 = true;
+        picture->frameNum = 0;
+        /* When the current picture includes a memory management control
+         * operation equal to 5, after the decoding of the current picture
+         * tempPicOrderCnt is set equal to PicOrderCnt(CurrPic),
+         * TopFieldOrderCnt of the current picture (if any) is set equal to
+         * TopFieldOrderCnt - tempPicOrderCnt, and BottomFieldOrderCnt of the
+         * current picture (if any) is set equal to BottomFieldOrderCnt -
+         * tempPicOrderCnt. */
+        if (picture->field == H264Picture::Top) {
+            picture->topFieldOrderCnt = 0;
+            picture->picOrderCnt = 0;
+        } else if (picture->field == H264Picture::Bottom) {
+            picture->bottomFieldOrderCnt = 0;
+            picture->picOrderCnt = 0;
+        } else {
+            picture->topFieldOrderCnt -= picture->picOrderCnt;
+            picture->bottomFieldOrderCnt -= picture->picOrderCnt;
+            picture->picOrderCnt = std::min(picture->topFieldOrderCnt,
+                                            picture->bottomFieldOrderCnt);
+        }
+        break;
+    }
+    case 6:
+    {
+        /* 8.2.5.4.6 Replace long term reference pictures with current picture.
+         * First unmark if any existing with this long_term_frame_idx */
+
+        /* If we have long-termref picture for LongTermFrameIdx, mark the
+         * picture as non-reference */
+        for (const H264PicturePtr &other : mPicList) {
+            if (other->ref == H264Picture::LongTerm &&
+                    other->longTermFrameIdx == refPicMarking.longTermFrameIdx) {
+                ALOGD("MMCO-6: unmark old long-term ref pic %p (poc %d)",
+                        other.get(), other->picOrderCnt);
+                other->setReference(H264Picture::None, true);
+                break;
+            }
+        }
+
+        picture->setReference(H264Picture::LongTerm, picture->secondField);
+        picture->longTermFrameIdx = refPicMarking.longTermFrameIdx;
+        if (picture->otherField && picture->otherField->ref == H264Picture::LongTerm) {
+            picture->otherField->longTermFrameIdx = refPicMarking.longTermFrameIdx;
+        }
+        break;
+    }
+    default:
+        LOG_FATAL("Should not end up here");
+        return false;
+    }
+
+    return true;
+}
+
+} // android
+
diff --git a/components/h264/parser/H264Parser.cpp b/components/h264/parser/H264Parser.cpp
new file mode 100644
index 0000000..50f3d9f
--- /dev/null
+++ b/components/h264/parser/H264Parser.cpp
@@ -0,0 +1,1877 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * Gstreamer
+ * Copyright (C) <2011> Intel Corporation
+ * Copyright (C) <2011> Collabora Ltd.
+ * Copyright (C) <2011> Thibault Saunier <thibault.saunier@collabora.com>
+ *
+ * Some bits C-c,C-v'ed and s/4/3 from h264parse and videoparsers/h264parse.c:
+ *    Copyright (C) <2010> Mark Nauwelaerts <mark.nauwelaerts@collabora.co.uk>
+ *    Copyright (C) <2010> Collabora Multimedia
+ *    Copyright (C) <2010> Nokia Corporation
+ *
+ *    (C) 2005 Michal Benes <michal.benes@itonis.tv>
+ *    (C) 2008 Wim Taymans <wim.taymans@gmail.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#include <v4l2_codec2/components/h264/parser/H264Parser.h>
+
+//#define LOG_NDEBUG 0
+#include <log/log.h>
+
+#include <cmath>
+#include <string>
+
+#define N_ELEMENTS(arr) (sizeof (arr) / sizeof ((arr)[0]))
+
+namespace android {
+
+/**** Default scaling_lists according to Table 7-2 *****/
+static const uint8_t default4x4Intra[16] = {
+    6, 13, 13, 20, 20, 20, 28, 28, 28, 28, 32, 32,
+    32, 37, 37, 42
+};
+
+static const uint8_t default4x4Inter[16] = {
+    10, 14, 14, 20, 20, 20, 24, 24, 24, 24, 27, 27,
+    27, 30, 30, 34
+};
+
+static const uint8_t default8x8Intra[64] = {
+    6, 10, 10, 13, 11, 13, 16, 16, 16, 16, 18, 18,
+    18, 18, 18, 23, 23, 23, 23, 23, 23, 25, 25, 25, 25, 25, 25, 25, 27, 27, 27,
+    27, 27, 27, 27, 27, 29, 29, 29, 29, 29, 29, 29, 31, 31, 31, 31, 31, 31, 33,
+    33, 33, 33, 33, 36, 36, 36, 36, 38, 38, 38, 40, 40, 42
+};
+
+static const uint8_t default8x8Inter[64] = {
+    9, 13, 13, 15, 13, 15, 17, 17, 17, 17, 19, 19,
+    19, 19, 19, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 24, 24, 24,
+    24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 27, 27, 27, 27, 27, 27, 28,
+    28, 28, 28, 28, 30, 30, 30, 30, 32, 32, 32, 33, 33, 35
+};
+
+struct PAR {
+    unsigned int parN, parD;
+};
+
+/* Table E-1 - Meaning of sample aspect ratio indicator (1..16) */
+static const PAR aspectRatios[17] = {
+    {0, 0},
+    {1, 1},
+    {12, 11},
+    {10, 11},
+    {16, 11},
+    {40, 33},
+    {24, 11},
+    {20, 11},
+    {32, 11},
+    {80, 33},
+    {18, 11},
+    {15, 11},
+    {64, 33},
+    {160, 99},
+    {4, 3},
+    {3, 2},
+    {2, 1}
+};
+
+/*****  Utils ****/
+#define EXTENDED_SAR 255
+
+static unsigned int ceilLog2(uint32_t v) {
+    unsigned int r, shift;
+
+    v--;
+    r = (v > 0xFFFF) << 4;
+    v >>=r;
+    shift = (v > 0xFF) < 3;
+    v >>= shift;
+    r |= shift;
+    shift = (v > 0xF) << 2;
+    v >>= shift;
+    r |= shift;
+    shift = (v > 0x3) << 1;
+    v >>= shift;
+    r |= shift;
+    r |= (v >> 1);
+    return r + 1;
+}
+
+H264SPS *H264Parser::getSPS(uint8_t spsId) {
+    H264SPS *sps;
+
+    sps = &mSPS[spsId];
+
+    if (sps->valid)
+        return sps;
+
+    return nullptr;
+}
+
+H264PPS *H264Parser::getPPS(uint8_t ppsId) {
+    H264PPS *pps;
+
+    pps = &mPPS[ppsId];
+
+    if (pps->valid)
+        return pps;
+
+    return nullptr;
+}
+
+/****** Parsing functions *****/
+
+static int scanForStartCodes(const uint8_t *data, unsigned int size) {
+    uint8_t *pdata = const_cast<uint8_t *>(data);
+    uint8_t *pend = pdata + size - 4;
+
+    while (pdata <= pend) {
+        if (pdata[2] > 1) {
+            pdata += 3;
+        } else if (pdata[1]) {
+            pdata += 2;
+        } else if (pdata[0] || pdata[2] != 1) {
+            pdata++;
+        } else {
+            return (pdata - data);
+        }
+    }
+
+    /* nothing found */
+    return -1;
+}
+
+static bool parseNaluHeader(H264NalUnit *nalu) {
+    uint8_t *data = nalu->data + nalu->offset;
+    uint8_t svcExtensionFlag;
+
+    if (nalu->size < 1)
+        return false;
+
+    nalu->type = (data[0] & 0x1f);
+    nalu->refIDC = (data[0] & 0x60) >> 5;
+    nalu->idrPicFlag = (nalu->type == 5 ? 1 : 0);
+    nalu->headerBytes = 1;
+
+    nalu->extensionType = H264NalUnit::None;
+
+    switch (nalu->type) {
+    case H264NalUnit::PrefixUnit:
+    case H264NalUnit::SliceExt:
+        if (nalu->size < 4)
+            return false;
+
+        data += nalu->headerBytes;
+
+        svcExtensionFlag = (data[0] & 0x80) >> 7;
+        if (svcExtensionFlag) {
+            nalu->extensionType = H264NalUnit::SVC;
+        } else {
+            nalu->extensionType = H264NalUnit::MVC;
+
+            H264NalUnitExtensionMVC mvc;
+            mvc.nonIdrFlag = (data[0] & 0x40) >> 6; // 1 bit
+            mvc.priorityId = (data[0] & 0x3f); // 6 bits
+            mvc.viewId = (data[1] << 2) + ((data[2] & 0x0c) >> 6); // 10 bits
+            mvc.temporalId = (data[2] & 0x38) >> 3; // 3 bits
+            mvc.anchorPicFlag = (data[2] & 0x04) >> 2; // 1 bits
+            mvc.interViewFlag = (data[2] & 0x02) >> 1; // 1 bits
+
+            nalu->extension = std::make_shared<H264NalUnitExtensionMVC>(std::move(mvc));
+
+            /* Update IdrPicFlag (H.7.4.1.1) */
+            nalu->idrPicFlag = !mvc.nonIdrFlag;
+        }
+        nalu->headerBytes += 3;
+        break;
+    default:
+        break;
+    }
+
+    ALOGI("Nal type %u, ref_idc %u", nalu->type, nalu->refIDC);
+    return true;
+}
+
+static H264Parser::Result identifyNaluUnchecked(const uint8_t *data,
+        unsigned int offset, size_t size, H264NalUnit *nalu) {
+    int off1;
+
+    if (size < offset + 4) {
+        ALOGI("Can't parse, buffer has too small size %zu, offset %u",
+            size, offset);
+        return H264Parser::Error;
+    }
+
+    off1 = scanForStartCodes(data + offset, size - offset);
+    if (off1 < 0) {
+        ALOGI("No start code prefix in this buffer");
+        return H264Parser::NoNal;
+    }
+
+    nalu->scOffset = offset + off1;
+
+    /* sc might have 2 or 3 0-bytes */
+    if (nalu->scOffset > 0 && data[nalu->scOffset - 1] == 00)
+        nalu->scOffset--;
+
+    nalu->offset = offset + off1 + 3;
+    nalu->data = (uint8_t *)data;
+    nalu->size = size - nalu->offset;
+
+    if (!parseNaluHeader(nalu)) {
+        ALOGI("not enough data to parse \"NAL unit header\"");
+        nalu->size = 0;
+        return H264Parser::NoNal;
+    }
+
+    nalu->valid = true;
+
+    if (nalu->type == H264NalUnit::SeqEnd ||
+        nalu->type == H264NalUnit::StreamEnd) {
+        ALOGI("end-of-seq or end-of-stream nal found");
+        nalu->size = 1;
+        return H264Parser::Ok;
+    }
+
+    return H264Parser::Ok;
+}
+
+H264Parser::Result H264Parser::identifyNalu(const uint8_t *data,
+        unsigned int offset, size_t size, H264NalUnit *nalu) {
+    ALOGI("Identifying Nalu...");
+
+    Result res;
+    int off2;
+
+    res = identifyNaluUnchecked(data, offset, size, nalu);
+
+    if (res != Ok)
+        goto beach;
+
+    /* The two NALs are exactly 1 byte size and are placed at the end of an AU,
+     * there is no need to wait for the following */
+    if (nalu->type == H264NalUnit::SeqEnd ||
+        nalu->type == H264NalUnit::StreamEnd)
+        goto beach;
+
+    off2 = scanForStartCodes(data + nalu->offset, size - nalu->offset);
+    if (off2 < 0) {
+        ALOGV("Nal start %d, No end found", nalu->offset);
+
+        return NoNalEnd;
+    } else {
+
+        /* Mini performance improvement:
+        * We could have a way to store how many 0s were skipped to avoid
+        * parsing them again on the next NAL */
+        while (off2 > 0 && data[nalu->offset + off2 - 1] == 00)
+            off2--;
+    }
+
+    nalu->size = off2;
+    if (nalu->size < 2)
+        return BrokenData;
+
+    ALOGI("Complete nal found. Off: %d, Size: %d", nalu->offset, nalu->size);
+
+beach:
+    return res;
+}
+
+static bool parseHRDParameters(H264HRDParams *hrd, NalReader *nr) {
+        unsigned int schedSelIdx;
+    ALOGI("parsing \"HRD Parameters\"");
+
+    READ_UE_MAX(nr, hrd->cpbCntMinus1, 31);
+    READ(nr, hrd->bitRateScale, 4);
+    READ(nr, hrd->cpbSizeScale, 4);
+
+    for (schedSelIdx = 0; schedSelIdx <= hrd->cpbCntMinus1; schedSelIdx++) {
+        READ_UE(nr, hrd->bitRateValueMinus1[schedSelIdx]);
+        READ_UE(nr, hrd->cpbSizeValueMinus1[schedSelIdx]);
+        READ(nr, hrd->cbrFlag[schedSelIdx], 1);
+    }
+
+    READ(nr, hrd->initialCPBRemovalDelayLengthMinus1, 5);
+    READ(nr, hrd->cpbRemovalDelayLengthMinus1, 5);
+    READ(nr, hrd->dpbOutputDelayLengthMinus1, 5);
+    READ(nr, hrd->timeOffsetLength, 5);
+
+    return true;
+
+error:
+    ALOGW("error parsing \"HRD Parameters\"");
+    return false;
+}
+
+static bool parseVUIParameters(H264SPS *sps, NalReader *nr) {
+    H264VUIParams *vui = &sps->vuiParameters;
+
+    ALOGI("parsing \"VUI Parameters\"");
+
+    /* set default values for fields that might not be present in the bitstream
+       and have valid defaults */
+    vui->videoFormat = 5;
+    vui->colourPrimaries = 2;
+    vui->transferCharacteristics = 2;
+    vui->matrixCoefficients = 2;
+
+    READ(nr, vui->aspectRatioInfoPresentFlag, 1);
+    if (vui->aspectRatioInfoPresentFlag) {
+        READ(nr, vui->aspectRatioIDC, 8);
+        if (vui->aspectRatioIDC == EXTENDED_SAR) {
+            READ(nr, vui->sarWidth, 16);
+            READ(nr, vui->sarHeight, 16);
+            vui->parN = vui->sarWidth;
+            vui->parD = vui->sarHeight;
+        } else if (vui->aspectRatioIDC <= 16) {
+            vui->parN = aspectRatios[vui->aspectRatioIDC].parN;
+            vui->parD = aspectRatios[vui->aspectRatioIDC].parD;
+        }
+    }
+
+    READ(nr, vui->overscanInfoPresentFlag, 1);
+    if (vui->overscanInfoPresentFlag)
+        READ(nr, vui->overscanAppropriateFlag, 1);
+
+    READ(nr, vui->videoSignalTypePresentFlag, 1);
+    if (vui->videoSignalTypePresentFlag) {
+
+        READ(nr, vui->videoFormat, 3);
+        READ(nr, vui->videoFullRangeFlag, 1);
+        READ(nr, vui->colourDescriptionPresentFlag, 1);
+        if (vui->colourDescriptionPresentFlag) {
+            READ(nr, vui->colourPrimaries, 8);
+            READ(nr, vui->transferCharacteristics, 8);
+            READ(nr, vui->matrixCoefficients, 8);
+        }
+    }
+
+    READ(nr, vui->chromaLocInfoPresentFlag, 1);
+    if (vui->chromaLocInfoPresentFlag) {
+        READ_UE_MAX(nr, vui->chromaSampleLocTypeTopField, 5);
+        READ_UE_MAX(nr, vui->chromaSampleLocTypeBottomField, 5);
+    }
+
+    READ(nr, vui->timingInfoPresentFlag, 1);
+    if (vui->timingInfoPresentFlag) {
+        READ(nr, vui->numUnitsInTick, 32);
+        if (vui->numUnitsInTick == 0)
+            ALOGW("num_units_in_tick = 0 detected in stream "
+                  "(incompliant to H.264 E.2.1).");
+
+        READ(nr, vui->timeScale, 32);
+        if (vui->timeScale == 0)
+            ALOGW("time_scale = 0 detected in stream "
+                  "(incompliant to H.264 E.2.1).");
+
+        READ(nr, vui->fixedFrameRateFlag, 1);
+    }
+
+    READ(nr, vui->nalHRDParametersPresentFlag, 1);
+    if (vui->nalHRDParametersPresentFlag) {
+        if (!parseHRDParameters(&vui->nalHRDParameters, nr))
+            goto error;
+    }
+
+    READ(nr, vui->vclHRDParametersPresentFlag, 1);
+    if (vui->vclHRDParametersPresentFlag) {
+        if (!parseHRDParameters(&vui->vclHRDParameters, nr))
+            goto error;
+    }
+
+    if (vui->nalHRDParametersPresentFlag ||
+            vui->vclHRDParametersPresentFlag)
+        READ(nr, vui->lowDelayHRDFlag, 1);
+
+    READ(nr, vui->picStructPresentFlag, 1);
+    READ(nr, vui->bitstreamRestrictionFlag, 1);
+    if (vui->bitstreamRestrictionFlag) {
+        READ(nr, vui->motionVectorsOverPicBoundariesFlag, 1);
+        READ_UE(nr, vui->maxBytesPerPicDenom);
+        READ_UE_MAX(nr, vui->maxBitsPerMBDenom, 16);
+        READ_UE_MAX(nr, vui->log2MaxMVLengthHorizontal, 16);
+        READ_UE_MAX(nr, vui->log2MaxMVLengthVertical, 16);
+        READ_UE(nr, vui->numReorderFrames);
+        READ_UE(nr, vui->maxDecFrameBuffering);
+    }
+
+    return true;
+
+error:
+    ALOGW("error parsing \"VUI Parameters\"");
+    return false;
+}
+
+static bool parseScalingList(NalReader *nr,
+        uint8_t scalingLists4x4[6][16], uint8_t scalingLists8x8[6][64],
+        const uint8_t fallback4x4Inter[16], const uint8_t fallback4x4Intra[16],
+        const uint8_t fallback8x8Inter[64], const uint8_t fallback8x8Intra[64],
+        uint8_t numLists) {
+    unsigned int i;
+
+    static const uint8_t *defaultLists[12] = {
+        default4x4Intra, default4x4Intra, default4x4Intra,
+        default4x4Inter, default4x4Inter, default4x4Inter,
+        default8x8Intra, default8x8Inter,
+        default8x8Intra, default8x8Inter,
+        default8x8Intra, default8x8Inter
+    };
+
+    ALOGI("parsing scaling lists");
+
+    for (i = 0; i < 12; i++) {
+        bool useDefault = false;
+
+        if (i < numLists) {
+            uint8_t scalingListPresentFlag;
+
+            READ(nr, scalingListPresentFlag, 1);
+            if (scalingListPresentFlag) {
+                uint8_t *scalingList;
+                unsigned int size;
+                unsigned int j;
+                uint8_t lastScale;
+                uint8_t nextScale;
+
+                if (i < 6) {
+                    scalingList = scalingLists4x4[i];
+                    size = 16;
+                } else {
+                    scalingList = scalingLists8x8[i - 6];
+                    size = 64;
+                }
+
+                lastScale = 8;
+                nextScale = 8;
+                for (j = 0; j < size; j++) {
+                    if (nextScale != 0) {
+                        int32_t deltaScale;
+
+                        READ_SE(nr, deltaScale);
+                        nextScale = (lastScale + deltaScale) & 0xff;
+                    }
+                    if (j == 0 && nextScale == 0) {
+                        /* Use default scaling lists (7.4.2.1.1.1) */
+                        memcpy(scalingList, defaultLists[i], size);
+                        break;
+                    }
+                    lastScale = scalingList[j] =
+                        (nextScale == 0) ? lastScale : nextScale;
+                }
+            } else
+                useDefault = true;
+        } else
+            useDefault = true;
+
+        if (useDefault) {
+            switch (i) {
+            case 0:
+                memcpy(scalingLists4x4[0], fallback4x4Intra, 16);
+                break;
+            case 1:
+                memcpy(scalingLists4x4[1], scalingLists4x4[0], 16);
+                break;
+            case 2:
+                memcpy(scalingLists4x4[2], scalingLists4x4[1], 16);
+                break;
+            case 3:
+                memcpy(scalingLists4x4[3], fallback4x4Inter, 16);
+                break;
+            case 4:
+                memcpy(scalingLists4x4[4], scalingLists4x4[3], 16);
+                break;
+            case 5:
+                memcpy(scalingLists4x4[5], scalingLists4x4[4], 16);
+                break;
+            case 6:
+                memcpy(scalingLists8x8[0], fallback8x8Intra, 64);
+                break;
+            case 7:
+                memcpy(scalingLists8x8[1], fallback8x8Inter, 64);
+                break;
+            case 8:
+                memcpy(scalingLists8x8[2], scalingLists8x8[0], 64);
+                break;
+            case 9:
+                memcpy(scalingLists8x8[3], scalingLists8x8[1], 64);
+                break;
+            case 10:
+                memcpy(scalingLists8x8[4], scalingLists8x8[2], 64);
+                break;
+            case 11:
+                memcpy(scalingLists8x8[5], scalingLists8x8[3], 64);
+                break;
+
+            default:
+                break;
+            }
+        }
+    }
+
+    return true;
+
+error:
+    ALOGW("error parsing scaling lists");
+    return false;
+}
+
+static bool sliceParseRefPicListModification1(H264SliceHdr *slice,
+        NalReader *nr, unsigned int list, bool isMvc) {
+    H264RefPicListModification *entries;
+    uint8_t *refPicListModificationFlag, *nRefPicListModification;
+    uint32_t modificationOfPicNumsIDC;
+    size_t maxEntries;
+    unsigned int i = 0;
+
+    if (list == 0) {
+        entries = slice->refPicListModificationL0;
+        maxEntries = N_ELEMENTS(slice->refPicListModificationL0);
+        refPicListModificationFlag = &slice->refPicListModificationFlagL0;
+        nRefPicListModification = &slice->nRefPicListModificationL0;
+    } else {
+        entries = slice->refPicListModificationL1;
+        maxEntries = N_ELEMENTS(slice->refPicListModificationL1);
+        refPicListModificationFlag = &slice->refPicListModificationFlagL1;
+        nRefPicListModification = &slice->nRefPicListModificationL1;
+    }
+
+    READ(nr, *refPicListModificationFlag, 1);
+    if (*refPicListModificationFlag) {
+        while (1) {
+            READ_UE(nr, modificationOfPicNumsIDC);
+            if (modificationOfPicNumsIDC == 0 ||
+                    modificationOfPicNumsIDC == 1) {
+                READ_UE_MAX(nr, entries[i].value.absDiffPicNumMinus1,
+                        slice->maxPicNum - 1);
+            } else if (modificationOfPicNumsIDC == 2) {
+                READ_UE(nr, entries[i].value.longTermPicNum);
+            } else if (isMvc && (modificationOfPicNumsIDC == 4 ||
+                        modificationOfPicNumsIDC == 5)) {
+                READ_UE(nr, entries[i].value.absDiffViewIdxMinus1);
+            }
+            entries[i++].modificationOfPicNumsIDC = modificationOfPicNumsIDC;
+            if (modificationOfPicNumsIDC == 3)
+                break;
+            if (i >= maxEntries)
+                goto error;
+        }
+    }
+    *nRefPicListModification = i;
+    return true;
+
+error:
+    ALOGW("error parsing \"Reference picture list %u modification\"", list);
+    return false;
+}
+
+static bool sliceParseRefPicListModification(H264SliceHdr *slice, NalReader *nr,
+        bool isMvc) {
+    if (!slice->is(H264SliceHdr::I) && !slice->is(H264SliceHdr::SI)) {
+        if (!sliceParseRefPicListModification1(slice, nr, 0, isMvc))
+            return false;
+    }
+
+    if (slice->is(H264SliceHdr::B)) {
+        if (!sliceParseRefPicListModification1(slice, nr, 1, isMvc))
+            return false;
+    }
+    return true;
+}
+
+static bool h264SliceParseDecRefPicMarking(H264SliceHdr *slice,
+        const H264NalUnit &nalu, NalReader *nr) {
+    H264DecRefPicMarking *decRefPicM;
+    unsigned int startPos, startEPB;
+
+    ALOGI("parsing \"Decoded reference picture marking\"");
+
+    startPos = nr->getPos();
+    startEPB = nr->getEPBCount();
+
+    decRefPicM = &slice->decRefPicMarking;
+
+    if (nalu.idrPicFlag) {
+        READ(nr, decRefPicM->noOutputOfPriorPicsFlag, 1);
+        READ(nr, decRefPicM->longTermReferenceFlag, 1);
+    } else {
+        READ(nr, decRefPicM->adaptiveRefPicMarkingModeFlag, 1);
+        if (decRefPicM->adaptiveRefPicMarkingModeFlag) {
+            uint32_t memMgmtCtrlOp;
+            H264RefPicMarking *refPicMarking;
+
+            decRefPicM->nRefPicMarking = 0;
+            while (1) {
+                READ_UE_MAX(nr, memMgmtCtrlOp, 6);
+                if (memMgmtCtrlOp == 0)
+                    break;
+
+                if (decRefPicM->nRefPicMarking >=
+                        N_ELEMENTS(decRefPicM->refPicMarking))
+                    goto error;
+
+                refPicMarking =
+                    &decRefPicM->refPicMarking[decRefPicM->nRefPicMarking];
+
+                refPicMarking->memoryManagementControlOperation = memMgmtCtrlOp;
+
+                if (memMgmtCtrlOp == 1 || memMgmtCtrlOp == 3)
+                    READ_UE(nr, refPicMarking->differenceOfPicNumsMinus1);
+
+                if (memMgmtCtrlOp == 2)
+                    READ_UE(nr, refPicMarking->longTermPicNum);
+
+                if (memMgmtCtrlOp == 3 || memMgmtCtrlOp == 6)
+                    READ_UE(nr, refPicMarking->longTermFrameIdx);
+
+                if (memMgmtCtrlOp == 4)
+                    READ_UE(nr, refPicMarking->maxLongTermFrameIdxPlus1);
+
+                decRefPicM->nRefPicMarking++;
+            }
+        }
+    }
+
+    decRefPicM->bitSize = (nr->getPos() - startPos) -
+        (8 * (nr->getEPBCount() - startEPB));
+
+    return true;
+
+error:
+    ALOGW("error parsing \"Decoded reference picture marking\"");
+    return false;
+}
+
+static bool h264SliceParsePredWeightTable(H264SliceHdr *slice,
+        NalReader *nr, uint8_t chromaArrayType) {
+    H264PredWeightTable *p;
+    int16_t defaultLumaWeight, defaultChromaWeight;
+    int i;
+
+    ALOGI("parsing \"Prediction weight table\"");
+
+    p = &slice->predWeightTable;
+
+    READ_UE_MAX(nr, p->lumaLog2WeightDenom, 7);
+    /* set default values */
+    defaultLumaWeight = 1 << p->lumaLog2WeightDenom;
+    for (i = 0; i <= slice->numRefIdxL0ActiveMinus1; i++)
+        p->lumaWeightL0[i] = defaultLumaWeight;
+    if (slice->is(H264SliceHdr::B)) {
+        for (i = 0; i <= slice->numRefIdxL1ActiveMinus1; i++)
+            p->lumaWeightL1[i] = defaultLumaWeight;
+    }
+
+    if (chromaArrayType != 0) {
+        READ_UE_MAX(nr, p->chromaLog2WeightDenom, 7);
+        /* set default values */
+        defaultChromaWeight = 1 << p->chromaLog2WeightDenom;
+        for (i = 0; i <= slice->numRefIdxL0ActiveMinus1; i++) {
+            p->chromaWeightL0[i][0] = defaultChromaWeight;
+            p->chromaWeightL0[i][1] = defaultChromaWeight;
+        }
+        if (slice->is(H264SliceHdr::B)) {
+            for (i = 0; i <= slice->numRefIdxL1ActiveMinus1; i++) {
+                p->chromaWeightL1[i][0] = defaultChromaWeight;
+                p->chromaWeightL1[i][1] = defaultChromaWeight;
+            }
+        }
+    }
+
+    for (i = 0; i <= slice->numRefIdxL0ActiveMinus1; i++) {
+        uint8_t lumaWeightL0Flag;
+
+        READ(nr, lumaWeightL0Flag, 1);
+        if (lumaWeightL0Flag) {
+            READ_SE_ALLOWED(nr, p->lumaWeightL0[i], -128, 127);
+            READ_SE_ALLOWED(nr, p->lumaOffsetL0[i], -128, 127);
+        }
+        if (chromaArrayType != 0) {
+            uint8_t chromaWeightL0Flag;
+            int j;
+
+            READ(nr, chromaWeightL0Flag, 1);
+            if (chromaWeightL0Flag) {
+                for (j = 0; j < 2; j++) {
+                    READ_SE_ALLOWED(nr, p->chromaWeightL0[i][j], -128, 127);
+                    READ_SE_ALLOWED(nr, p->chromaOffsetL0[i][j], -128, 127);
+                }
+            }
+        }
+    }
+
+    if (slice->is(H264SliceHdr::B)) {
+        for (i = 0; i <= slice->numRefIdxL1ActiveMinus1; i++) {
+            uint8_t lumaWeightL1Flag;
+
+            READ(nr, lumaWeightL1Flag, 1);
+            if (lumaWeightL1Flag) {
+                READ_SE_ALLOWED(nr, p->lumaWeightL1[i], -128, 127);
+                READ_SE_ALLOWED(nr, p->lumaOffsetL1[i], -128, 127);
+            }
+            if (chromaArrayType != 0) {
+                uint8_t chromaWeightL1Flag;
+                int j;
+
+                READ(nr, chromaWeightL1Flag, 1);
+                if (chromaWeightL1Flag) {
+                    for (j = 0; j < 2; j++) {
+                        READ_SE_ALLOWED(nr, p->chromaWeightL1[i][j], -128, 127);
+                        READ_SE_ALLOWED(nr, p->chromaOffsetL1[i][j], -128, 127);
+                    }
+                }
+            }
+        }
+    }
+
+    return true;
+
+error:
+    ALOGW("error parsing \"Prediction weight table\"");
+    return false;
+}
+
+H264Parser::Result H264Parser::parseBufferingPeriod(H264BufferingPeriod *per,
+        NalReader *nr) {
+    H264SPS *sps;
+    uint8_t spsId;
+
+    ALOGI("parsing \"Buffering period\"");
+
+    READ_UE_MAX(nr, spsId, H264_MAX_SPS_COUNT - 1);
+    sps = getSPS(spsId);
+    if (!sps) {
+        ALOGW("couldn't find associated sequence parameter set with id: %d",
+                spsId);
+        return BrokenLink;
+    }
+    per->sps = sps;
+
+    if (sps->vuiParametersPresentFlag) {
+        H264VUIParams *vui = &sps->vuiParameters;
+
+        if (vui->nalHRDParametersPresentFlag) {
+            H264HRDParams *hrd = &vui->nalHRDParameters;
+            const uint8_t nbits = hrd->initialCPBRemovalDelayLengthMinus1 + 1;
+            uint8_t schedSelIdx;
+
+            for (schedSelIdx = 0; schedSelIdx <= hrd->cpbCntMinus1;
+                    schedSelIdx++) {
+                READ(nr, per->nalInitialCPBRemovalDelay[schedSelIdx], nbits);
+                READ(nr, per->nalInitialCPBRemovalDelayOffset[schedSelIdx],
+                        nbits);
+            }
+        }
+
+        if (vui->vclHRDParametersPresentFlag) {
+            H264HRDParams *hrd = &vui->vclHRDParameters;
+            const uint8_t nbits = hrd->initialCPBRemovalDelayLengthMinus1 + 1;
+            uint8_t schedSelIdx;
+
+            for (schedSelIdx = 0; schedSelIdx <= hrd->cpbCntMinus1;
+                    schedSelIdx++) {
+                READ(nr, per->vclInitialCPBRemovalDelay[schedSelIdx], nbits);
+                READ(nr, per->vclInitialCPBRemovalDelayOffset[schedSelIdx],
+                        nbits);
+            }
+        }
+    }
+
+    return Ok;
+
+error:
+    ALOGW("error parsing \"Buffering period\"");
+    return Error;
+}
+
+static bool h264ParseClockTimestamp(H264ClockTimestamp * tim,
+        uint8_t timeOffsetLength, NalReader *nr) {
+    ALOGI("parsing \"Clock timestamp\"");
+
+    /* default values */
+    tim->timeOffset = 0;
+
+    READ(nr, tim->ctType, 2);
+    READ(nr, tim->nuitFieldBasedFlag, 1);
+    READ(nr, tim->countingType, 5);
+    READ(nr, tim->fullTimestampFlag, 1);
+    READ(nr, tim->discontinuityFlag, 1);
+    READ(nr, tim->cntDroppedFlag, 1);
+    READ(nr, tim->nFrames, 8);
+
+    if (tim->fullTimestampFlag) {
+        tim->secondsFlag = true;
+        READ(nr, tim->secondsValue, 6);
+
+        tim->minutesFlag = true;
+        READ(nr, tim->minutesValue, 6);
+
+        tim->hoursFlag = true;
+        READ(nr, tim->hoursValue, 5);
+    } else {
+        READ(nr, tim->secondsFlag, 1);
+        if (tim->secondsFlag) {
+            READ(nr, tim->secondsValue, 6);
+            READ(nr, tim->minutesFlag, 1);
+            if (tim->minutesFlag) {
+                READ(nr, tim->minutesValue, 6);
+                READ(nr, tim->hoursFlag, 1);
+                if (tim->hoursFlag)
+                    READ(nr, tim->hoursValue, 5);
+            }
+        }
+    }
+
+    if (timeOffsetLength > 0)
+        READ(nr, tim->timeOffset, timeOffsetLength);
+
+    return true;
+
+error:
+    ALOGW("error parsing \"Clock timestamp\"");
+    return false;
+}
+
+H264Parser::Result H264Parser::parsePicTiming(H264PicTiming *tim,
+        NalReader * nr) {
+    Result error = Error;
+
+    ALOGI("parsing \"Picture timing\"");
+    if (!mLastSPS || !mLastSPS->valid) {
+        ALOGW("didn't get the associated sequence parameter set for the "
+                "current access unit");
+        error = BrokenLink;
+        goto error;
+    }
+
+    if (mLastSPS->vuiParametersPresentFlag) {
+        H264VUIParams *vui = &mLastSPS->vuiParameters;
+        H264HRDParams *hrd = NULL;
+
+        if (vui->nalHRDParametersPresentFlag) {
+            hrd = &vui->nalHRDParameters;
+        } else if (vui->vclHRDParametersPresentFlag) {
+            hrd = &vui->vclHRDParameters;
+        }
+
+        tim->cpbDpbDelaysPresentFlag = !!hrd;
+        tim->picStructPresentFlag = vui->picStructPresentFlag;
+
+        if (tim->cpbDpbDelaysPresentFlag) {
+            tim->cpbRemovalDelayLengthMinus1 =
+                hrd->cpbRemovalDelayLengthMinus1;
+            tim->dpbOutputDelayLengthMinus1 = hrd->dpbOutputDelayLengthMinus1;
+
+            READ(nr, tim->cpbRemovalDelay,
+                    tim->cpbRemovalDelayLengthMinus1 + 1);
+            READ(nr, tim->dpbOutputDelay,
+                    tim->dpbOutputDelayLengthMinus1 + 1);
+        }
+
+        if (tim->picStructPresentFlag) {
+            const uint8_t numClockTsTable[9] = {
+                1, 1, 1, 2, 2, 3, 3, 2, 3
+            };
+            uint8_t numClockNumTs;
+            unsigned int i;
+
+            READ(nr, tim->picStruct, 4);
+            CHECK_ALLOWED((int8_t) tim->picStruct, 0, 8);
+
+            tim->timeOffsetLength = 24;
+            if (hrd)
+                tim->timeOffsetLength = hrd->timeOffsetLength;
+
+            numClockNumTs = numClockTsTable[tim->picStruct];
+            for (i = 0; i < numClockNumTs; i++) {
+                READ(nr, tim->clockTimestampFlag[i], 1);
+                if (tim->clockTimestampFlag[i]) {
+                    if (!h264ParseClockTimestamp(&tim->clockTimestamp[i],
+                                tim->timeOffsetLength, nr))
+                        goto error;
+                }
+            }
+        }
+    }
+
+    if (!tim->cpbDpbDelaysPresentFlag && !tim->picStructPresentFlag) {
+        ALOGW
+            ("Invalid pic_timing SEI NAL with neither CpbDpbDelays nor pic_struct");
+        return BrokenData;
+    }
+
+    return Ok;
+
+error:
+    ALOGW("error parsing \"Picture timing\"");
+    return Error;
+}
+
+H264Parser::Result H264Parser::parseRegisteredUserData(
+        H264RegisteredUserData *rud, NalReader *nr, unsigned int payloadSize) {
+    std::vector<uint8_t> data;
+    unsigned int i;
+
+    rud->data.clear();
+    rud->size = 0;
+
+    if (payloadSize < 2) {
+        ALOGW("Too small payload size %d", payloadSize);
+        return BrokenData;
+    }
+
+    READ(nr, rud->countryCode, 8);
+    --payloadSize;
+
+    if (rud->countryCode == 0xFF) {
+        READ(nr, rud->countryCodeExtension, 8);
+        --payloadSize;
+    } else {
+        rud->countryCodeExtension = 0;
+    }
+
+    if (payloadSize < 1) {
+        ALOGW("No more remaining payload data to store");
+        return BrokenData;
+    }
+
+    for (i = 0; i < payloadSize; ++i) {
+        uint8_t tmp;
+        READ(nr, tmp, 8);
+        data.push_back(std::move(tmp));
+    }
+
+    rud->data = std::move(data);
+    rud->size = payloadSize;
+    return Ok;
+
+error:
+    ALOGW("error parsing \"Registered User Data\"");
+    return Error;
+}
+
+H264Parser::Result H264Parser::parseUserDataUnregistered(
+        H264UserDataUnregistered *urud, NalReader *nr,
+        unsigned int payloadSize) {
+    std::vector<uint8_t> data;
+    int i;
+
+    if (payloadSize < 16) {
+        ALOGW("Too small payload size %d", payloadSize);
+        return BrokenData;
+    }
+
+    for (int i = 0; i < 16; i++) {
+        READ(nr, urud->uuid[i], 8);
+    }
+    payloadSize -= 16;
+
+    urud->size = payloadSize;
+
+    for (i = 0; i < payloadSize; ++i) {
+        uint8_t tmp;
+        READ(nr, tmp, 8);
+        data.push_back(std::move(tmp));
+    }
+
+    if (payloadSize < 1) {
+        ALOGW("No more remaining payload data to store");
+        return BrokenData;
+    }
+
+    urud->data = std::move(data);
+    return Ok;
+
+error:
+    ALOGW("error parsing \"User Data Unregistered\"");
+    return Error;
+}
+
+H264Parser::Result H264Parser::parseRecoveryPoint(H264RecoveryPoint *rp, NalReader *nr) {
+    H264SPS *const sps = mLastSPS;
+
+    ALOGI("parsing \"Recovery point\"");
+    if (!sps || !sps->valid) {
+        ALOGW("didn't get the associated sequence parameter set for the "
+                "current access unit");
+        goto error;
+    }
+
+    READ_UE_MAX(nr, rp->recoveryFrameCnt, sps->maxFrameNum - 1);
+    READ(nr, rp->exactMatchFlag, 1);
+    READ(nr, rp->brokenLinkFlag, 1);
+    READ(nr, rp->changingSliceGroupIDC, 2);
+
+    return Ok;
+
+error:
+    ALOGW("error parsing \"Recovery point\"");
+    return Error;
+}
+
+/* Parse SEI stereo_video_info() message */
+H264Parser::Result H264Parser::parseStereoVideoInfo(H264StereoVideoInfo *info,
+        NalReader *nr) {
+    ALOGI("parsing \"Stereo Video info\"");
+
+    READ(nr, info->fieldViewsFlag, 1);
+    if (info->fieldViewsFlag) {
+        READ(nr, info->topFieldIsLeftViewFlag, 1);
+    } else {
+        READ(nr, info->currentFrameIsLeftViewFlag, 1);
+        READ(nr, info->nextFrameIsSecondViewFlag, 1);
+    }
+    READ(nr, info->leftViewSelfContainedFlag, 1);
+    READ(nr, info->rightViewSelfContainedFlag, 1);
+
+    return Ok;
+
+error:
+    ALOGW("error parsing \"Stereo Video info\"");
+    return Error;
+}
+
+/* Parse SEI frame_packing_arrangement() message */
+H264Parser::Result H264Parser::parseFramePacking(H264FramePacking *framePacking,
+        NalReader *nr, unsigned int payloadSize) {
+    uint8_t framePackingExtensionFlag;
+    unsigned int startPos;
+
+    ALOGI("parsing \"Frame Packing Arrangement\"");
+
+    startPos = nr->getPos();
+    READ_UE(nr, framePacking->framePackingId);
+    READ(nr, framePacking->framePackingCancelFlag, 1);
+
+    if (!framePacking->framePackingCancelFlag) {
+        READ(nr, framePacking->framePackingType, 7);
+        READ(nr, framePacking->quincunxSamplingFlag, 1);
+        READ(nr, framePacking->contentInterpretationType, 6);
+        READ(nr, framePacking->spatialFlippingFlag, 1);
+        READ(nr, framePacking->frame0FlippedFlag, 1);
+        READ(nr, framePacking->fieldViewsFlag, 1);
+        READ(nr, framePacking->currentFrameIsFrame0Flag, 1);
+        READ(nr, framePacking->frame0SelfContainedFlag, 1);
+        READ(nr, framePacking->frame1SelfContainedFlag, 1);
+
+        if (!framePacking->quincunxSamplingFlag &&
+                framePacking->framePackingType !=
+                H264FramePacking::TemporalInterleaving) {
+            READ(nr, framePacking->frame0GridPositionX, 4);
+            READ(nr, framePacking->frame0GridPositionY, 4);
+            READ(nr, framePacking->frame1GridPositionX, 4);
+            READ(nr, framePacking->frame1GridPositionY, 4);
+        }
+
+        /* Skip frame_packing_arrangement_reserved_byte */
+        if (!nr->skip(8))
+            goto error;
+
+        READ_UE_MAX(nr, framePacking->framePackingRepetitionPeriod, 16384);
+    }
+
+    READ(nr, framePackingExtensionFlag, 1);
+
+    /* All data that follows within a frame packing arrangement SEI message
+       after the value 1 for frame_packing_arrangement_extension_flag shall
+       be ignored (D.2.25) */
+        if (framePackingExtensionFlag) {
+            nr->skipLong(payloadSize - (nr->getPos() - startPos));
+    }
+
+    return Ok;
+
+error:
+    ALOGW("error parsing \"Frame Packing Arrangement\"");
+    return Error;
+}
+
+H264Parser::Result H264Parser::parseMasteringDisplayColourVolume(
+        H264MasteringDisplayColourVolume *mdcv, NalReader *nr) {
+    unsigned int i;
+
+    ALOGI("parsing \"Mastering display colour volume\"");
+
+    for (i = 0; i < 3; i++) {
+        READ(nr, mdcv->displayPrimariesX[i], 16);
+        READ(nr, mdcv->displayPrimariesY[i], 16);
+    }
+
+    READ(nr, mdcv->whitePointX, 16);
+    READ(nr, mdcv->whitePointY, 16);
+    READ(nr, mdcv->maxDisplayMasteringLuminance, 32);
+    READ(nr, mdcv->minDisplayMasteringLuminance, 32);
+
+    return Ok;
+
+error:
+    ALOGW("error parsing \"Mastering display colour volume\"");
+    return Error;
+}
+
+H264Parser::Result H264Parser::parseContentLightLevelInfo(
+        H264ContentLightLevel *cll, NalReader *nr) {
+    ALOGI("parsing \"Content light level\"");
+
+    READ(nr, cll->maxContentLightLevel, 16);
+    READ(nr, cll->maxPicAverageLightLevel, 16);
+
+    return Ok;
+
+error:
+    ALOGW("error parsing \"Content light level\"");
+    return Error;
+}
+
+H264Parser::Result H264Parser::parseSEIUnhandledPayload(
+        H264SEIUnhandledPayload *payload, NalReader *nr,
+        unsigned int payloadType, unsigned int payloadSize) {
+    std::vector<uint8_t> data;
+    int i;
+
+    payload->payloadType = payloadType;
+
+    for (i = 0; i < payloadSize; ++i) {
+        uint8_t tmp;
+        READ(nr, tmp, 8);
+        data.push_back(std::move(tmp));
+    }
+
+    payload->size = payloadSize;
+    payload->data = std::move(data);
+
+    return Ok;
+
+error:
+    ALOGW("error parsing \"Unhandled payload\"");
+    return Error;
+}
+
+H264Parser::Result H264Parser::parseSEIMessage(NalReader *nr,
+        H264SEIMessage *sei) {
+    uint32_t aux;
+    uint8_t payloadTypeByte, payloadSizeByte;
+    unsigned int remaining, payloadSize, next;
+    H264Parser::Result res;
+
+    ALOGI("parsing \"SEI message\"");
+
+    do {
+        READ(nr, payloadTypeByte, 8);
+        sei->payloadType = static_cast<H264SEIMessage::PayloadType>(
+            sei->payloadType + payloadTypeByte);
+    } while (payloadTypeByte == 0xff);
+
+    aux = 0;
+    do {
+        READ(nr, payloadSizeByte, 8);
+        aux += payloadSizeByte;
+    }
+    while (payloadSizeByte == 0xff);
+
+    remaining = nr->getRemaining();
+    payloadSize = aux * 8 < remaining ? aux * 8 : remaining;
+    next = nr->getPos() + payloadSize;
+
+    ALOGI("SEI message received: payloadType  %u, payloadSize = %u bits",
+            sei->payloadType, payloadSize);
+
+    switch (sei->payloadType) {
+        case H264SEIMessage::BufPeriod:
+        {
+            /* size not set; might depend on emulation_prevention_three_byte */
+            H264BufferingPeriod payload;
+            res = parseBufferingPeriod(&payload, nr);
+            sei->payload = std::make_shared<H264BufferingPeriod>(std::move(payload));
+            break;
+        }
+        case H264SEIMessage::PicTiming:
+        {
+            /* size not set; might depend on emulation_prevention_three_byte */
+            H264PicTiming payload;
+            res = parsePicTiming(&payload, nr);
+            sei->payload = std::make_shared<H264PicTiming>(std::move(payload));
+            break;
+        }
+        case H264SEIMessage::RegisteredUserData:
+        {
+            H264RegisteredUserData payload;
+            res = parseRegisteredUserData(&payload, nr, payloadSize >> 3);
+            sei->payload = std::make_shared<H264RegisteredUserData>(std::move(payload));
+            break;
+        }
+        case H264SEIMessage::UserDataUnregistered:
+        {
+            H264UserDataUnregistered payload;
+            res = parseUserDataUnregistered(&payload, nr, payloadSize >> 3);
+            sei->payload = std::make_shared<H264UserDataUnregistered>(std::move(payload));
+            break;
+        }
+        case H264SEIMessage::RecoveryPoint:
+        {
+            H264RecoveryPoint payload;
+            res = parseRecoveryPoint(&payload, nr);
+            sei->payload = std::make_shared<H264RecoveryPoint>(std::move(payload));
+            break;
+        }
+        case H264SEIMessage::StereoVideoInfo:
+        {
+            H264StereoVideoInfo payload;
+            res = parseStereoVideoInfo(&payload, nr);
+            sei->payload = std::make_shared<H264StereoVideoInfo>(std::move(payload));
+            break;
+        }
+        case H264SEIMessage::FramePacking:
+        {
+            H264FramePacking payload;
+            res = parseFramePacking(&payload, nr, payloadSize);
+            sei->payload = std::make_shared<H264FramePacking>(std::move(payload));
+            break;
+        }
+        case H264SEIMessage::MasteringDisplayColourVolume:
+        {
+            H264MasteringDisplayColourVolume payload;
+            res = parseMasteringDisplayColourVolume(&payload, nr);
+            sei->payload = std::make_shared<H264MasteringDisplayColourVolume>(std::move(payload));
+            break;
+        }
+        case H264SEIMessage::ContentLightLevel:
+        {
+            H264ContentLightLevel payload;
+            res = parseContentLightLevelInfo(&payload, nr);
+            sei->payload = std::make_shared<H264ContentLightLevel>(std::move(payload));
+            break;
+        }
+        default:
+        {
+            H264SEIUnhandledPayload payload;
+            res = parseSEIUnhandledPayload(&payload, nr,
+                    sei->payloadType, payloadSize >> 3);
+            sei->payloadType = H264SEIMessage::UnhandledPayload;
+            sei->payload = std::make_shared<H264SEIUnhandledPayload>(std::move(payload));
+            break;
+        }
+    }
+
+    /* When SEI message doesn't end at byte boundary,
+     * check remaining bits fit the specification.
+     */
+    if (!nr->isByteAligned()) {
+        uint8_t bitEqualToOne;
+        READ(nr, bitEqualToOne, 1);
+        if (!bitEqualToOne)
+            ALOGW("Bit non equal to one.");
+
+        while (!nr->isByteAligned()) {
+            uint8_t bitEqualToZero;
+            READ(nr, bitEqualToZero, 1);
+            if (bitEqualToZero)
+                ALOGW("Bit non equal to zero.");
+        }
+    }
+
+    /* Always make sure all the advertised SEI bits
+     * were consumed during parsing */
+    if (next > nr->getPos()) {
+        ALOGV("Skipping %u unused SEI bits", next - nr->getPos());
+
+        if (!nr->skipLong(next - nr->getPos()))
+            goto error;
+    }
+
+    return res;
+
+error:
+    ALOGW("error parsing \"Sei message\"");
+    return Error;
+}
+
+/******** API *************/
+
+H264Parser::Result H264Parser::parseNal(const H264NalUnit &nalu) {
+    H264SPS sps;
+    H264PPS pps;
+
+    switch (nalu.type) {
+        case H264NalUnit::SPS:
+            return parseSPSUpdate(nalu, &sps);
+            break;
+        case H264NalUnit::PPS:
+            return parsePPSUpdate(nalu, &pps);
+    }
+
+    return Ok;
+}
+
+H264Parser::Result H264Parser::parseSPSUpdate(const H264NalUnit &nalu, H264SPS *sps) {
+    Result res = parseSPS(nalu, sps);
+
+    if (res == Ok) {
+        ALOGV("adding sequence parameter set with id: %d to array", sps->id);
+
+        mSPS[sps->id] = *sps;
+        mLastSPS = &mSPS[sps->id];
+    }
+    return res;
+}
+
+static bool parseSPSData(NalReader *nr, H264SPS *sps) {
+    int width, height;
+    unsigned int subwc[] = { 1, 2, 2, 1 };
+    unsigned int subhc[] = { 1, 2, 1, 1 };
+
+    /* set default values for fields that might not be present in the bitstream
+       and have valid defaults */
+    sps->extensionType = H264NalUnit::Extension::None;
+    sps->chromaFormatIDC = 1;
+    memset(sps->scalingLists4x4, 16, 96);
+    memset(sps->scalingLists8x8, 16, 384);
+
+    READ(nr, sps->profileIDC, 8);
+    READ(nr, sps->constraintSet0Flag, 1);
+    READ(nr, sps->constraintSet1Flag, 1);
+    READ(nr, sps->constraintSet2Flag, 1);
+    READ(nr, sps->constraintSet3Flag, 1);
+    READ(nr, sps->constraintSet4Flag, 1);
+    READ(nr, sps->constraintSet5Flag, 1);
+
+    /* skip reserved_zero_2bits */
+    if (!nr->skip(2))
+        goto error;
+
+    READ(nr, sps->levelIDC, 8);
+
+    READ_UE_MAX(nr, sps->id, H264_MAX_SPS_COUNT - 1);
+
+    if (sps->profileIDC == 100 || sps->profileIDC == 110 ||
+        sps->profileIDC == 122 || sps->profileIDC == 244 ||
+        sps->profileIDC == 44 || sps->profileIDC == 83 ||
+        sps->profileIDC == 86 || sps->profileIDC == 118 ||
+        sps->profileIDC == 128 || sps->profileIDC == 138 ||
+        sps->profileIDC == 139 || sps->profileIDC == 134 ||
+        sps->profileIDC == 135) {
+
+        READ_UE_MAX(nr, sps->chromaFormatIDC, 3);
+        if (sps->chromaFormatIDC == 3)
+            READ(nr, sps->separateColourPlaneFlag, 1);
+
+        READ_UE_MAX(nr, sps->bitDepthLumaMinus8, 6);
+        READ_UE_MAX(nr, sps->bitDepthChromaMinus8, 6);
+        READ(nr, sps->qpprimeYZeroTransformBypassFlag, 1);
+
+        READ(nr, sps->scalingMatrixPresentFlag, 1);
+        if (sps->scalingMatrixPresentFlag) {
+            uint8_t numLists;
+
+            numLists = (sps->chromaFormatIDC != 3) ? 8 : 12;
+            if (!parseScalingList (nr,
+                               sps->scalingLists4x4, sps->scalingLists8x8,
+                               default4x4Inter, default4x4Intra,
+                               default8x8Inter, default8x8Intra, numLists)) {
+                goto error;
+            }
+        }
+    }
+
+    READ_UE_MAX(nr, sps->log2MaxFrameNumMinus4, 12);
+
+    sps->maxFrameNum = 1 << (sps->log2MaxFrameNumMinus4 + 4);
+
+    READ_UE_MAX(nr, sps->picOrderCntType, 2);
+    if (sps->picOrderCntType == 0) {
+        READ_UE_MAX(nr, sps->log2MaxPicOrderCntLSBMinus4, 12);
+  } else if (sps->picOrderCntType == 1) {
+        unsigned int i;
+
+        READ(nr, sps->deltaPicOrderAlwaysZeroFlag, 1);
+        READ_SE(nr, sps->offsetForNonRefPic);
+        READ_SE(nr, sps->offsetForTopToBottomField);
+        READ_UE_MAX(nr, sps->numRefFramesInPicOrderCntCycle, 255);
+
+        for (i = 0; i < sps->numRefFramesInPicOrderCntCycle; i++)
+            READ_SE(nr, sps->offsetForRefFrame[i]);
+    }
+
+    READ_UE(nr, sps->numRefFrames);
+    READ(nr, sps->gapsInFrameNumValueAllowedFlag, 1);
+    READ_UE(nr, sps->picWidthInMBSMinus1);
+    READ_UE(nr, sps->picHeightInMapUnitsMinus1);
+    READ(nr, sps->frameMBSOnlyFlag, 1);
+
+    if (!sps->frameMBSOnlyFlag)
+        READ(nr, sps->mbAdaptiveFrameFieldFlag, 1);
+
+    READ(nr, sps->direct8x8InferenceFlag, 1);
+    READ(nr, sps->frameCroppingFlag, 1);
+    if (sps->frameCroppingFlag) {
+        READ_UE(nr, sps->frameCropLeftOffset);
+        READ_UE(nr, sps->frameCropRightOffset);
+        READ_UE(nr, sps->frameCropTopOffset);
+        READ_UE(nr, sps->frameCropBottomOffset);
+    }
+
+    READ(nr, sps->vuiParametersPresentFlag, 1);
+    if (sps->vuiParametersPresentFlag)
+        if (!parseVUIParameters(sps, nr))
+            goto error;
+
+    /* calculate ChromaArrayType */
+    if (!sps->separateColourPlaneFlag)
+        sps->chromaArrayType = sps->chromaFormatIDC;
+
+    /* Calculate  width and height */
+    width = (sps->picWidthInMBSMinus1 + 1);
+    width *= 16;
+    height = (sps->picHeightInMapUnitsMinus1 + 1);
+    height *= 16 * (2 - sps->frameMBSOnlyFlag);
+    ALOGV("initial width=%d, height=%d", width, height);
+    if (width < 0 || height < 0) {
+        ALOGW("invalid width/height in SPS");
+        goto error;
+    }
+
+    sps->width = width;
+    sps->height = height;
+
+    if (sps->frameCroppingFlag) {
+        const unsigned int cropUnitX = subwc[sps->chromaFormatIDC];
+        const unsigned int cropUnitY =
+            subhc[sps->chromaFormatIDC] * (2 - sps->frameMBSOnlyFlag);
+
+        width -= (sps->frameCropLeftOffset + sps->frameCropRightOffset)
+            * cropUnitX;
+        height -= (sps->frameCropTopOffset + sps->frameCropBottomOffset)
+            * cropUnitY;
+
+        sps->cropRectWidth = width;
+        sps->cropRectHeight = height;
+        sps->cropRectX = sps->frameCropLeftOffset * cropUnitX;
+        sps->cropRectY = sps->frameCropTopOffset * cropUnitY;
+
+        ALOGI("crop_rectangle x=%u y=%u width=%u, height=%u", sps->cropRectX,
+              sps->cropRectY, width, height);
+    }
+
+    sps->fpsNumRemoved = 0;
+    sps->fpsDenRemoved = 1;
+
+    return true;
+
+error:
+    return false;
+}
+
+H264Parser::Result H264Parser::parseSPS(const H264NalUnit &nalu, H264SPS *sps) {
+    ALOGI("parsing SPS");
+
+    NalReader nr(nalu.data + nalu.offset + nalu.headerBytes,
+                 nalu.size - nalu.headerBytes);
+
+    if (!parseSPSData(&nr, sps))
+        goto error;
+
+    sps->valid = true;
+
+    return Ok;
+
+error:
+    ALOGW("error parsing \"Sequence parameter set\"");
+    sps->valid = false;
+    return Error;
+}
+
+H264Parser::Result H264Parser::parsePPS(const H264NalUnit &nalu, H264PPS *pps) {
+    H264SPS *sps;
+    int spsId;
+    int qpBdOffset;
+
+    ALOGI("parsing PPS");
+
+    NalReader nr(nalu.data + nalu.offset + nalu.headerBytes,
+                 nalu.size - nalu.headerBytes);
+
+    READ_UE_MAX(&nr, pps->id, H264_MAX_PPS_COUNT - 1);
+    READ_UE_MAX(&nr, spsId, H264_MAX_SPS_COUNT - 1);
+
+    sps = getSPS(spsId);
+    if (!sps) {
+        ALOGW("couldn't find associated sequence parameter set with id: %d",
+              spsId);
+        return BrokenLink;
+    }
+    pps->sequence = sps;
+    qpBdOffset = 6 * (sps->bitDepthLumaMinus8 + sps->separateColourPlaneFlag);
+
+    /* set default values for fields that might not be present in the bitstream
+       and have valid defaults */
+    memcpy(&pps->scalingLists4x4, &sps->scalingLists4x4, 96);
+    memcpy(&pps->scalingLists8x8, &sps->scalingLists8x8, 384);
+
+    READ(&nr, pps->entropyCodingModeFlag, 1);
+    READ(&nr, pps->picOrderPresentFlag, 1);
+    READ_UE_MAX(&nr, pps->numSliceGroupsMinus1, 7);
+    if (pps->numSliceGroupsMinus1 > 0) {
+        READ_UE_MAX(&nr, pps->sliceGroupMapType, 6);
+
+        if (pps->sliceGroupMapType == 0) {
+            int i;
+
+            for (i = 0; i <= pps->numSliceGroupsMinus1; i++)
+                READ_UE(&nr, pps->runLengthMinus1[i]);
+        } else if (pps->sliceGroupMapType == 2) {
+            int i;
+
+            for (i = 0; i < pps->numSliceGroupsMinus1; i++) {
+                READ_UE(&nr, pps->topLeft[i]);
+                READ_UE(&nr, pps->bottomRight[i]);
+            }
+        } else if (pps->sliceGroupMapType >= 3 && pps->sliceGroupMapType <= 5) {
+            READ(&nr, pps->sliceGroupChangeDirectionFlag, 1);
+            READ_UE(&nr, pps->sliceGroupChangeRateMinus1);
+        } else if (pps->sliceGroupMapType == 6) {
+            int bits;
+            int i;
+
+            READ_UE(&nr, pps->picSizeInMapUnitsMinus1);
+            bits = (int)log2(pps->numSliceGroupsMinus1) + 1;
+
+            pps->sliceGroupId.clear();
+            for (i = 0; i <= pps->picSizeInMapUnitsMinus1; i++) {
+                uint8_t tmp;
+                READ(&nr, tmp, bits);
+                pps->sliceGroupId.push_back(tmp);
+            }
+        }
+    }
+
+    READ_UE_MAX(&nr, pps->numRefIdxL0ActiveMinus1, 31);
+    READ_UE_MAX(&nr, pps->numRefIdxL1ActiveMinus1, 31);
+    READ(&nr, pps->weightedPredFlag, 1);
+    READ(&nr, pps->weightedBipredIDC, 2);
+    READ_SE_ALLOWED (&nr, pps->picInitQPMinus26, -(26 + qpBdOffset), 25);
+    READ_SE_ALLOWED (&nr, pps->picInitQSMinus26, -26, 25);
+    READ_SE_ALLOWED (&nr, pps->chromaQPIndexOffset, -12, 12);
+    pps->secondChromaQPIndexOffset = pps->chromaQPIndexOffset;
+    READ(&nr, pps->deblockingFilterControlPresentFlag, 1);
+    READ(&nr, pps->constrainedIntraPredFlag, 1);
+    READ(&nr, pps->redundantPicCntPresentFlag, 1);
+
+    if (!nr.hasMoreData())
+        goto done;
+
+    READ(&nr, pps->transform8x8ModeFlag, 1);
+
+    READ(&nr, pps->picScalingMatrixPresentFlag, 1);
+    if (pps->picScalingMatrixPresentFlag) {
+        uint8_t numLists;
+
+        numLists = 6 + ((sps->chromaFormatIDC != 3) ? 2 : 6) *
+                    pps->transform8x8ModeFlag;
+
+        if (sps->scalingMatrixPresentFlag) {
+            if (!parseScalingList(&nr,
+                    pps->scalingLists4x4, pps->scalingLists8x8,
+                    sps->scalingLists4x4[3], sps->scalingLists4x4[0],
+                    sps->scalingLists8x8[3], sps->scalingLists8x8[0], numLists))
+                goto error;
+        } else {
+            if (!parseScalingList(&nr,
+                    pps->scalingLists4x4, pps->scalingLists8x8,
+                    default4x4Inter, default4x4Intra,
+                    default8x8Inter, default8x8Intra, numLists))
+                goto error;
+        }
+    }
+
+    READ_SE_ALLOWED(&nr, pps->secondChromaQPIndexOffset, -12, 12);
+
+done:
+    pps->valid = true;
+    return Ok;
+
+error:
+    ALOGW("error parsing \"Picture parameter set\"");
+    pps->valid = false;
+    return Error;
+}
+
+H264Parser::Result H264Parser::parsePPSUpdate(const H264NalUnit &nalu, H264PPS *pps) {
+    Result res = parsePPS(nalu, pps);
+
+    if (res == Ok) {
+        ALOGV("adding picture parameter set with id: %d to array", pps->id);
+
+        mPPS[pps->id] = *pps;
+        mLastPPS = &mPPS[pps->id];
+    }
+
+    return res;
+}
+
+H264Parser::Result H264Parser::parseSliceHdr(
+        const H264NalUnit &nalu, H264SliceHdr *slice,
+        bool /* parsePredWeightTable */, bool /* parseDecRefPicMarking */) {
+    int ppsId;
+    H264PPS *pps;
+    H264SPS *sps;
+    unsigned int startPos, startEPB;
+
+    if (!nalu.size) {
+        ALOGV("Invalid Nal Unit");
+        return Error;
+    }
+
+    NalReader nr(nalu.data + nalu.offset + nalu.headerBytes,
+                 nalu.size - nalu.headerBytes);
+
+    READ_UE(&nr, slice->firstMBInSlice);
+    READ_UE(&nr, slice->type);
+
+    ALOGV("parsing \"Slice header\", slice type %u", slice->type);
+
+    READ_UE_MAX(&nr, ppsId, H264_MAX_PPS_COUNT - 1);
+    pps = getPPS(ppsId);
+
+    if (!pps) {
+        ALOGW("couldn't find associated picture parameter set with id: %d",
+                ppsId);
+
+        return BrokenLink;
+    }
+
+    slice->pps = pps;
+    sps = pps->sequence;
+    if (!sps) {
+        ALOGW("couldn't find associated sequence parameter set with id: %d",
+                pps->id);
+        return BrokenLink;
+    }
+
+    /* Check we can actually parse this slice (AVC, MVC headers only) */
+    if (sps->extensionType &&
+            sps->extensionType != H264NalUnit::Extension::MVC) {
+        ALOGW("failed to parse unsupported slice header");
+        return BrokenData;
+    }
+
+    /* set default values for fields that might not be present in the bitstream
+       and have valid defaults */
+    if (slice->is(H264SliceHdr::I)) {
+        slice->numRefIdxL0ActiveMinus1 = 0;
+        slice->numRefIdxL1ActiveMinus1 = 0;
+    } else {
+        slice->numRefIdxL0ActiveMinus1 = pps->numRefIdxL0ActiveMinus1;
+
+        if (slice->is(H264SliceHdr::B))
+            slice->numRefIdxL1ActiveMinus1 = pps->numRefIdxL1ActiveMinus1;
+        else
+            slice->numRefIdxL1ActiveMinus1 = 0;
+    }
+
+    if (sps->separateColourPlaneFlag)
+        READ(&nr, slice->colourPlaneId, 2);
+
+    READ(&nr, slice->frameNum, sps->log2MaxFrameNumMinus4 + 4);
+
+    if (!sps->frameMBSOnlyFlag) {
+        READ(&nr, slice->fieldPicFlag, 1);
+        if (slice->fieldPicFlag)
+            READ(&nr, slice->bottomFieldFlag, 1);
+    }
+
+    /* calculate MaxPicNum */
+    if (slice->fieldPicFlag)
+        slice->maxPicNum = 2 * sps->maxFrameNum;
+    else
+        slice->maxPicNum = sps->maxFrameNum;
+
+    if (nalu.idrPicFlag)
+        READ_UE_MAX(&nr, slice->idrPicId, std::numeric_limits<uint16_t>::max());
+
+    startPos = nr.getPos();
+    startEPB = nr.getEPBCount();
+
+    if (sps->picOrderCntType == 0) {
+        READ(&nr, slice->picOrderCntLSB,
+                sps->log2MaxPicOrderCntLSBMinus4 + 4);
+
+        if (pps->picOrderPresentFlag && !slice->fieldPicFlag)
+            READ_SE(&nr, slice->deltaPicOrderCntBottom);
+    }
+
+    if (sps->picOrderCntType == 1 && !sps->deltaPicOrderAlwaysZeroFlag) {
+        READ_SE(&nr, slice->deltaPicOrderCnt[0]);
+        if (pps->picOrderPresentFlag && !slice->fieldPicFlag)
+            READ_SE(&nr, slice->deltaPicOrderCnt[1]);
+    }
+
+    slice->picOrderCntBitSize = (nr.getPos() - startPos) -
+        (8 * (nr.getEPBCount() - startEPB));
+
+    if (pps->redundantPicCntPresentFlag)
+        READ_UE_MAX(&nr, slice->redundantPicCnt, std::numeric_limits<int8_t>::max());
+
+    if (slice->is(H264SliceHdr::B))
+        READ(&nr, slice->directSpatialMVPredFlag, 1);
+
+    if (slice->is(H264SliceHdr::P) || slice->is(H264SliceHdr::SP) ||
+            slice->is(H264SliceHdr::B)) {
+        READ(&nr, slice->numRefIdxActiveOverrideFlag, 1);
+        if (slice->numRefIdxActiveOverrideFlag) {
+            READ_UE_MAX(&nr, slice->numRefIdxL0ActiveMinus1, 31);
+
+            if (slice->is(H264SliceHdr::B))
+                READ_UE_MAX(&nr, slice->numRefIdxL1ActiveMinus1, 31);
+        }
+    }
+
+    if (!sliceParseRefPicListModification(slice, &nr,
+                H264_IS_MVC_NALU(nalu)))
+        goto error;
+
+    if ((pps->weightedPredFlag && (slice->is(H264SliceHdr::P)
+                    || slice->is(H264SliceHdr::SP)))
+            || (pps->weightedBipredIDC == 1 && slice->is(H264SliceHdr::B))) {
+        if (!h264SliceParsePredWeightTable(slice, &nr,
+                    sps->chromaArrayType))
+            goto error;
+    }
+
+    if (nalu.refIDC != 0) {
+        if (!h264SliceParseDecRefPicMarking(slice, nalu, &nr))
+            goto error;
+    }
+
+    if (pps->entropyCodingModeFlag && !slice->is(H264SliceHdr::I) &&
+            !slice->is(H264SliceHdr::SI))
+        READ_UE_MAX(&nr, slice->cabacInitIDC, 2);
+
+    READ_SE_ALLOWED(&nr, slice->sliceQPDelta, -87, 77);
+
+    if (slice->is(H264SliceHdr::SP) || slice->is(H264SliceHdr::SI)) {
+        if (slice->is(H264SliceHdr::SP))
+            READ(&nr, slice->spForSwitchFlag, 1);
+        READ_SE_ALLOWED(&nr, slice->sliceQSDelta, -51, 51);
+    }
+
+    if (pps->deblockingFilterControlPresentFlag) {
+        READ_UE_MAX(&nr, slice->disableDeblockingFilterIDC, 2);
+        if (slice->disableDeblockingFilterIDC != 1) {
+            READ_SE_ALLOWED(&nr, slice->sliceAlphaC0OffsetDiv2, -6, 6);
+            READ_SE_ALLOWED(&nr, slice->sliceBetaOffsetDiv2, -6, 6);
+        }
+    }
+
+    if (pps->numSliceGroupsMinus1 > 0 &&
+            pps->sliceGroupMapType >= 3 && pps->sliceGroupMapType <= 5) {
+        /* Ceil(Log2(PicSizeInMapUnits / SliceGroupChangeRate + 1))  [7-33] */
+        uint32_t picWidthInMbs = sps->picWidthInMBSMinus1 + 1;
+        uint32_t picHeightInMapUnits = sps->picHeightInMapUnitsMinus1 + 1;
+        uint32_t picSizeInMapUnits = picWidthInMbs * picHeightInMapUnits;
+        uint32_t sliceGroupChangeRate = pps->sliceGroupChangeRateMinus1 + 1;
+        const unsigned int n = ceilLog2(picSizeInMapUnits / sliceGroupChangeRate + 1);
+        READ(&nr, slice->sliceGroupChangeCycle, n);
+    }
+
+    slice->headerSize = nr.getPos();
+    slice->nEmulationPreventionBytes = nr.getEPBCount();
+
+    return Ok;
+
+error:
+    ALOGW("error parsing \"Slice header\"");
+    return Error;
+}
+
+H264Parser::Result H264Parser::parseSEI(
+        const H264NalUnit &nalu, std::vector<H264SEIMessage> *messages) {
+    ALOGI("parsing SEI nal");
+
+    if (messages == nullptr)
+        return Error;
+
+    Result res;
+    NalReader nr(nalu.data + nalu.offset + nalu.headerBytes,
+                 nalu.size - nalu.headerBytes);
+
+    do {
+        H264SEIMessage sei;
+        res = parseSEIMessage(&nr, &sei);
+        if (res == Ok)
+            messages->push_back(std::move(sei));
+        else
+            break;
+    } while (nr.hasMoreData());
+
+    return res;
+}
+
+H264Parser::Result H264Parser::updateSPS(const H264SPS &sps) {
+    if (sps.id < 0 || sps.id >= H264_MAX_SPS_COUNT) {
+        ALOGW("SPS has invalid id: %d", sps.id);
+        return Error;
+    }
+
+    if (!sps.valid) {
+        ALOGW("Cannot update with invalid SPS");
+        return Error;
+    }
+
+    ALOGI("Updating sequence parameter set with id: %d", sps.id);
+
+    mSPS[sps.id] = sps;
+    mLastSPS = &mSPS[sps.id];
+
+    return Ok;
+}
+
+H264Parser::Result H264Parser::updatePPS(const H264PPS &pps) {
+    H264SPS *sps;
+
+    if (pps.id < 0 || pps.id >= H264_MAX_PPS_COUNT) {
+        ALOGW("PPS has invalid id: %d", pps.id);
+        return Error;
+    }
+
+    if (!pps.valid) {
+        ALOGW("Cannot update with invalid PPS");
+        return Error;
+    }
+
+    if (!pps.sequence) {
+        ALOGW("No linked SPS struct");
+        return BrokenLink;
+    }
+
+    sps = getSPS(pps.sequence->id);
+    if (!sps || sps != pps.sequence) {
+        ALOGW("Linked SPS is not identical to internal SPS");
+        return BrokenLink;
+    }
+
+    ALOGI("Updating picture parameter set with id: %d", pps.id);
+
+    mPPS[pps.id] = pps;
+    mLastPPS = &mPPS[pps.id];
+
+    return Ok;
+}
+
+} // namespace
diff --git a/components/h264/parser/NalReader.cpp b/components/h264/parser/NalReader.cpp
new file mode 100644
index 0000000..1e0dcd3
--- /dev/null
+++ b/components/h264/parser/NalReader.cpp
@@ -0,0 +1,193 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * Gstreamer
+ * Copyright (C) <2011> Intel Corporation
+ * Copyright (C) <2011> Collabora Ltd.
+ * Copyright (C) <2011> Thibault Saunier <thibault.saunier@collabora.com>
+ *
+ * Some bits C-c,C-v'ed and s/4/3 from h264parse and videoparsers/h264parse.c:
+ *    Copyright (C) <2010> Mark Nauwelaerts <mark.nauwelaerts@collabora.co.uk>
+ *    Copyright (C) <2010> Collabora Multimedia
+ *    Copyright (C) <2010> Nokia Corporation
+ *
+ *    (C) 2005 Michal Benes <michal.benes@itonis.tv>
+ *    (C) 2008 Wim Taymans <wim.taymans@gmail.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#include <v4l2_codec2/components/h264/parser/NalReader.h>
+
+#include <log/log.h>
+
+namespace android {
+
+NalReader::NalReader(const uint8_t *data, uint32_t size)
+    : mData(data),
+      mSize(size),
+      mNumEPB(0),
+      mByte(0),
+      mBitsInCache(0),
+      mFirstByte(0xff),
+      mEpbCache(0xff),
+      mCache(0xff)
+{ }
+
+bool NalReader::read(uint32_t numBits) {
+    if (mByte * 8 + (numBits - mBitsInCache) > mSize * 8) {
+        ALOGE("Can not read %u bits, bits in cache %u, byte * 8 %u, size in "
+              "bits %u", numBits, mBitsInCache, mByte * 8, mSize * 8);
+        return false;
+    }
+
+    while (mBitsInCache < numBits) {
+        uint8_t byte;
+
+    next_byte:
+        if (mByte >= mSize)
+            return false;
+
+        byte = mData[mByte++];
+        mEpbCache = (mEpbCache << 8) | byte;
+
+        /* check if the byte is a emulation_prevention_three_byte */
+        if ((mEpbCache & 0xffffff) == 0x3) {
+            mNumEPB++;
+            goto next_byte;
+        }
+
+        mCache = (mCache << 8) | mFirstByte;
+        mFirstByte = byte;
+        mBitsInCache += 8;
+    }
+
+    return true;
+}
+
+bool NalReader::skip(uint32_t numBits) {
+    if (!(numBits <= 8 * sizeof(mCache)))
+        return false;
+
+    if (!read(numBits))
+        return false;
+
+    mBitsInCache -= numBits;
+
+    return true;
+}
+
+bool NalReader::skipLong(uint32_t numBits) {
+    const uint32_t skipSize = 4 * sizeof(mCache);
+    unsigned int remaining = numBits;
+
+    numBits %= skipSize;
+    while (remaining > 0) {
+        if (!skip(numBits))
+            return false;
+        remaining -= numBits;
+        numBits = skipSize;
+    }
+
+    return true;
+}
+
+uint32_t NalReader::getPos() const {
+    return mByte * 8 - mBitsInCache;
+}
+
+uint32_t NalReader::getRemaining() const {
+    return (mSize - mByte) * 8 + mBitsInCache;
+}
+
+uint32_t NalReader::getEPBCount() const {
+    return mNumEPB;
+}
+
+bool NalReader::getUE(uint32_t *val) {
+    uint32_t i = 0;
+    uint8_t bit;
+    uint32_t value;
+
+    if (!getBits(&bit, 1))
+        return false;
+
+    while (bit == 0) {
+        i++;
+        if (!getBits(&bit, 1))
+            return false;
+    }
+
+    if (i > 31)
+        return false;
+
+    if (!getBits(&value, i))
+        return false;
+
+    *val = (1 << i) - 1 + value;
+
+    return true;
+}
+
+bool NalReader::getSE(int32_t *val) {
+    uint32_t value;
+
+    if (!getUE(&value))
+        return false;
+
+    if (value % 2)
+        *val = (value / 2) + 1;
+    else
+        *val = -(value / 2);
+
+    return true;
+}
+
+bool NalReader::isByteAligned() const {
+    return mBitsInCache == 0;
+}
+
+bool NalReader::hasMoreData() const {
+    uint32_t remaining;
+    uint32_t numBits;
+    uint8_t rbspStopOneBit;
+    uint8_t zeroBits;
+
+    remaining = getRemaining();
+    if (remaining == 0)
+        return false;
+
+    NalReader temp = *this;
+
+    if (!temp.getBits(&rbspStopOneBit, 1))
+        return false;
+    if (!rbspStopOneBit)
+        return true;
+
+    numBits = --remaining % 8;
+    while (remaining > 0) {
+        if (!temp.getBits(&zeroBits, numBits))
+            return false;
+        if (zeroBits != 0)
+            return true;
+        remaining -= numBits;
+        numBits = 8;
+    }
+
+    return false;
+}
+
+} // android
diff --git a/components/include/v4l2_codec2/components/V4L2DecodeInterface.h b/components/include/v4l2_codec2/components/V4L2DecodeInterface.h
index f2ab898..bc7898b 100644
--- a/components/include/v4l2_codec2/components/V4L2DecodeInterface.h
+++ b/components/include/v4l2_codec2/components/V4L2DecodeInterface.h
@@ -25,6 +25,7 @@ public:
 
     // interfaces for the client component.
     c2_status_t status() const { return mInitStatus; }
+    C2AllocatorStore::id_t getOutputAllocatorId() const { return mOutputAllocatorIds->m.values[0]; }
     C2BlockPool::local_id_t getBlockPoolId() const { return mOutputBlockPoolIds->m.values[0]; }
     std::optional<VideoCodec> getVideoCodec() const { return mVideoCodec; }
 
diff --git a/components/include/v4l2_codec2/components/V4L2Decoder.h b/components/include/v4l2_codec2/components/V4L2Decoder.h
index 2ecb3bd..449ecb7 100644
--- a/components/include/v4l2_codec2/components/V4L2Decoder.h
+++ b/components/include/v4l2_codec2/components/V4L2Decoder.h
@@ -25,16 +25,42 @@ namespace android {
 
 class V4L2Decoder : public VideoDecoder {
 public:
-    static std::unique_ptr<VideoDecoder> Create(
-            const VideoCodec& codec, const size_t inputBufferSize, const size_t minNumOutputBuffers,
-            GetPoolCB getPoolCB, OutputCB outputCb, ErrorCB errorCb,
-            scoped_refptr<::base::SequencedTaskRunner> taskRunner);
     ~V4L2Decoder() override;
 
     void decode(std::unique_ptr<ConstBitstreamBuffer> buffer, DecodeCB decodeCb) override;
     void drain(DecodeCB drainCb) override;
     void flush() override;
 
+    void release(int id);
+
+protected:
+    V4L2Decoder(scoped_refptr<::base::SequencedTaskRunner> taskRunner);
+
+    virtual bool start(const VideoCodec &codec, size_t inputBufferSize,
+                       GetPoolCB getPoolCb, OutputCB outputCb, ErrorCB errorCb);
+
+    bool changeResolution(const ui::Size &size, std::vector<V4L2ExtCtrl> &controls);
+
+    typedef std::shared_ptr<void> ResultHandle;
+    typedef std::shared_ptr<void> RequestHandle;
+
+    RequestHandle allocRequest(int bitstreamId);
+    RequestHandle allocSubRequest(ResultHandle previous);
+
+    // The child must hang on the returned data until it is safe to release
+    // the decoded data (when the decoded data is not used as reference anymore)
+    ResultHandle submitRequest(RequestHandle, std::vector<V4L2ExtCtrl> &controls, uint32_t flags);
+    bool ensureInputBuffer();
+    void finish(int id);
+
+    virtual bool decode(std::unique_ptr<ConstBitstreamBuffer> buffer) = 0;
+    virtual void flushInternal() = 0;
+    virtual bool drainInternal() = 0;
+
+    scoped_refptr<MediaDevice> mMedia;
+    scoped_refptr<V4L2Device> mDevice;
+    std::optional<V4L2WritableBufferRef> mInputBuffer;
+
 private:
     enum class State {
         Idle,  // Not received any decode buffer after initialized, flushed, or drained.
@@ -54,53 +80,73 @@ private:
         DecodeCB decodeCb;
     };
 
-    V4L2Decoder(scoped_refptr<::base::SequencedTaskRunner> taskRunner);
-    bool start(const VideoCodec& codec, const size_t inputBufferSize,
-               const size_t minNumOutputBuffers, GetPoolCB getPoolCb, OutputCB outputCb,
-               ErrorCB errorCb);
-    bool setupInputFormat(const uint32_t inputPixelFormat, const size_t inputBufferSize);
+    struct V4L2Result {
+        int frameNum;
+        V4L2ReadableBufferRef outputBuffer;
+    };
+
+    struct V4L2Request {
+        int frameNum;
+        scoped_refptr<MediaRequest> request;
+        std::shared_ptr<V4L2Result> result;
+    };
+
     void pumpDecodeRequest();
 
     void serviceDeviceTask(bool event);
     bool dequeueResolutionChangeEvent();
-    bool changeResolution();
-    bool setupOutputFormat(const ui::Size& size);
+    bool setupInputFormat(const ui::Size &size);
+    bool setupOutputFormat(const ui::Size &size);
 
+    void tryOutputFrame();
     void tryFetchVideoFrame();
     void onVideoFrameReady(std::optional<VideoFramePool::FrameWithBlockId> frameWithBlockId);
 
     std::optional<size_t> getNumOutputBuffers();
     std::optional<struct v4l2_format> getFormatInfo();
-    Rect getVisibleRect(const ui::Size& codedSize);
     bool sendV4L2DecoderCmd(bool start);
 
     void setState(State newState);
     void onError();
 
-    std::unique_ptr<VideoFramePool> mVideoFramePool;
+    struct VideoFramePoolInfo {
+        std::unique_ptr<VideoFramePool> pool;
+        bool active;
+
+        // The frame pool must be kept until all frames are sent back to the
+        // client.
+        // If the pool is not used anymore (active = false) and must be deleted,
+        // the deleteDelay variable will be set to the number of frames that
+        // still need to be outputted.
+        int deleteDelay;
+    };
+    std::list<VideoFramePoolInfo> mVideoFramePools;
+
+    // Current video frames fetched from the active pool
+    std::queue<std::unique_ptr<VideoFrame>> mVideoFrames;
 
-    scoped_refptr<V4L2Device> mDevice;
     scoped_refptr<V4L2Queue> mInputQueue;
     scoped_refptr<V4L2Queue> mOutputQueue;
 
+    // Newcoming requests to process
     std::queue<DecodeRequest> mDecodeRequests;
-    std::map<int32_t, DecodeCB> mPendingDecodeCbs;
+    // Pending requests in the input queue
+    std::queue<std::shared_ptr<V4L2Request>> mPendingRequest;
+    // Pending result in the output queue
+    std::queue<std::shared_ptr<V4L2Result>> mPendingResult;
+    /* Completed frame waiting to be sent back to the client */
+    std::map<int32_t, std::unique_ptr<VideoFrame>> mCompletedFrames;
+    /* Queue of frames to output */
+    std::queue<int32_t> mFrameToOutput;
 
-    size_t mMinNumOutputBuffers = 0;
     GetPoolCB mGetPoolCb;
     OutputCB mOutputCb;
     DecodeCB mDrainCb;
     ErrorCB mErrorCb;
 
+    uint32_t mInputPixelFormat;
+    size_t mInputBufferSize;
     ui::Size mCodedSize;
-    Rect mVisibleRect;
-
-    std::map<size_t, std::unique_ptr<VideoFrame>> mFrameAtDevice;
-
-    // Block IDs can be arbitrarily large, but we only have a limited number of
-    // buffers. This maintains an association between a block ID and a specific
-    // V4L2 buffer index.
-    std::map<size_t, size_t> mBlockIdToV4L2Id;
 
     State mState = State::Idle;
 
diff --git a/components/include/v4l2_codec2/components/VideoFrame.h b/components/include/v4l2_codec2/components/VideoFrame.h
index b5d7b99..bc99ed4 100644
--- a/components/include/v4l2_codec2/components/VideoFrame.h
+++ b/components/include/v4l2_codec2/components/VideoFrame.h
@@ -35,6 +35,10 @@ public:
     // Get the read-only C2GraphicBlock, should be called after calling setVisibleRect().
     C2ConstGraphicBlock getGraphicBlock();
 
+    std::shared_ptr<C2GraphicBlock> graphicBlock() {
+        return mGraphicBlock;
+    }
+
 private:
     VideoFrame(std::shared_ptr<C2GraphicBlock> block, std::vector<int> fds);
 
diff --git a/components/include/v4l2_codec2/components/h264/H264Decoder.h b/components/include/v4l2_codec2/components/h264/H264Decoder.h
new file mode 100644
index 0000000..6d31117
--- /dev/null
+++ b/components/include/v4l2_codec2/components/h264/H264Decoder.h
@@ -0,0 +1,232 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * GStreamer
+ * Copyright (C) 2019 Seungha Yang <seungha.yang@navercorp.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ *
+ * Copyright 2015 The Chromium Authors. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *    * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *    * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *    * Neither the name of Google Inc. nor the names of its
+ * contributors may be used to endorse or promote products derived from
+ * this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef ANDROID_V4L2_CODEC2_COMPONENTS_H264_DECODER_H
+#define ANDROID_V4L2_CODEC2_COMPONENTS_H264_DECODER_H
+
+#include <stdint.h>
+
+#include <memory>
+#include <optional>
+
+#include <base/callback.h>
+#include <base/memory/weak_ptr.h>
+
+#include <ui/Rect.h>
+#include <ui/Size.h>
+#include <v4l2_codec2/common/V4L2Device.h>
+#include <v4l2_codec2/common/VideoTypes.h>
+#include <v4l2_codec2/components/VideoDecoder.h>
+#include <v4l2_codec2/components/VideoFrame.h>
+#include <v4l2_codec2/components/VideoFramePool.h>
+#include <v4l2_codec2/components/h264/parser/H264Parser.h>
+#include <v4l2_codec2/components/h264/parser/H264DPB.h>
+
+namespace android {
+
+class H264Decoder {
+public:
+    enum Compliance {
+        Auto,
+        Strict,
+        Normal,
+        Flexible,
+    };
+
+public:
+    virtual ~H264Decoder();
+
+protected:
+    H264Decoder();
+
+    void setProcessRefPicLists(bool process) { mProcessRefPicLists = process; }
+
+    bool decode(std::unique_ptr<ConstBitstreamBuffer> buffer);
+    void flush();
+    bool drain();
+
+    virtual bool newSequence(const H264SPS &sps, int maxDPBSize) = 0;
+
+    virtual bool newFieldPicture(const H264PicturePtr &picture,
+            const H264PicturePtr &new_picture) = 0;
+
+    virtual bool startPicture(const H264PicturePtr &picture,
+            const H264Slice &slice, const H264DPB &dpb) { return true; }
+
+    virtual bool decodeSlice(const H264PicturePtr &picture,
+                             const H264Slice &slice,
+                             const std::list<H264PicturePtr> &refPicList0,
+                             const std::list<H264PicturePtr> &refPicList1) = 0;
+
+    virtual bool endPicture(const H264PicturePtr &picture) { return true; }
+
+    virtual bool outputPicture(const H264PicturePtr &picture) = 0;
+
+    virtual unsigned int getPreferredOutputDelay(bool live) { return 0; }
+
+private:
+    int getMaxNumReorderFrames(const H264SPS &sps, int maxDpbSize);
+
+    bool parseSPS(const H264NalUnit &nalu);
+    bool processSPS(const H264SPS &sps);
+
+    bool parsePPS(const H264NalUnit &nalu);
+
+    bool parseSlice(const H264NalUnit &nalu);
+    bool preprocessSlice(const H264Slice &slice);
+    bool decodeSlice();
+
+    bool modifyRefPicLists();
+    bool modifyRefPicList(int list);
+    int longTermPicNumF(const H264PicturePtr &picture);
+    int picNumF(const H264PicturePtr &picture);
+
+    void clearRefPicLists();
+
+    bool handleFrameNumGap(int frameNum);
+    bool initGapPicture(const H264PicturePtr &picture, int frameNum);
+
+    bool referencePictureMarking(const H264PicturePtr &picture);
+    bool handleMemoryManagementOpt(const H264PicturePtr &picture);
+    bool slidingWindowPictureMarking(const H264PicturePtr &picture);
+
+    bool finishCurrentPicture();
+    bool finishPicture(const H264PicturePtr &picture);
+    H264DPB::BumpMode getBumpLevel() const;
+    bool bumpDPB(H264DPB::BumpMode bumpLevel, const H264PicturePtr &currentPicture);
+    bool doOutputPicture(const H264PicturePtr &picture);
+
+    H264PicturePtr splitFrame(const H264PicturePtr &picture);
+    H264PicturePtr newFieldPicture(const H264PicturePtr &picture);
+    bool findFirstFieldPicture(const H264Slice &slice, H264PicturePtr &firstField);
+
+    bool startCurrentPicture();
+    bool initCurrentPicture();
+    bool fillPictureFromSlice(const H264Slice &slice, const H264PicturePtr &picture);
+    bool calculatePOC(const H264PicturePtr &picture);
+    void updatePicNums(const H264PicturePtr &currentPicture, int frameNum);
+    void addPictureToDPB(const H264PicturePtr &picture);
+    void clearDPB();
+
+    void prepareRefPicLists(const H264PicturePtr &currentPicture);
+    void constructRefPicListsP(const H264PicturePtr &currentPicture);
+    void constructRefPicListsB(const H264PicturePtr &currentPicture);
+    void constructRefFieldPicListsP(const H264PicturePtr &currentPicture);
+    void constructRefFieldPicListsB(const H264PicturePtr &currentPicture);
+
+    bool drainInternal();
+    bool drainOutputQueue(unsigned int num);
+
+    bool outputPictureDirectly(const H264PicturePtr &picture);
+
+private:
+    std::unique_ptr<ConstBitstreamBuffer> mCurrentFrame;
+
+    /* state */
+    H264Parser mParser;
+    H264DPB mDPB;
+    /* Cache last field which can not enter the DPB, shoud be a non ref */
+    H264PicturePtr mLastField;
+
+    Compliance mCompliance;
+
+    uint8_t mProfileIDC;
+    int mWidth;
+    int mHeight;
+
+    /* used for low-latency vs. high throughput mode decision */
+    bool mIsLive;
+
+    /* sps/pps of the current slice */
+    H264SPS *mActiveSPS;
+    H264PPS *mActivePPS;
+
+    /* Picture currently being processed/decoded */
+    H264PicturePtr mCurrentPicture;
+
+    /* Slice (slice header + nalu) currently being processed / decoded */
+    H264Slice mCurrentSlice;
+
+    int mMaxFrameNum;
+    int mMaxPicNum;
+    int mMaxLongTermFrameIdx;
+
+    int mPrevFrameNum;
+    int mPrevRefFrameNum;
+    int mPrevFrameNumOffset;
+    bool mPrevHasMemMgmnt5;
+
+    /* Values related to previously decoded reference picture */
+    bool mPrevRefHasMemMgmnt5;
+    int mPrevRefTopFieldOrderCnt;
+    int mPrevRefPicOrderCntMsb;
+    int mPrevRefPicOrderCntLsb;
+
+    H264Picture::Field mPrevRefField;
+
+    bool mProcessRefPicLists;
+    unsigned int mPreferredOutputDelay;
+
+    /* Reference picture lists, constructed for each frame */
+    std::list<H264PicturePtr> mRefPicListP0;
+    std::list<H264PicturePtr> mRefPicListB0;
+    std::list<H264PicturePtr> mRefPicListB1;
+
+    /* Reference picture lists, constructed for each slice */
+    std::list<H264PicturePtr> mRefPicList0;
+    std::list<H264PicturePtr> mRefPicList1;
+
+    /* For delayed output */
+    std::queue<H264PicturePtr> mOutputQueue;
+};
+
+}  // namespace android
+
+#endif  // ANDROID_V4L2_CODEC2_COMPONENTS_H264_DECODER_H
diff --git a/components/include/v4l2_codec2/components/h264/V4L2H264Decoder.h b/components/include/v4l2_codec2/components/h264/V4L2H264Decoder.h
new file mode 100644
index 0000000..5b27b76
--- /dev/null
+++ b/components/include/v4l2_codec2/components/h264/V4L2H264Decoder.h
@@ -0,0 +1,115 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * GStreamer
+ * Copyright (C) 2020 Nicolas Dufresne <nicolas.dufresne@collabora.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef ANDROID_V4L2_CODEC2_COMPONENTS_V4L2_H264_DECODER_H
+#define ANDROID_V4L2_CODEC2_COMPONENTS_V4L2_H264_DECODER_H
+
+#include <v4l2_codec2/components/V4L2Decoder.h>
+#include <v4l2_codec2/components/h264/H264Decoder.h>
+
+namespace android {
+
+class V4L2H264Decoder : public V4L2Decoder, public H264Decoder {
+
+public:
+    static std::unique_ptr<VideoDecoder> Create(
+        const size_t inputBufferSize,
+        GetPoolCB getPoolCb, OutputCB outputCb, ErrorCB errorCb,
+        scoped_refptr<::base::SequencedTaskRunner> taskRunner);
+
+    virtual ~V4L2H264Decoder();
+
+protected:
+    V4L2H264Decoder(scoped_refptr<::base::SequencedTaskRunner> taskRunner);
+
+    // V4L2Decoder
+    bool start(const VideoCodec &codec, size_t inputBufferSize,
+               GetPoolCB getPoolCb, OutputCB outputCb, ErrorCB errorCb);
+    bool decode(std::unique_ptr<ConstBitstreamBuffer> buffer) override;
+    void flushInternal() override;
+    bool drainInternal() override;
+
+    // H264Decoder
+    virtual bool newSequence(const H264SPS &sps, int maxDPBSize) override;
+
+    virtual bool newFieldPicture(const H264PicturePtr &picture,
+            const H264PicturePtr &new_picture) override;
+
+    virtual bool startPicture(const H264PicturePtr &picture,
+            const H264Slice &slice, const H264DPB &dpb) override;
+
+    virtual bool decodeSlice(const H264PicturePtr &picture,
+                             const H264Slice &slice,
+                             const std::list<H264PicturePtr> &refPicList0,
+                             const std::list<H264PicturePtr> &refPicList1) override;
+
+    virtual bool endPicture(const H264PicturePtr &picture) override;
+
+    virtual bool outputPicture(const H264PicturePtr &picture) override;
+
+    virtual unsigned int getPreferredOutputDelay(bool live) override;
+
+private:
+    bool negotiate();
+    void fillSequence(const H264SPS &sps);
+    void fillPPS(H264PPS *pps);
+    void fillScallingMatrix(H264PPS *pps);
+    void fillDecoderParams(const H264SliceHdr &sliceHdr,
+        const H264PicturePtr &picture, const H264DPB &dpb);
+    void fillSliceParams(const H264Slice &slice);
+    void fillPredWeight(const H264SliceHdr &sliceHdr);
+    void fillReferences(bool curIsFrame,
+        const std::list<H264PicturePtr> &refPicList0,
+        const std::list<H264PicturePtr> &refPicList1);
+
+    bool submitBitstream(const H264PicturePtr &picture, unsigned int flags);
+    void resetPicture();
+
+private:
+    int mDisplayWidth;
+    int mDisplayHeight;
+    int mCodedWidth;
+    int mCodedHeight;
+    unsigned int mBitdepth;
+    unsigned int mChromaFormatIDC;
+    bool mFirstSlice;
+
+    int mMinPoolSize;
+    bool mInterlaced;
+    bool mNeedSequence;
+    bool mScalingMatrixPresent;
+
+    enum v4l2_stateless_h264_decode_mode mDecodeMode;
+    enum v4l2_stateless_h264_start_code mStartCode;
+
+    struct v4l2_ctrl_h264_sps mSPS;
+    struct v4l2_ctrl_h264_pps mPPS;
+    struct v4l2_ctrl_h264_scaling_matrix mScalingMatrix;
+    struct v4l2_ctrl_h264_decode_params mDecodeParams;
+    struct v4l2_ctrl_h264_pred_weights mPredWeight;
+    std::vector<struct v4l2_ctrl_h264_slice_params> mSliceParams;
+
+};
+
+} // android
+
+#endif // ANDROID_V4L2_CODEC2_COMPONENTS_V4L2_H264_DECODER_H
diff --git a/components/include/v4l2_codec2/components/h264/parser/H264DPB.h b/components/include/v4l2_codec2/components/h264/parser/H264DPB.h
new file mode 100644
index 0000000..238568c
--- /dev/null
+++ b/components/include/v4l2_codec2/components/h264/parser/H264DPB.h
@@ -0,0 +1,117 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * GStreamer
+ * Copyright (C) 2019 Seungha Yang <seungha.yang@navercorp.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef ANDROID_V4L2_CODEC2_COMMON_H264_DBP_H
+#define ANDROID_V4L2_CODEC2_COMMON_H264_DBP_H
+
+#include <cstdint>
+#include <list>
+
+#include "H264Picture.h"
+
+/* As specified in A.3.1 h) and A.3.2 f) */
+#define H264_DPB_MAX_SIZE 16
+
+namespace android {
+
+class H264DPB {
+
+public:
+    enum BumpMode {
+        NormalLatency,
+        LowLatency,
+        VeryLowLatency,
+    };
+
+public:
+    H264DPB();
+
+    void setMaxNumFrames(int maxNumFrames);
+    int getMaxNumFrames() const;
+
+    void setInterlaced(bool interlaced);
+    bool getInterlaced() const;
+
+    int32_t getLastOutputPoc() const;
+
+    void clear();
+
+    void setMaxNumReorderFrames(uint32_t maxNumReorderFrames);
+    uint32_t getMaxNumReorderFrames() const;
+
+    void add(const H264PicturePtr &picture);
+
+    void deleteUnused();
+
+    int numRefFrames() const;
+
+    void markAllNonRef();
+
+    std::shared_ptr<H264Picture> getShortRefByPicNum(int picNum) const;
+
+    std::shared_ptr<H264Picture> getLongRefByLongTermPicNum(int longTermPicNum) const;
+
+    std::shared_ptr<H264Picture> getLowestFrameNumShortRef() const;
+
+    void getPicturesShortTermRef(bool includeNonExisting,
+                                 bool includeSecondField,
+                                 std::list<H264PicturePtr> &out) const;
+
+    void getPicturesLongTermRef(bool includeSecondField,
+                                std::list<H264PicturePtr> &out) const;
+
+    const std::list<H264PicturePtr> &getPicturesAll() const;
+
+    int getSize() const;
+
+    H264PicturePtr getPicture(uint32_t systemFrameNumber) const;
+
+    bool hasEmptyFrameBuffer() const;
+
+    bool needsBump(const H264PicturePtr &toInsert, BumpMode latencyMode) const;
+
+    H264PicturePtr bump(bool drain);
+
+    void setLastOutput(const H264PicturePtr &picture);
+
+    bool performMemoryManagementControlOperation(
+        const H264RefPicMarking &refPicMarking, const H264PicturePtr &picture);
+
+private:
+    int getLowestOutputNeededPicture(bool force,
+            H264PicturePtr &picture,
+            std::list<H264PicturePtr>::const_iterator *picIt = nullptr) const;
+
+private:
+    std::list<H264PicturePtr> mPicList;
+    int mMaxNumFrames;
+    int mNumOutputNeeded;
+    uint32_t mMaxNumReorderFrames;
+    int32_t mLastOutputPoc;
+    bool mLastOutputNonRef;
+
+    bool mInterlaced;
+};
+
+} // android
+
+#endif // ANDROID_V4L2_CODEC2_COMMON_H264_DBP_H
diff --git a/components/include/v4l2_codec2/components/h264/parser/H264NalUnit.h b/components/include/v4l2_codec2/components/h264/parser/H264NalUnit.h
new file mode 100644
index 0000000..08b95a9
--- /dev/null
+++ b/components/include/v4l2_codec2/components/h264/parser/H264NalUnit.h
@@ -0,0 +1,102 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * Gstreamer
+ * Copyright (C) <2011> Intel Corporation
+ * Copyright (C) <2011> Collabora Ltd.
+ * Copyright (C) <2011> Thibault Saunier <thibault.saunier@collabora.com>
+ *
+ * Some bits C-c,C-v'ed and s/4/3 from h264parse and videoparsers/h264parse.c:
+ *    Copyright (C) <2010> Mark Nauwelaerts <mark.nauwelaerts@collabora.co.uk>
+ *    Copyright (C) <2010> Collabora Multimedia
+ *    Copyright (C) <2010> Nokia Corporation
+ *
+ *    (C) 2005 Michal Benes <michal.benes@itonis.tv>
+ *    (C) 2008 Wim Taymans <wim.taymans@gmail.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef ANDROID_V4L2_CODEC2_COMMON_H264_NAL_UNIT_H
+#define ANDROID_V4L2_CODEC2_COMMON_H264_NAL_UNIT_H
+
+#include <cstdint>
+
+#define H264_IS_MVC_NALU(nalu) \
+    ((nalu).extensionType == H264NalUnit::MVC)
+
+namespace android {
+
+struct H264NalUnitExtensionMVC {
+    uint8_t nonIdrFlag;
+    uint8_t priorityId;
+    uint16_t viewId;
+    uint8_t temporalId;
+    uint8_t anchorPicFlag;
+    uint8_t interViewFlag;
+};
+
+struct H264NalUnit {
+
+    enum Extension {
+        None,
+        SVC,
+        MVC,
+    };
+
+    enum Type {
+        Unknown = 0,
+        Slice = 1,
+        SliceDPA = 2,
+        SliceDPB = 3,
+        SliceDPC = 4,
+        SliceIDR = 5,
+        SEI = 6,
+        SPS = 7,
+        PPS = 8,
+        AUDelimiter = 9,
+        SeqEnd = 10,
+        StreamEnd = 11,
+        FillerData = 12,
+        SPSExt = 13,
+        PrefixUnit = 14,
+        SubsetSPS = 15,
+        DepthSPS = 16,
+        SliceAux = 19,
+        SliceExt = 20,
+        SliceDepth = 21
+    };
+
+    uint16_t refIDC;
+    uint16_t type;
+
+    /* calculated values */
+    uint8_t idrPicFlag;
+    uint32_t size;
+    uint32_t offset;
+    uint32_t scOffset;
+    bool valid;
+
+    uint8_t *data;
+
+    uint8_t headerBytes;
+    uint8_t extensionType;
+    std::shared_ptr<void> extension;
+};
+
+} // android
+
+#endif // ANDROID_V4L2_CODEC2_COMMON_H264_NAL_UNIT_H
diff --git a/components/include/v4l2_codec2/components/h264/parser/H264PPS.h b/components/include/v4l2_codec2/components/h264/parser/H264PPS.h
new file mode 100644
index 0000000..26f9604
--- /dev/null
+++ b/components/include/v4l2_codec2/components/h264/parser/H264PPS.h
@@ -0,0 +1,92 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * Gstreamer
+ * Copyright (C) <2011> Intel Corporation
+ * Copyright (C) <2011> Collabora Ltd.
+ * Copyright (C) <2011> Thibault Saunier <thibault.saunier@collabora.com>
+ *
+ * Some bits C-c,C-v'ed and s/4/3 from h264parse and videoparsers/h264parse.c:
+ *    Copyright (C) <2010> Mark Nauwelaerts <mark.nauwelaerts@collabora.co.uk>
+ *    Copyright (C) <2010> Collabora Multimedia
+ *    Copyright (C) <2010> Nokia Corporation
+ *
+ *    (C) 2005 Michal Benes <michal.benes@itonis.tv>
+ *    (C) 2008 Wim Taymans <wim.taymans@gmail.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef ANDROID_V4L2_CODEC2_COMMON_H264_PPS_H
+#define ANDROID_V4L2_CODEC2_COMMON_H264_PPS_H
+
+#include "H264SPS.h"
+
+#include <memory>
+#include <vector>
+
+namespace android {
+
+struct H264PPS {
+    int id;
+    H264SPS *sequence;
+    uint8_t entropyCodingModeFlag;
+    uint8_t picOrderPresentFlag;
+
+    uint32_t numSliceGroupsMinus1;
+
+    /* if numSliceGroupsMinus1 > 0 */
+    uint8_t sliceGroupMapType;
+    /* and if sliceGroupMapType == 0 */
+    uint32_t runLengthMinus1[8];
+    /* or if sliceGroupMapType == 2 */
+    uint32_t topLeft[8];
+    uint32_t bottomRight[8];
+    /* or if sliceGroupMapType == (3, 4, 5) */
+    uint8_t sliceGroupChangeDirectionFlag;
+    uint32_t sliceGroupChangeRateMinus1;
+    /* or if sliceGroupMapType == 6 */
+    uint32_t picSizeInMapUnitsMinus1;
+    std::vector<uint8_t> sliceGroupId;
+
+    /* FIXME rename to numRefIdxL{0,1}DefaultActiveMinus1 */
+    uint8_t numRefIdxL0ActiveMinus1;
+    uint8_t numRefIdxL1ActiveMinus1;
+    uint8_t weightedPredFlag;
+    uint8_t weightedBipredIDC;
+    int8_t picInitQPMinus26;
+    int8_t picInitQSMinus26;
+    int8_t chromaQPIndexOffset;
+    uint8_t deblockingFilterControlPresentFlag;
+    uint8_t constrainedIntraPredFlag;
+    uint8_t redundantPicCntPresentFlag;
+
+    uint8_t transform8x8ModeFlag;
+
+    uint8_t scalingLists4x4[6][16];
+    uint8_t scalingLists8x8[6][64];
+
+    int8_t secondChromaQPIndexOffset;
+
+    bool valid;
+
+    /* Since: 1.18 */
+    uint8_t picScalingMatrixPresentFlag;
+};
+
+} // android
+
+#endif // ANDROID_V4L2_CODEC2_COMMON_H264_PPS_H
diff --git a/components/include/v4l2_codec2/components/h264/parser/H264Parser.h b/components/include/v4l2_codec2/components/h264/parser/H264Parser.h
new file mode 100644
index 0000000..b114c13
--- /dev/null
+++ b/components/include/v4l2_codec2/components/h264/parser/H264Parser.h
@@ -0,0 +1,154 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * Gstreamer
+ * Copyright (C) <2011> Intel Corporation
+ * Copyright (C) <2011> Collabora Ltd.
+ * Copyright (C) <2011> Thibault Saunier <thibault.saunier@collabora.com>
+ *
+ * Some bits C-c,C-v'ed and s/4/3 from h264parse and videoparsers/h264parse.c:
+ *    Copyright (C) <2010> Mark Nauwelaerts <mark.nauwelaerts@collabora.co.uk>
+ *    Copyright (C) <2010> Collabora Multimedia
+ *    Copyright (C) <2010> Nokia Corporation
+ *
+ *    (C) 2005 Michal Benes <michal.benes@itonis.tv>
+ *    (C) 2008 Wim Taymans <wim.taymans@gmail.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef ANDROID_V4L2_CODEC2_COMMON_H264_PARSER_H
+#define ANDROID_V4L2_CODEC2_COMMON_H264_PARSER_H
+
+#include "H264SPS.h"
+#include "H264PPS.h"
+#include "H264Slice.h"
+#include "H264SEIMessage.h"
+#include "NalReader.h"
+#include "H264NalUnit.h"
+
+#include <vector>
+
+#define H264_MAX_SPS_COUNT 32
+#define H264_MAX_PPS_COUNT 256
+
+namespace android {
+
+class H264Parser {
+public:
+    enum Result {
+        Ok,
+        BrokenData,
+        BrokenLink,
+        Error,
+        NoNal,
+        NoNalEnd,
+    };
+
+    enum Level {
+        LevelL1 = 10,
+        LevelL1B = 9,
+        LevelL1_1 = 11,
+        LevelL1_2 = 12,
+        LevelL1_3 = 13,
+        LevelL2 = 20,
+        LevelL2_1 = 21,
+        LevelL2_2 = 22,
+        LevelL3 = 30,
+        LevelL3_1 = 31,
+        LevelL3_2 = 32,
+        LevelL4 = 40,
+        LevelL4_1 = 41,
+        LevelL4_2 = 42,
+        LevelL5 = 50,
+        LevelL5_1 = 51,
+        LevelL5_2 = 52,
+        LevelL6 = 60,
+        LevelL6_1 = 61,
+        LevelL6_2 = 62,
+    };
+
+    enum Profile {
+        Baseline = 66,
+        Main = 77,
+        Extended = 88,
+        High = 100,
+        High10 = 110,
+        High422 = 122,
+        High444 = 244,
+        MultiviewHigh = 118,
+        StereoHigh = 128,
+        ScalableBaseline = 83,
+        ScalableHigh = 86
+    };
+
+public:
+    Result identifyNalu(const uint8_t *data, unsigned int offset,
+            size_t size, H264NalUnit *nalu);
+
+    H264SPS *getSPS(uint8_t spsId);
+    H264PPS *getPPS(uint8_t ppsId);
+
+    Result updateSPS(const H264SPS &sps);
+    Result updatePPS(const H264PPS &pps);
+
+    Result parseNal(const H264NalUnit &nalu);
+
+    Result parseSPS(const H264NalUnit &nalu, H264SPS *sps);
+    Result parseSPSUpdate(const H264NalUnit &nalu, H264SPS *sps);
+
+    Result parsePPS(const H264NalUnit &nalu, H264PPS *pps);
+    Result parsePPSUpdate(const H264NalUnit &nalu, H264PPS *pps);
+
+    Result parseSliceHdr(const H264NalUnit &nalu, H264SliceHdr *slice,
+            bool parsePredWeightTable, bool parseDecRefPicMarking);
+
+    Result parseSEI(const H264NalUnit &nalu, std::vector<H264SEIMessage> *message);
+
+private:
+    /* parse SEI functions */
+    Result parseSEIMessage(NalReader *nr, H264SEIMessage *sei);
+    Result parseBufferingPeriod(H264BufferingPeriod *per, NalReader *nr);
+    Result parsePicTiming(H264PicTiming *tim, NalReader * nr);
+    Result parseRegisteredUserData(H264RegisteredUserData *rud,
+            NalReader *nr, unsigned int payloadSize);
+    Result parseUserDataUnregistered(H264UserDataUnregistered *urud,
+            NalReader *nr, unsigned int payloadSize);
+    Result parseRecoveryPoint(H264RecoveryPoint *rp, NalReader *nr);
+    Result parseStereoVideoInfo(H264StereoVideoInfo *info, NalReader *nr);
+    Result parseFramePacking(H264FramePacking *framePacking,
+            NalReader *nr, unsigned int payloadSize);
+    Result parseMasteringDisplayColourVolume(
+            H264MasteringDisplayColourVolume *mdcv, NalReader *nr);
+    Result parseContentLightLevelInfo(H264ContentLightLevel *cll,
+            NalReader *nr);
+    Result parseSEIUnhandledPayload(H264SEIUnhandledPayload *payload,
+            NalReader *nr, unsigned int payloadType, unsigned int payloadSize);
+
+
+
+
+private:
+    H264NalUnit mNalu;
+    H264SPS mSPS[H264_MAX_SPS_COUNT];
+    H264PPS mPPS[H264_MAX_PPS_COUNT];
+    H264SPS *mLastSPS;
+    H264PPS *mLastPPS;
+};
+
+} // android
+
+#endif // ANDROID_V4L2_CODEC2_COMMON_H264_PARSER_H
diff --git a/components/include/v4l2_codec2/components/h264/parser/H264Picture.h b/components/include/v4l2_codec2/components/h264/parser/H264Picture.h
new file mode 100644
index 0000000..b9d96ec
--- /dev/null
+++ b/components/include/v4l2_codec2/components/h264/parser/H264Picture.h
@@ -0,0 +1,107 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * GStreamer
+ * Copyright (C) 2019 Seungha Yang <seungha.yang@navercorp.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef ANDROID_V4L2_CODEC2_COMMON_H264_PICTURE_H
+#define ANDROID_V4L2_CODEC2_COMMON_H264_PICTURE_H
+
+#include "H264Slice.h"
+
+namespace android {
+
+struct H264Picture {
+
+    enum Field {
+        Frame,
+        Top,
+        Bottom,
+    };
+
+    enum Reference {
+        None = 0,
+        ShortTerm,
+        LongTerm,
+    };
+
+    void setReference(Reference reference, bool otherField) {
+        ref = reference;
+        if (reference > None)
+            refPic = true;
+
+        if (otherField && this->otherField) {
+            this->otherField->ref= reference;
+
+        if (reference > None)
+            this->otherField->refPic = true;
+
+        }
+    }
+
+    H264SliceHdr::Type type;
+
+    uint32_t systemFrameNumber;
+
+    uint8_t picOrderCntType;
+    int32_t topFieldOrderCnt;
+    int32_t bottomFieldOrderCnt;
+
+    int picOrderCnt;
+    int picOrderCntMSB;
+    int picOrderCntLSB;
+    int deltaPicOrderCntBottom;
+    int deltaPicOrderCnt0;
+    int deltaPicOrderCnt1;
+
+    int picNum;
+    int longTermPicNum;
+    int frameNum;
+    int frameNumOffset;
+    int frameNumWrap;
+    int longTermFrameIdx;
+
+    int nalRefIDC;
+    bool idr;
+    int idrPicId;
+    bool fieldPicFlag;
+    Reference ref;
+    /* Whether a reference picture. */
+    bool refPic;
+    bool neededForOutput;
+    bool memMgmt5;
+
+    bool nonexisting;
+
+    Field field;
+
+    H264DecRefPicMarking decRefPicMarking;
+
+    /* For interlaced decoding */
+    bool secondField;
+    std::shared_ptr<H264Picture> otherField;
+
+    std::shared_ptr<void> userData;
+};
+
+using H264PicturePtr = std::shared_ptr<H264Picture>;
+
+} // android
+
+#endif // ANDROID_V4L2_CODEC2_COMMON_H264_PICTURE_H
diff --git a/components/include/v4l2_codec2/components/h264/parser/H264SEIMessage.h b/components/include/v4l2_codec2/components/h264/parser/H264SEIMessage.h
new file mode 100644
index 0000000..b4a2c23
--- /dev/null
+++ b/components/include/v4l2_codec2/components/h264/parser/H264SEIMessage.h
@@ -0,0 +1,194 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * Gstreamer
+ * Copyright (C) <2011> Intel Corporation
+ * Copyright (C) <2011> Collabora Ltd.
+ * Copyright (C) <2011> Thibault Saunier <thibault.saunier@collabora.com>
+ *
+ * Some bits C-c,C-v'ed and s/4/3 from h264parse and videoparsers/h264parse.c:
+ *    Copyright (C) <2010> Mark Nauwelaerts <mark.nauwelaerts@collabora.co.uk>
+ *    Copyright (C) <2010> Collabora Multimedia
+ *    Copyright (C) <2010> Nokia Corporation
+ *
+ *    (C) 2005 Michal Benes <michal.benes@itonis.tv>
+ *    (C) 2008 Wim Taymans <wim.taymans@gmail.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef ANDROID_V4L2_CODEC2_COMMON_H264_SEI_MESSAGE_H
+#define ANDROID_V4L2_CODEC2_COMMON_H264_SEI_MESSAGE_H
+
+#include "H264SPS.h"
+
+#include <vector>
+
+namespace android {
+
+struct H264ClockTimestamp {
+    uint8_t ctType;
+    uint8_t nuitFieldBasedFlag;
+    uint8_t countingType;
+    uint8_t fullTimestampFlag;
+    uint8_t discontinuityFlag;
+    uint8_t cntDroppedFlag;
+    uint8_t nFrames;
+
+    uint8_t secondsFlag;
+    uint8_t secondsValue;
+
+    uint8_t minutesFlag;
+    uint8_t minutesValue;
+
+    uint8_t hoursFlag;
+    uint8_t hoursValue;
+
+    uint32_t timeOffset;
+};
+
+struct H264FramePacking {
+    enum Type {
+        None = 6,
+        CheckerboardInterleaving = 0,
+        ColumnInterleaving = 1,
+        RowInterleaving = 2,
+        SideBySide = 3,
+        TopBottom  = 4,
+        TemporalInterleaving = 5
+    };
+
+    uint32_t framePackingId;
+    uint8_t framePackingCancelFlag;
+    uint8_t framePackingType;
+    uint8_t quincunxSamplingFlag;
+    uint8_t contentInterpretationType;
+    uint8_t spatialFlippingFlag;
+    uint8_t frame0FlippedFlag;
+    uint8_t fieldViewsFlag;
+    uint8_t currentFrameIsFrame0Flag;
+    uint8_t frame0SelfContainedFlag;
+    uint8_t frame1SelfContainedFlag;
+    uint8_t frame0GridPositionX;
+    uint8_t frame0GridPositionY;
+    uint8_t frame1GridPositionX;
+    uint8_t frame1GridPositionY;
+    uint16_t framePackingRepetitionPeriod;
+};
+
+struct H264StereoVideoInfo {
+    uint8_t fieldViewsFlag;
+    uint8_t topFieldIsLeftViewFlag;
+    uint8_t currentFrameIsLeftViewFlag;
+    uint8_t nextFrameIsSecondViewFlag;
+    uint8_t leftViewSelfContainedFlag;
+    uint8_t rightViewSelfContainedFlag;
+};
+
+struct H264PicTiming {
+    /* from vui */
+    uint8_t cpbDpbDelaysPresentFlag;
+    /* if cpbDpbDelaysPresentFlag */
+    uint8_t cpbRemovalDelayLengthMinus1;
+    uint8_t dpbOutputDelayLengthMinus1;
+    uint32_t cpbRemovalDelay;
+    uint32_t dpbOutputDelay;
+
+    uint8_t picStructPresentFlag;
+    /* if picStructPresentFlag */
+    uint8_t picStruct;
+
+    uint8_t clockTimestampFlag[3];
+    H264ClockTimestamp clockTimestamp[3];
+    uint8_t timeOffsetLength;
+};
+
+struct H264RegisteredUserData {
+    uint8_t countryCode;
+    uint8_t countryCodeExtension;
+    std::vector<uint8_t> data;
+    unsigned int size;
+};
+
+struct H264UserDataUnregistered {
+    uint8_t uuid[16];
+    std::vector<uint8_t> data;
+    unsigned int size;
+};
+
+struct H264BufferingPeriod {
+    H264SPS *sps;
+
+    /* seq->vuiParameters->nalHrdParametersPresentFlag */
+    uint32_t nalInitialCPBRemovalDelay[32];
+    uint32_t nalInitialCPBRemovalDelayOffset[32];
+
+    /* seq->vuiParameters->vclHrdParametersPresentFlag */
+    uint32_t vclInitialCPBRemovalDelay[32];
+    uint32_t vclInitialCPBRemovalDelayOffset[32];
+};
+
+struct H264RecoveryPoint {
+    uint32_t recoveryFrameCnt;
+    uint8_t exactMatchFlag;
+    uint8_t brokenLinkFlag;
+    uint8_t changingSliceGroupIDC;
+};
+
+struct H264MasteringDisplayColourVolume {
+    uint16_t displayPrimariesX[3];
+    uint16_t displayPrimariesY[3];
+    uint16_t whitePointX;
+    uint16_t whitePointY;
+    uint32_t maxDisplayMasteringLuminance;
+    uint32_t minDisplayMasteringLuminance;
+};
+
+struct H264ContentLightLevel {
+    uint16_t maxContentLightLevel;
+    uint16_t maxPicAverageLightLevel;
+};
+
+struct H264SEIUnhandledPayload {
+    unsigned int payloadType;
+    std::vector<uint8_t> data;
+    unsigned int size;
+};
+
+struct H264SEIMessage {
+    enum PayloadType {
+        BufPeriod = 0,
+        PicTiming = 1,
+        RegisteredUserData = 4,
+        UserDataUnregistered = 5,
+        RecoveryPoint = 6,
+        StereoVideoInfo = 21,
+        FramePacking = 45,
+        MasteringDisplayColourVolume = 137,
+        ContentLightLevel = 144,
+        /* and more...  */
+
+        /* Unhandled SEI type */
+        UnhandledPayload = -1
+    };
+
+    PayloadType payloadType;
+    std::shared_ptr<void> payload;
+};
+
+} // android
+
+#endif // ANDROID_V4L2_CODEC2_COMMON_H264_SEI_MESSAGE_H
diff --git a/components/include/v4l2_codec2/components/h264/parser/H264SPS.h b/components/include/v4l2_codec2/components/h264/parser/H264SPS.h
new file mode 100644
index 0000000..87682eb
--- /dev/null
+++ b/components/include/v4l2_codec2/components/h264/parser/H264SPS.h
@@ -0,0 +1,218 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * Gstreamer
+ * Copyright (C) <2011> Intel Corporation
+ * Copyright (C) <2011> Collabora Ltd.
+ * Copyright (C) <2011> Thibault Saunier <thibault.saunier@collabora.com>
+ *
+ * Some bits C-c,C-v'ed and s/4/3 from h264parse and videoparsers/h264parse.c:
+ *    Copyright (C) <2010> Mark Nauwelaerts <mark.nauwelaerts@collabora.co.uk>
+ *    Copyright (C) <2010> Collabora Multimedia
+ *    Copyright (C) <2010> Nokia Corporation
+ *
+ *    (C) 2005 Michal Benes <michal.benes@itonis.tv>
+ *    (C) 2008 Wim Taymans <wim.taymans@gmail.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef ANDROID_V4L2_CODEC2_COMMON_H264_SPS_H
+#define ANDROID_V4L2_CODEC2_COMMON_H264_SPS_H
+
+#include <cstdint>
+
+namespace android {
+
+struct H264HRDParams {
+    uint8_t cpbCntMinus1;
+    uint8_t bitRateScale;
+    uint8_t cpbSizeScale;
+
+    uint32_t bitRateValueMinus1[32];
+    uint32_t cpbSizeValueMinus1[32];
+    uint8_t cbrFlag[32];
+
+    uint8_t initialCPBRemovalDelayLengthMinus1;
+    uint8_t cpbRemovalDelayLengthMinus1;
+    uint8_t dpbOutputDelayLengthMinus1;
+    uint8_t timeOffsetLength;
+};
+
+struct H264VUIParams {
+    uint8_t aspectRatioInfoPresentFlag;
+    uint8_t aspectRatioIDC;
+    /* if aspectRatioIDC == 255 */
+    uint16_t sarWidth;
+    uint16_t sarHeight;
+
+    uint8_t overscanInfoPresentFlag;
+    /* if overscanInfoPresentFlag */
+    uint8_t overscanAppropriateFlag;
+
+    uint8_t videoSignalTypePresentFlag;
+    uint8_t videoFormat;
+    uint8_t videoFullRangeFlag;
+    uint8_t colourDescriptionPresentFlag;
+    uint8_t colourPrimaries;
+    uint8_t transferCharacteristics;
+    uint8_t matrixCoefficients;
+
+    uint8_t chromaLocInfoPresentFlag;
+    uint8_t chromaSampleLocTypeTopField;
+    uint8_t chromaSampleLocTypeBottomField;
+
+    uint8_t timingInfoPresentFlag;
+    /* if timingInfoPresentFlag */
+    uint32_t numUnitsInTick;
+    uint32_t timeScale;
+    uint8_t fixedFrameRateFlag;
+
+    uint8_t nalHRDParametersPresentFlag;
+    /* if nalHrdParametersPresentFlag */
+    H264HRDParams nalHRDParameters;
+
+    uint8_t vclHRDParametersPresentFlag;
+    /* if vclHRDParametersPresentFlag */
+    H264HRDParams vclHRDParameters;
+
+    uint8_t lowDelayHRDFlag;
+    uint8_t picStructPresentFlag;
+
+    uint8_t bitstreamRestrictionFlag;
+    /*  if bitstreamRestrictionFlag */
+    uint8_t motionVectorsOverPicBoundariesFlag;
+    uint32_t maxBytesPerPicDenom;
+    uint32_t maxBitsPerMBDenom;
+    uint32_t log2MaxMVLengthHorizontal;
+    uint32_t log2MaxMVLengthVertical;
+    uint32_t numReorderFrames;
+    uint32_t maxDecFrameBuffering;
+
+    /* calculated values */
+    uint32_t parN;
+    uint32_t parD;
+};
+
+struct H264SPSExtMVCView {
+    uint16_t viewId;
+    uint8_t numAnchorRefsL0;
+    uint16_t anchorRefL0[15];
+    uint8_t numAnchorRefsL1;
+    uint16_t anchorRefL1[15];
+    uint8_t numNonAnchorRefsL0;
+    uint16_t nonAnchorRefL0[15];
+    uint8_t numNonAnchorRefsL1;
+    uint16_t nonAnchorRefL1[15];
+};
+
+struct H264SPSExtMVCLevelValueOp {
+    uint8_t temporalId;
+    uint16_t numTargetViewsMinus1;
+    uint16_t *targetViewId;
+    uint16_t numViewsMinus1;
+};
+
+struct H264SPSExtMVCLevelValue {
+    uint8_t levelIDC;
+    uint16_t numApplicableOpsMinus1;
+    H264SPSExtMVCLevelValueOp *applicableOp;
+};
+
+struct H264SPSExtMVC {
+    uint16_t numViewsMinus1;
+    H264SPSExtMVCView *view;
+    uint8_t numLevelValuesSignalledMinus1;
+    H264SPSExtMVCLevelValue *levelValue;
+};
+
+struct H264SPS {
+    int id;
+    uint8_t profileIDC;
+    uint8_t constraintSet0Flag;
+    uint8_t constraintSet1Flag;
+    uint8_t constraintSet2Flag;
+    uint8_t constraintSet3Flag;
+    uint8_t constraintSet4Flag;
+    uint8_t constraintSet5Flag;
+    uint8_t levelIDC;
+
+    uint8_t chromaFormatIDC;
+
+    uint8_t separateColourPlaneFlag;
+    uint8_t bitDepthLumaMinus8;
+    uint8_t bitDepthChromaMinus8;
+    uint8_t qpprimeYZeroTransformBypassFlag;
+
+    uint8_t scalingMatrixPresentFlag;
+    uint8_t scalingLists4x4[6][16];
+    uint8_t scalingLists8x8[6][64];
+
+    uint8_t log2MaxFrameNumMinus4;
+    uint8_t picOrderCntType;
+
+    /* if picOrderCntType == 0 */
+    uint8_t log2MaxPicOrderCntLSBMinus4;
+
+    /* else if picOrderCntType == 1 */
+    uint8_t deltaPicOrderAlwaysZeroFlag;
+    int32_t offsetForNonRefPic;
+    int32_t offsetForTopToBottomField;
+    uint8_t numRefFramesInPicOrderCntCycle;
+    int32_t offsetForRefFrame[255];
+
+    /* FIXME rename according to spec, maxNumRefFrames */
+    uint32_t numRefFrames;
+    uint8_t gapsInFrameNumValueAllowedFlag;
+    uint32_t picWidthInMBSMinus1;
+    uint32_t picHeightInMapUnitsMinus1;
+    uint8_t frameMBSOnlyFlag;
+
+    uint8_t mbAdaptiveFrameFieldFlag;
+
+    uint8_t direct8x8InferenceFlag;
+
+    uint8_t frameCroppingFlag;
+
+    /* if frameCroppingFlag */
+    uint32_t frameCropLeftOffset;
+    uint32_t frameCropRightOffset;
+    uint32_t frameCropTopOffset;
+    uint32_t frameCropBottomOffset;
+
+    uint8_t vuiParametersPresentFlag;
+    /* if vuiParametersPresentFlag */
+    H264VUIParams vuiParameters;
+
+    /* calculated values */
+    uint8_t chromaArrayType;
+    uint32_t maxFrameNum;
+    int width, height;
+    int cropRectWidth, cropRectHeight;
+    int cropRectX, cropRectY;
+    int fpsNumRemoved, fpsDenRemoved; /* FIXME: remove */
+    bool valid;
+
+    /* Subset SPS extensions */
+    uint8_t extensionType;
+    union {
+        H264SPSExtMVC mvc;
+    } extension;
+};
+
+} // android
+
+#endif // ANDROID_V4L2_CODEC2_COMMON_H264_SPS_H
diff --git a/components/include/v4l2_codec2/components/h264/parser/H264Slice.h b/components/include/v4l2_codec2/components/h264/parser/H264Slice.h
new file mode 100644
index 0000000..dcc22c6
--- /dev/null
+++ b/components/include/v4l2_codec2/components/h264/parser/H264Slice.h
@@ -0,0 +1,196 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * Gstreamer
+ * Copyright (C) <2011> Intel Corporation
+ * Copyright (C) <2011> Collabora Ltd.
+ * Copyright (C) <2011> Thibault Saunier <thibault.saunier@collabora.com>
+ *
+ * Some bits C-c,C-v'ed and s/4/3 from h264parse and videoparsers/h264parse.c:
+ *    Copyright (C) <2010> Mark Nauwelaerts <mark.nauwelaerts@collabora.co.uk>
+ *    Copyright (C) <2010> Collabora Multimedia
+ *    Copyright (C) <2010> Nokia Corporation
+ *
+ *    (C) 2005 Michal Benes <michal.benes@itonis.tv>
+ *    (C) 2008 Wim Taymans <wim.taymans@gmail.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef ANDROID_V4L2_CODEC2_COMMON_H264_SLICE_HDR_H
+#define ANDROID_V4L2_CODEC2_COMMON_H264_SLICE_HDR_H
+
+#include <cstdint>
+
+#include "H264NalUnit.h"
+#include "H264PPS.h"
+
+namespace android {
+
+struct H264RefPicListModification {
+    uint8_t modificationOfPicNumsIDC;
+    union {
+        /* if modificationOfPicNumsIDC == 0 || 1 */
+        uint32_t absDiffPicNumMinus1;
+        /* if modificationOfPicNumsIDC == 2 */
+        uint32_t longTermPicNum;
+        /* if modificationOfPicNumsIDC == 4 || 5 */
+        uint32_t absDiffViewIdxMinus1;
+    } value;
+};
+
+struct H264PredWeightTable {
+    uint8_t lumaLog2WeightDenom;
+    uint8_t chromaLog2WeightDenom;
+
+    int16_t lumaWeightL0[32];
+    int8_t lumaOffsetL0[32];
+
+    /* if seq->ChromaArrayType != 0 */
+    int16_t chromaWeightL0[32][2];
+    int8_t chromaOffsetL0[32][2];
+
+    /* if slice->sliceType % 5 == 1 */
+    int16_t lumaWeightL1[32];
+    int8_t lumaOffsetL1[32];
+
+    /* and if seq->ChromaArrayType != 0 */
+    int16_t chromaWeightL1[32][2];
+    int8_t chromaOffsetL1[32][2];
+};
+
+struct H264RefPicMarking {
+    uint8_t memoryManagementControlOperation;
+
+    uint32_t differenceOfPicNumsMinus1;
+    uint32_t longTermPicNum;
+    uint32_t longTermFrameIdx;
+    uint32_t maxLongTermFrameIdxPlus1;
+};
+
+struct H264DecRefPicMarking {
+    /* if slice->nal_unit.IdrPicFlag */
+    uint8_t noOutputOfPriorPicsFlag;
+    uint8_t longTermReferenceFlag;
+
+    uint8_t adaptiveRefPicMarkingModeFlag;
+    H264RefPicMarking refPicMarking[10];
+    uint8_t nRefPicMarking;
+
+    /* Size of the decRefPicMarking() syntax element in bits (Since: 1.18) */
+    unsigned int bitSize;
+};
+
+struct H264SliceHdr {
+    enum Type {
+        P = 0,
+        B = 1,
+        I = 2,
+        SP = 3,
+        SI = 4,
+        S_P = 5,
+        S_B = 6,
+        S_I = 7,
+        S_SP = 8,
+        S_SI = 9
+    };
+
+    uint32_t firstMBInSlice;
+    uint32_t type;
+    H264PPS *pps;
+
+    /* if seq->separateColourPlaneFlag */
+    uint8_t colourPlaneId;
+
+    uint16_t frameNum;
+
+    uint8_t fieldPicFlag;
+    uint8_t bottomFieldFlag;
+
+    /* if nalUnit.type == 5 */
+    uint16_t idrPicId;
+
+    /* if seq->picOrderCntType == 0 */
+    uint16_t picOrderCntLSB;
+    /* if seq->picOrderPresentFlag && !fieldPicFlag */
+    int32_t deltaPicOrderCntBottom;
+
+    int32_t deltaPicOrderCnt[2];
+    uint8_t redundantPicCnt;
+
+    /* if sliceType == B_Slice */
+    uint8_t directSpatialMVPredFlag;
+
+    uint8_t numRefIdxL0ActiveMinus1;
+    uint8_t numRefIdxL1ActiveMinus1;
+
+    uint8_t refPicListModificationFlagL0;
+    uint8_t nRefPicListModificationL0;
+    H264RefPicListModification refPicListModificationL0[32];
+    uint8_t refPicListModificationFlagL1;
+    uint8_t nRefPicListModificationL1;
+    H264RefPicListModification refPicListModificationL1[32];
+
+    H264PredWeightTable predWeightTable;
+    /* if nalUnit.refIDC != 0 */
+    H264DecRefPicMarking decRefPicMarking;
+
+    uint8_t cabacInitIDC;
+    int8_t sliceQPDelta;
+    int8_t sliceQSDelta;
+
+    uint8_t disableDeblockingFilterIDC;
+    int8_t sliceAlphaC0OffsetDiv2;
+    int8_t sliceBetaOffsetDiv2;
+
+    uint16_t sliceGroupChangeCycle;
+
+    /* calculated values */
+    uint32_t maxPicNum;
+    bool valid;
+
+    /* Size of the sliceHeader() in bits */
+    unsigned int headerSize;
+
+    /* Number of emulation prevention bytes (EPB) in this sliceHeader() */
+    unsigned int nEmulationPreventionBytes;
+
+    /* Since: 1.18 */
+    uint8_t numRefIdxActiveOverrideFlag;
+    uint8_t spForSwitchFlag;
+
+    /*
+     * Size of the picOrderCnt related syntax elements picOrderCntLsb,
+     * deltaPicOrderCntBottom, deltaPicOrderCnt[0], and
+     * deltaPicOrderCnt[1]. (Since: 1.18)
+     */
+    unsigned int picOrderCntBitSize;
+
+    bool is(Type t) const { return (type % 5) == t; }
+};
+
+struct H264Slice {
+    H264SliceHdr header;
+
+    /* parsed nal unit (doesn't take ownership of raw data) */
+    H264NalUnit nalu;
+};
+
+
+
+} // android
+
+#endif // ANDROID_V4L2_CODEC2_COMMON_H264_SLICE_HDR_H
diff --git a/components/include/v4l2_codec2/components/h264/parser/NalReader.h b/components/include/v4l2_codec2/components/h264/parser/NalReader.h
new file mode 100644
index 0000000..28bdc63
--- /dev/null
+++ b/components/include/v4l2_codec2/components/h264/parser/NalReader.h
@@ -0,0 +1,175 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * Gstreamer
+ * Copyright (C) <2011> Intel Corporation
+ * Copyright (C) <2011> Collabora Ltd.
+ * Copyright (C) <2011> Thibault Saunier <thibault.saunier@collabora.com>
+ *
+ * Some bits C-c,C-v'ed and s/4/3 from h264parse and videoparsers/h264parse.c:
+ *    Copyright (C) <2010> Mark Nauwelaerts <mark.nauwelaerts@collabora.co.uk>
+ *    Copyright (C) <2010> Collabora Multimedia
+ *    Copyright (C) <2010> Nokia Corporation
+ *
+ *    (C) 2005 Michal Benes <michal.benes@itonis.tv>
+ *    (C) 2008 Wim Taymans <wim.taymans@gmail.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef ANDROID_V4L2_CODEC2_COMMON_H264_NAL_READER_H
+#define ANDROID_V4L2_CODEC2_COMMON_H264_NAL_READER_H
+
+#include <cstdint>
+
+#define STRINGIFY_ARG(arg) #arg
+#define STRINGIFY(arg) STRINGIFY_ARG(arg)
+
+#define CHECK_ALLOWED_MAX_WITH_DEBUG(dbg, val, max) { \
+    if (val > max) { \
+        ALOGW("value for '" dbg "' greater than max. value: %d, max: %d", \
+                val, max); \
+        goto error; \
+    } \
+}
+
+#define CHECK_ALLOWED_MAX(val, max) \
+    CHECK_ALLOWED_MAX_WITH_DEBUG(STRINGIFY(val), val, max)
+
+#define CHECK_ALLOWED_WITH_DEBUG(dbg, val, min, max) { \
+    if (val < min || val > max) { \
+        ALOGW("value for '" dbg "' not in allowed range. value: %d, range: %d-%d", \
+                val, min, max); \
+        goto error; \
+    } \
+}
+
+#define CHECK_ALLOWED(val, min, max) \
+    CHECK_ALLOWED_WITH_DEBUG(STRINGIFY(val), val, min, max)
+
+#define READ(nr, val, nbits) { \
+    if (!(nr)->getBits(&val, nbits)) { \
+        ALOGW("failed to read '" STRINGIFY(val) "', nbits: %d", nbits); \
+        goto error; \
+    } \
+}
+
+#define READ_UE(nr, val) { \
+    if (!(nr)->getUE(&val)) { \
+        ALOGW("failed to read UE for '" STRINGIFY(val) "'"); \
+        goto error; \
+    } \
+}
+
+#define READ_UE_ALLOWED(nr, val, min, max) { \
+    uint32_t tmp; \
+    READ_UE(nr, tmp); \
+    CHECK_ALLOWED_WITH_DEBUG(STRINGIFY(val), tmp, min, max); \
+    val = tmp; \
+}
+
+#define READ_UE_MAX(nr, val, max) { \
+    uint32_t tmp; \
+    READ_UE(nr, tmp); \
+    CHECK_ALLOWED_MAX_WITH_DEBUG(STRINGIFY(val), tmp, max); \
+    val = tmp; \
+}
+
+#define READ_SE(nr, val) { \
+    if (!(nr)->getSE(&val)) { \
+        ALOGW("failed to read SE for '" STRINGIFY(val) "'"); \
+        goto error; \
+    } \
+}
+
+#define READ_SE_ALLOWED(nr, val, min, max) { \
+    int32_t tmp; \
+    READ_SE(nr, tmp); \
+    CHECK_ALLOWED_WITH_DEBUG(STRINGIFY(val), tmp, min, max); \
+    val = tmp; \
+}
+
+namespace android {
+
+class NalReader {
+
+public:
+    NalReader(const uint8_t *data, uint32_t size);
+    NalReader(const NalReader &other) = default;
+
+    NalReader &operator=(const NalReader &other) = default;
+
+    bool read(uint32_t numBits);
+    bool skip(uint32_t numBits);
+    bool skipLong(uint32_t numBits);
+    uint32_t getPos() const;
+    uint32_t getRemaining() const;
+    uint32_t getEPBCount() const;
+    bool isByteAligned() const;
+    bool hasMoreData() const;
+
+    bool getUE(uint32_t *val);
+    bool getSE(int32_t *val);
+
+    template<class T>
+    bool getBits(T *val, uint32_t numBits);
+
+    template<class T>
+    bool peekBits(T *val, uint32_t numBits);
+
+private:
+    const uint8_t *mData;
+    uint32_t mSize;
+    uint32_t mNumEPB;
+    uint32_t mByte;
+    uint32_t mBitsInCache;
+    uint8_t mFirstByte;
+    uint32_t mEpbCache;
+    uint64_t mCache;
+};
+
+
+template<class T>
+bool NalReader::getBits(T *val, uint32_t numBits) {
+    uint32_t shift;
+    uint8_t bits = sizeof(T) * 8;
+
+    if (!read(numBits))
+        return false;
+
+    /* bring the required bits down and truncate */
+    shift = mBitsInCache - numBits;
+    *val = mFirstByte >> shift;
+
+    *val |= mCache << (8 - shift);
+    /* mask out the required bits */
+    if (numBits < bits)
+        *val &= ((T)1 << numBits) - 1;
+
+    mBitsInCache = shift;
+
+    return true;
+}
+
+template<class T>
+bool NalReader::peekBits(T *val, uint32_t numBits) {
+    NalReader temp = *this;
+    return temp.getBits<T>(val, numBits);
+}
+
+} // android
+
+#endif // ANDROID_V4L2_CODEC2_COMMON_H264_NAL_READER_H
diff --git a/components/include/v4l2_codec2/components/vp8/V4L2VP8Decoder.h b/components/include/v4l2_codec2/components/vp8/V4L2VP8Decoder.h
new file mode 100644
index 0000000..069f4c8
--- /dev/null
+++ b/components/include/v4l2_codec2/components/vp8/V4L2VP8Decoder.h
@@ -0,0 +1,87 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * GStreamer
+ * Copyright (C) 2020 Nicolas Dufresne <nicolas.dufresne@collabora.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef ANDROID_V4L2_CODEC2_COMPONENTS_VP8_V4L2_VP8_DECODER_H
+#define ANDROID_V4L2_CODEC2_COMPONENTS_VP8_V4L2_VP8_DECODER_H
+
+#define TYPE_V4L2_CODEC_VP8_DEC           (v4l2CodecVP8DecGetType())
+#define V4L2_CODEC_VP8_DEC(obj)           (G_TYPE_CHECK_INSTANCE_CAST((obj),TYPE_V4L2_CODEC_VP8_DEC,GstV4l2CodecVP8Dec))
+#define V4L2_CODEC_VP8_DEC_CLASS(klass)   (G_TYPE_CHECK_CLASS_CAST((klass),TYPE_V4L2_CODEC_VP8_DEC,GstV4l2CodecVP8DecClass))
+#define V4L2_CODEC_VP8_DEC_GET_CLASS(obj) (G_TYPE_INSTANCE_GET_CLASS ((obj), TYPE_V4L2_CODEC_VP8_DEC, GstV4l2CodecVP8DecClass))
+#define IS_V4L2_CODEC_VP8_DEC(obj)        (G_TYPE_CHECK_INSTANCE_TYPE((obj),TYPE_V4L2_CODEC_VP8_DEC))
+#define IS_V4L2_CODEC_VP8_DEC_CLASS(obj)  (G_TYPE_CHECK_CLASS_TYPE((klass),TYPE_V4L2_CODEC_VP8_DEC))
+
+#include <v4l2_codec2/components/V4L2Decoder.h>
+#include <v4l2_codec2/components/vp8/VP8Decoder.h>
+
+namespace android {
+
+    class V4L2VP8Decoder : public V4L2Decoder, public VP8Decoder {
+
+        public:
+            static std::unique_ptr<VideoDecoder> Create(
+                    const size_t inputBufferSize,
+                    GetPoolCB getPoolCb, OutputCB outputCb, ErrorCB errorCb,
+                    scoped_refptr<::base::SequencedTaskRunner> taskRunner);
+
+            virtual ~V4L2VP8Decoder();
+
+        protected:
+            V4L2VP8Decoder(scoped_refptr<::base::SequencedTaskRunner> taskRunner);
+
+            // V4L2Decoder
+            bool decode(std::unique_ptr<ConstBitstreamBuffer> buffer) override;
+            void flushInternal() override;
+            bool drainInternal() override;
+
+            // VP8Decoder
+            virtual bool newSequence (const VP8FrameHdr &frameHdr, int maxDpbSize) override;
+
+            virtual bool startPicture(const VP8PicturePtr &picture) override;
+
+            virtual bool decodePicture (const VP8PicturePtr &picture) override;
+
+            virtual bool endPicture(const VP8PicturePtr &picture) override;
+
+            virtual bool outputPicture(const VP8PicturePtr &picture) override;
+
+            virtual unsigned int getPreferredOutputDelay(bool live) override;
+
+        private:
+            uint16_t mWidth;
+            uint16_t mHeight;
+
+            struct v4l2_ctrl_vp8_frame mFrameHeader;
+
+            bool negotiate (void);
+
+            void fillSegment (struct v4l2_vp8_segment &segment,
+                    const VP8Segmentation &segmentation);
+            void fillLf (struct v4l2_vp8_loop_filter &lf, const VP8MbLfAdjustments &lfAdj);
+            void fillEntropy (struct v4l2_vp8_entropy &entropy, const VP8FrameHdr &frameHdr);
+            void fillFrameHeader (const VP8FrameHdr &frameHdr);
+            void fillReferences (void);
+    };
+
+} // android
+
+#endif // ANDROID_V4L2_CODEC2_COMPONENTS_VP8_V4L2_VP8_DECODER_H
diff --git a/components/include/v4l2_codec2/components/vp8/VP8Decoder.h b/components/include/v4l2_codec2/components/vp8/VP8Decoder.h
new file mode 100644
index 0000000..6118d74
--- /dev/null
+++ b/components/include/v4l2_codec2/components/vp8/VP8Decoder.h
@@ -0,0 +1,140 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * GStreamer
+ * Copyright (C) 2020 Nicolas Dufresne <nicolas.dufresne@collabora.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef ANDROID_V4L2_CODEC2_COMPONENTS_VP8_VP8_DECODER_H
+#define ANDROID_V4L2_CODEC2_COMPONENTS_VP8_VP8_DECODER_H
+
+#include <stdint.h>
+
+#include <memory>
+#include <optional>
+
+#include <base/callback.h>
+#include <base/memory/weak_ptr.h>
+
+#include <ui/Rect.h>
+#include <ui/Size.h>
+#include <v4l2_codec2/common/V4L2Device.h>
+#include <v4l2_codec2/common/VideoTypes.h>
+#include <v4l2_codec2/components/VideoDecoder.h>
+#include <v4l2_codec2/components/VideoFrame.h>
+#include <v4l2_codec2/components/VideoFramePool.h>
+
+#include "parser/VP8Parser.h"
+#include "parser/VP8Picture.h"
+
+namespace android {
+
+/**
+ * VP8Decoder:
+ * @newSequence:       Notifies subclass of SPS update
+ * @newPicture:   Optional.
+ *                     Called whenever new #VP8Picture is created.
+ *                     Subclass can set implementation specific user data
+ *                     on the #VP8Picture via VP8Picture::setUserData()
+ * @startPicture:      Optional.
+ *                     Called per one #VP8Picture to notify subclass to prepare
+ *                     decoding process for the #VP8Picture
+ * @decodeSlice:       Provides per slice data with parsed slice header and
+ *                     required raw bitstream for subclass to decode it
+ * @endPicture:        Optional.
+ *                     Called per one #VP8Picture to notify subclass to finish
+ *                     decoding process for the #VP8Picture
+ * @outputPicture:     Called with a #VP8Picture which is required to be output.
+ *                     Subclass can retrieve parent #VideoCodecFrame by using
+ *                     VideoDecoder::getFrame() with system_frame_number
+ *                     and the #VideoCodecFrame must be consumed by subclass via
+ *                     VideoDecoder::{finish,drop,release}Frame().
+ */
+class VP8Decoder {
+public:
+    VP8Decoder();
+    virtual ~VP8Decoder() {}
+
+protected:
+    VP8PicturePtr mLastPicture;
+    VP8PicturePtr mGoldenRefPicture;
+    VP8PicturePtr mAltRefPicture;
+    VP8Parser mParser;
+
+    bool decode (std::unique_ptr<ConstBitstreamBuffer> buffer);
+    void flush();
+    bool drain();
+
+    virtual bool newSequence (const VP8FrameHdr &frameHdr, int maxDpbSize) = 0;
+
+    virtual bool startPicture (const VP8PicturePtr &picture) = 0;
+
+    virtual bool decodePicture (const VP8PicturePtr &picture) = 0;
+
+    virtual bool endPicture (const VP8PicturePtr &picture) = 0;
+
+    /**
+     * VP8Decoder:output_picture:
+     * @decoder: a #VP8Decoder
+     * @picture: (transfer full): a #VP8Picture
+     */
+    virtual bool outputPicture(const VP8PicturePtr &picture) = 0;
+
+    /**
+     * V8Decoder::getPreferredOutputDelay:
+     * @is_live: whether upstream is live or not
+     *
+     * Optional. Called by baseclass to query whether delaying output is
+     * preferred by subclass or not.
+     *
+     * Returns: the number of perferred delayed output frame
+     *
+     * Since: 1.20
+     */
+    virtual unsigned int getPreferredOutputDelay(bool live) { return 0; }
+
+    /**
+     * newPicture:
+     * @decoder: a #VP8Decoder
+     * @frame: (transfer none): a #VideoCodecFrame
+     * @picture: (transfer none): a #VP8Picture
+     */
+    virtual bool newPicture (ConstBitstreamBuffer &buffer, const VP8PicturePtr &picture) { return true; }
+
+private:
+    std::queue<VP8PicturePtr> mOutputQueue;
+
+    int mWidth;
+    int mHeight;
+
+    bool mHadSequence;
+    bool mWaitKeyFrame;
+    unsigned int mPreferredOutputDelay;
+    /* for delayed output */
+    bool mIsLive;
+
+    bool drainOutputQueue (unsigned int num);
+    bool checkCodecChange (const VP8FrameHdr &frameHdr);
+    bool updateReference (VP8PicturePtr picture);
+    bool drainInternal (bool waitKeyFrame);
+    void reset (void);
+};
+
+}  // namespace android
+
+#endif  // ANDROID_V4L2_CODEC2_COMPONENTS_VP8_VP8_DECODER_H
diff --git a/components/include/v4l2_codec2/components/vp8/parser/ByteReader.h b/components/include/v4l2_codec2/components/vp8/parser/ByteReader.h
new file mode 100644
index 0000000..aef3e35
--- /dev/null
+++ b/components/include/v4l2_codec2/components/vp8/parser/ByteReader.h
@@ -0,0 +1,49 @@
+/*
+ * Copyright 2024, The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef ANDROID_V4L2_CODEC2_COMPONENTS_VP8_PARSER_BYTE_READER_H
+#define ANDROID_V4L2_CODEC2_COMPONENTS_VP8_PARSER_BYTE_READER_H
+
+#include <stdint.h>
+
+namespace android {
+
+    class ByteReader {
+        public:
+            ByteReader (const uint8_t *data, size_t size);
+
+            uint8_t getUint8 (uint8_t &val);
+
+            uint16_t getUint16Le (uint16_t &val);
+            uint16_t getUint16Be (uint16_t &val);
+
+            uint32_t getUint24Le (uint32_t &val);
+            uint32_t getUint24Be (uint32_t &val);
+
+            uint32_t getUint32Le (uint32_t &val);
+            uint32_t getUint32Be (uint32_t &val);
+
+            size_t getPos (void);
+
+        private:
+            const uint8_t * const mData;
+            const size_t mSize;
+            size_t mPos;
+    };
+
+}
+
+#endif  // ANDROID_V4L2_CODEC2_COMPONENTS_VP8_PARSER_BYTE_READER_H
diff --git a/components/include/v4l2_codec2/components/vp8/parser/VP8BoolDecoder.h b/components/include/v4l2_codec2/components/vp8/parser/VP8BoolDecoder.h
new file mode 100644
index 0000000..dd608c7
--- /dev/null
+++ b/components/include/v4l2_codec2/components/vp8/parser/VP8BoolDecoder.h
@@ -0,0 +1,84 @@
+/*
+ * NOTE: some of implementations are copied/modified from WebM code
+ *
+ *  Copyright (c) 2010 The WebM project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef ANDROID_V4L2_CODEC2_COMPONENTS_VP8_PARSER_VP8_BOOL_DECODER_H
+#define ANDROID_V4L2_CODEC2_COMPONENTS_VP8_PARSER_VP8_BOOL_DECODER_H
+
+#include <stdint.h>
+#include <stddef.h>
+#include <limits.h>
+
+#define VP8_BD_VALUE_SIZE ((int)sizeof(VP8BdValue)*CHAR_BIT)
+
+    /*This is meant to be a large, positive constant that can still be efficiently
+      loaded as an immediate (on platforms like ARM, for example).
+      Even relatively modest values like 100 would work fine.*/
+#define VP8_LOTS_OF_BITS (0x40000000)
+
+namespace android {
+
+    typedef size_t VP8BdValue;
+
+    class VP8BoolDecoder {
+        public:
+            typedef size_t Value;
+
+            typedef void (*DecryptCb) (void *decryptState, const unsigned char *input,
+                    unsigned char *output, int count);
+
+            VP8BoolDecoder (const unsigned char *source, unsigned int sourceSz,
+                    DecryptCb decryptCb, void *decryptState);
+
+            void fill();
+
+            /*Decrypt n bytes of data from input -> output, using the decryptStat
+              passed in VP8D_SET_DECRYPTOR.
+             */
+            int decodeBool(int probability);
+            int decodeValue(int bits);
+
+            bool inError();
+
+        protected:
+            int                  mCount;
+            unsigned int         mRange;
+            Value                mValue;
+            const unsigned char *mUserBuffer;
+
+        private:
+            const unsigned char *mUserBufferEnd;
+            DecryptCb            mDecryptCb;
+            void                 *mDecryptState;
+
+            static constexpr uint8_t vp8Norm[256] = {
+                0, 7, 6, 6, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,
+                3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
+                2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
+                2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
+                1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
+                1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
+                1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
+                1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
+                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
+                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
+                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
+                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
+                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
+                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
+                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
+                0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0
+            };
+    };
+
+}
+
+#endif  // ANDROID_V4L2_CODEC2_COMPONENTS_VP8_PARSER_VP8_BOOL_DECODER_H
diff --git a/components/include/v4l2_codec2/components/vp8/parser/VP8Parser.h b/components/include/v4l2_codec2/components/vp8/parser/VP8Parser.h
new file mode 100644
index 0000000..1439c12
--- /dev/null
+++ b/components/include/v4l2_codec2/components/vp8/parser/VP8Parser.h
@@ -0,0 +1,724 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * GStreamer
+ * Copyright (C) 2019 Seungha Yang <seungha.yang@navercorp.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef ANDROID_V4L2_CODEC2_COMPONENTS_VP8_PARSER_VP8_PARSER_H
+#define ANDROID_V4L2_CODEC2_COMPONENTS_VP8_PARSER_VP8_PARSER_H
+
+#include <stdint.h>
+
+#include "ByteReader.h"
+#include "VP8RangeDecoder.h"
+
+namespace android {
+
+    /**
+     * VP8QuantIndices:
+     * @yAcQi: indicates the dequantization table index used for the
+     *   luma AC coefficients
+     * @yDcDelta: indicates the delta value that is added to the
+     *   baseline index to obtain the luma DC coefficient dequantization
+     *   index
+     * @y2DcDelta: indicates the delta value that is added to the
+     *   baseline index to obtain the Y2 block DC coefficient dequantization
+     *   index
+     * @y2AcDelta: indicates the delta value that is added to the
+     *   baseline index to obtain the Y2 block AC coefficient dequantization
+     *   index
+     * @uvDcDelta: indicates the delta value that is added to the
+     *   baseline index to obtain the chroma DC coefficient dequantization
+     *   index
+     * @uvAcDelta: indicates the delta value that is added to the
+     *   baseline index to obtain the chroma AC coefficient dequantization
+     *   index
+     *
+     * Dequantization indices.
+     */
+    struct VP8QuantIndices
+    {
+        uint8_t yAcQi;
+        int8_t yDcDelta;
+        int8_t y2DcDelta;
+        int8_t y2AcDelta;
+        int8_t uvDcDelta;
+        int8_t uvAcDelta;
+    };
+
+    /**
+     * VP8Segmentation:
+     * @segmentationEnabled: enables the segmentation feature for the
+     *   current frame
+     * @updateMbSegmentationMap: determines if the MB segmentation map
+     *   is updated in the current frame
+     * @updateSegmentFeatureData: indicates if the segment feature data
+     *   is updated in the current frame
+     * @segmentFeatureMode: indicates the feature data update mode (0:
+     *   delta, 1: absolute value)
+     * @quantizerUpdateValue: indicates the update value for the segment
+     *   quantizer
+     * @lfUpdateValue: indicates the update value for the loop filter level
+     * @segmentProb: indicates the branch probabilities of the segmentId
+     *   decoding tree
+     *
+     * Segmentation feature data.
+     */
+    struct VP8Segmentation
+    {
+        uint8_t segmentationEnabled;
+        uint8_t updateMbSegmentationMap;
+        uint8_t updateSegmentFeatureData;
+
+        /* if updateSegmentFeatureData == 1 */
+        uint8_t segmentFeatureMode;
+        int8_t quantizerUpdateValue[4];
+        int8_t lfUpdateValue[4];
+
+        /* if updateMbSegmentationMap == 1 */
+        uint8_t segmentProb[3];
+    };
+
+    /**
+     * VP8MbLfAdjustments:
+     * @loopFilterAdjEnable: indicates if the MB-level loop filter
+     *   adjustment is on for the current frame
+     * @modeRefLfDeltaUpdate: indicates if the delta values used in an
+     *   adjustment are updated in the current frame
+     * @refFrameDelta: indicates the adjustment delta value
+     *   corresponding to a certain used reference frame
+     * @mbModeDelta: indicates the adjustment delta value corresponding
+     *   to a certain MB prediction mode
+     *
+     * MB-level loop filter adjustments.
+     */
+    struct VP8MbLfAdjustments
+    {
+        uint8_t loopFilterAdjEnable;
+        uint8_t modeRefLfDeltaUpdate;
+
+        /* if modeRefLfDeltaUpdate == 1 */
+        int8_t refFrameDelta[4];
+        int8_t mbModeDelta[4];
+    };
+
+    /**
+     * VP8TokenProbs:
+     * @prob: token probability
+     *
+     * Token probabilities, with cumulative updates applied.
+     *
+     * Each probability value in this matrix is live across frames, until
+     * they are reset to their default values on key frame.
+     */
+    struct VP8TokenProbs
+    {
+        uint8_t prob[4][8][3][11];
+    };
+
+    /**
+     * VP8MvProbs:
+     * @prob: MV probability
+     *
+     * Probabilities used for motion vector decoding, with cumulative
+     * updates applied.
+     *
+     * Each probability value in this matrix is live across frames, until
+     * they are reset to their default values on key frame.
+     */
+    struct VP8MvProbs
+    {
+        uint8_t prob[2][19];
+    };
+
+    /**
+     * VP8ModeProbs:
+     * @yProb: indicates the branch probabilities of the luma
+     *   intra-prediction mode decoding tree
+     * @uvProb: indicates the branch probabilities of the chroma
+     *   intra-prediction mode decoding tree
+     *
+     * Probabilities used for intra-prediction mode decoding tree.
+     *
+     * Each probability value in the structure is live across frames,
+     * until they are reset to their default values on key frame.
+     */
+    struct VP8ModeProbs
+    {
+        uint8_t yProb[4];
+        uint8_t uvProb[3];
+    };
+
+    /**
+     * VP8FrameHdr:
+     * @keyFrame: indicates whether the frame is a key frame (1), or an
+     *   inter frame (0)
+     * @version: version number
+     * @showFrame: indicates whether the frame is meant to be displayed (1),
+     *   or not (0)
+     * @dataChunkSize: the size in bytes of the Uncompressed Data Chunk
+     * @firstPartSize: the size in bytes of the first partition (control
+     *   partition), excluding the uncompressed data chunk
+     * @width: the frame width in pixels
+     * @height: the frame height in pixels
+     * @horizScaleCode: horizontal scale code value
+     * @vertScaleCode: vertical scale code value
+     * @colorSpace: defines the YUV color space of the sequence
+     * @clampingType: specifies if the decoder is required to clamp the
+     *   reconstructed pixel values
+     * @filterType: determines whether the normal or the simple loop
+     *   filter is used
+     * @loopFilterLevel: controls the deblocking filter
+     * @sharpnessLevel: controls the deblocking filter
+     * @log2NbrOfDctPartitions: determines the number of separate
+     *   partitions containing the DCT coefficients of the macroblocks
+     * @partitionSize: determines the size of each separate partition
+     *   containing the DCT coefficients of the macroblocks, including the
+     *   very last one (calculated size)
+     * @quantIndices: dequantization indices (see #VP8QuantIndices)
+     * @tokenProbs: token probabilities (see #VP8TokenProbs)
+     * @mvProbs: probabilities used for motion vector decoding
+     *   (see #VP8MvProbs)
+     * @modeProbs: probabilities used for intra-prediction mode decoding
+     *   tree (see #VP8ModeProbs)
+     * @refreshEntropyProbs: determines whether updated token
+     *   probabilities are used only for this frame or until further update
+     * @refreshGoldenFrame: determines if the current decoded frame
+     *   refreshes the golden frame
+     * @refreshAlternateFrame: determines if the current decoded frame
+     *   refreshes the alternate reference frame
+     * @copyBufferToGolden: determines if the golden reference is
+     *   replaced by another reference
+     * @copyBufferToAlternate: determines if the alternate reference is
+     *   replaced by another reference
+     * @signBiasGolden: controls the sign of motion vectors when the
+     *   golden frame is referenced
+     * @signBiasAlternate: controls the sign of motion vectors when the
+     *   alternate frame is referenced
+     * @refreshLast: determines if the current decoded frame refreshes
+     *   the last frame reference buffer
+     * @mbNoSkipCoeff: enables (0) or disables (1) the skipping of
+     *   macroblocks containing no non-zero coefficients
+     * @probSkipFalse: indicates the probability that the macroblock is
+     *   not skipped
+     * @probIntra: indicates the probability of an intra macroblock
+     * @probLast: indicates the probability that the last reference frame
+     *   is used for inter-prediction
+     * @probGf: indicates the probability that the golden reference frame
+     *   is used for inter-prediction
+     * @rdRange: last range decoder value for "Range"
+     * @rdValue: last range decoder value for "Value"
+     * @rdCount: number of bits left in range decoder "Value" (@rdValue)
+     * @headerSize: the size in bits of the Frame Header, thus excluding
+     *   any Uncompressed Data Chunk bytes
+     *
+     * Frame header.
+     */
+    struct VP8FrameHdr
+    {
+        uint8_t keyFrame;
+        uint8_t version;
+        uint8_t showFrame;
+        uint8_t dataChunkSize;
+        uint32_t firstPartSize;
+
+        /* if keyFrame == 1 */
+        uint16_t width;
+        uint16_t height;
+        uint8_t horizScaleCode;
+        uint8_t vertScaleCode;
+        uint8_t colorSpace;
+        uint8_t clampingType;
+
+        uint8_t filterType;
+        uint8_t loopFilterLevel;
+        uint8_t sharpnessLevel;
+        uint8_t log2NbrOfDctPartitions;
+        unsigned int partitionSize[8];
+
+        VP8QuantIndices quantIndices;
+        VP8TokenProbs tokenProbs;
+        VP8MvProbs mvProbs;
+        VP8ModeProbs modeProbs;
+
+        uint8_t refreshEntropyProbs;
+        uint8_t refreshLast;
+        /* if keyFrame != 1 */
+        uint8_t refreshGoldenFrame;
+        uint8_t refreshAlternateFrame;
+        uint8_t copyBufferToGolden;
+        uint8_t copyBufferToAlternate;
+        uint8_t signBiasGolden;
+        uint8_t signBiasAlternate;
+
+        uint8_t mbNoSkipCoeff;
+        uint8_t probSkipFalse;
+
+        /* if keyFrame != 1 */
+        uint8_t probIntra;
+        uint8_t probLast;
+        uint8_t probGf;
+
+        /* Range decoder state */
+        uint8_t rdRange;
+        uint8_t rdValue;
+        uint8_t rdCount;
+
+        /* Size of the Frame Header in bits */
+        unsigned int headerSize;
+    };
+
+    /**
+     * VP8Parser:
+     * @mSegmentation: segmentation feature data
+     * @mMbLfAdjust: MB-level loop filter adjustments
+     * @mTokenProbs: token probabilities
+     * @mMvProbs: probabilities used for motion vector decoding
+     * @mModeProbs: probabilities used for intra-prediction mode decoding tree.
+     *
+     * Parser context that needs to be live across frames. For instance
+     * the probabilities tables stored in #VP8FrameHdr may depend on
+     * the previous frames.
+     */
+    class VP8Parser {
+        public:
+            enum Result {
+                Ok,
+                BrokenData,
+                Error,
+            };
+
+        public:
+            VP8Parser (void);
+            Result parseFrameHeader (VP8FrameHdr &frameHdr, const uint8_t *data, size_t size);
+
+            VP8Segmentation mSegmentation;
+            VP8MbLfAdjustments mMbLfAdjust;
+
+        private:
+            void init ();
+            Result parseFrameHeader (VP8RangeDecoder &rd, VP8FrameHdr &frameHdr);
+            Result parseUncompressedDataChunk (ByteReader &br, VP8FrameHdr &frameHdr);
+            bool parseUpdateSegmentation (VP8RangeDecoder &rd, VP8Segmentation &seg);
+
+            static bool calcPartitionSizes (VP8FrameHdr &frameHdr, const uint8_t *data,
+                    unsigned int size);
+            static bool parseMvProbUpdate (VP8RangeDecoder &rd, VP8MvProbs &probs);
+            static bool parseTokenProbUpdate (VP8RangeDecoder &rd, VP8TokenProbs &probs);
+            static bool parseQuantIndices (VP8RangeDecoder &rd, VP8QuantIndices &qip);
+            static bool parseMbLfAdjustments (VP8RangeDecoder &rd, VP8MbLfAdjustments &adj);
+
+            VP8TokenProbs mTokenProbs;
+            VP8MvProbs mMvProbs;
+            VP8ModeProbs mModeProbs;
+
+            static constexpr uint8_t mvUpdateProbs[2][19] = {
+                {
+                    237,
+                    246,
+                    253, 253, 254, 254, 254, 254, 254,
+                    254, 254, 254, 254, 254, 250, 250, 252, 254, 254
+                },
+                {
+                    231,
+                    243,
+                    245, 253, 254, 254, 254, 254, 254,
+                    254, 254, 254, 254, 254, 251, 251, 254, 254, 254
+                }
+            };
+
+            static constexpr uint8_t defaultMvProbs[2][19] = {
+                {
+                    /* row */
+                    162,                                        /* is short */
+                    128,                                        /* sign */
+                    225, 146, 172, 147, 214,  39, 156,          /* short tree */
+                    128, 129, 132,  75, 145, 178, 206, 239, 254, 254 /* long bits */
+                },
+                {
+                    /* same for column */
+                    164,                                        /* is short */
+                    128,
+                    204, 170, 119, 235, 140, 230, 228,
+                    128, 130, 130,  74, 148, 180, 203, 236, 254, 254 /* long bits */
+                }
+            };
+
+            static constexpr uint8_t nkYModeProbs[4] = {
+                112, 86, 140, 37
+            };
+
+            static constexpr uint8_t kfYModeProbs[4] = {
+                145, 156, 163, 128
+            };
+
+            static constexpr uint8_t nkUvModeProbs[3] = {
+                162, 101, 204
+            };
+
+            static constexpr uint8_t kfUvModeProbs[3] = {
+                142, 114, 183
+            };
+
+            static constexpr uint8_t tokenUpdateProbs[4][8][3][11] = {
+                {
+                    {
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {176, 246, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {223, 241, 252, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {249, 253, 253, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 244, 252, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {234, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {253, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 246, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {239, 253, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {254, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 248, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {251, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 253, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {251, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {254, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 254, 253, 255, 254, 255, 255, 255, 255, 255, 255, },
+                        {250, 255, 254, 255, 254, 255, 255, 255, 255, 255, 255, },
+                        {254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                },
+                {
+                    {
+                        {217, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {225, 252, 241, 253, 255, 255, 254, 255, 255, 255, 255, },
+                        {234, 250, 241, 250, 253, 255, 253, 254, 255, 255, 255, },
+                    },
+                    {
+                        {255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {223, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {238, 253, 254, 254, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 248, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {249, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 253, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {247, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 253, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {252, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {253, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 254, 253, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {250, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                },
+                {
+                    {
+                        {186, 251, 250, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {234, 251, 244, 254, 255, 255, 255, 255, 255, 255, 255, },
+                        {251, 251, 243, 253, 254, 255, 254, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 253, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {236, 253, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {251, 253, 253, 254, 254, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {254, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {254, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                },
+                {
+                    {
+                        {248, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {250, 254, 252, 254, 255, 255, 255, 255, 255, 255, 255, },
+                        {248, 254, 249, 253, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 253, 253, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {246, 253, 253, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {252, 254, 251, 254, 254, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 254, 252, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {248, 254, 253, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {253, 255, 254, 254, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 251, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {245, 251, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {253, 253, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 251, 253, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {252, 253, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 252, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {249, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 255, 253, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {250, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                    {
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                        {255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, },
+                    },
+                },
+            };
+
+            static constexpr uint8_t defaultTokenProbs[4][8][3][11] = {
+                { /* Block Type ( 0 ) */
+                    { /* Coeff Band ( 0 )*/
+                        { 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128 },
+                        { 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128 },
+                        { 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128 }
+                    },
+                    { /* Coeff Band ( 1 )*/
+                        { 253, 136, 254, 255, 228, 219, 128, 128, 128, 128, 128 },
+                        { 189, 129, 242, 255, 227, 213, 255, 219, 128, 128, 128 },
+                        { 106, 126, 227, 252, 214, 209, 255, 255, 128, 128, 128 }
+                    },
+                    { /* Coeff Band ( 2 )*/
+                        {   1,  98, 248, 255, 236, 226, 255, 255, 128, 128, 128 },
+                        { 181, 133, 238, 254, 221, 234, 255, 154, 128, 128, 128 },
+                        {  78, 134, 202, 247, 198, 180, 255, 219, 128, 128, 128 }
+                    },
+                    { /* Coeff Band ( 3 )*/
+                        {   1, 185, 249, 255, 243, 255, 128, 128, 128, 128, 128 },
+                        { 184, 150, 247, 255, 236, 224, 128, 128, 128, 128, 128 },
+                        {  77, 110, 216, 255, 236, 230, 128, 128, 128, 128, 128 }
+                    },
+                    { /* Coeff Band ( 4 )*/
+                        {   1, 101, 251, 255, 241, 255, 128, 128, 128, 128, 128 },
+                        { 170, 139, 241, 252, 236, 209, 255, 255, 128, 128, 128 },
+                        {  37, 116, 196, 243, 228, 255, 255, 255, 128, 128, 128 }
+                    },
+                    { /* Coeff Band ( 5 )*/
+                        {   1, 204, 254, 255, 245, 255, 128, 128, 128, 128, 128 },
+                        { 207, 160, 250, 255, 238, 128, 128, 128, 128, 128, 128 },
+                        { 102, 103, 231, 255, 211, 171, 128, 128, 128, 128, 128 }
+                    },
+                    { /* Coeff Band ( 6 )*/
+                        {   1, 152, 252, 255, 240, 255, 128, 128, 128, 128, 128 },
+                        { 177, 135, 243, 255, 234, 225, 128, 128, 128, 128, 128 },
+                        {  80, 129, 211, 255, 194, 224, 128, 128, 128, 128, 128 }
+                    },
+                    { /* Coeff Band ( 7 )*/
+                        {   1,   1, 255, 128, 128, 128, 128, 128, 128, 128, 128 },
+                        { 246,   1, 255, 128, 128, 128, 128, 128, 128, 128, 128 },
+                        { 255, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128 }
+                    }
+                },
+                { /* Block Type ( 1 ) */
+                    { /* Coeff Band ( 0 )*/
+                        { 198,  35, 237, 223, 193, 187, 162, 160, 145, 155,  62 },
+                        { 131,  45, 198, 221, 172, 176, 220, 157, 252, 221,   1 },
+                        {  68,  47, 146, 208, 149, 167, 221, 162, 255, 223, 128 }
+                    },
+                    { /* Coeff Band ( 1 )*/
+                        {   1, 149, 241, 255, 221, 224, 255, 255, 128, 128, 128 },
+                        { 184, 141, 234, 253, 222, 220, 255, 199, 128, 128, 128 },
+                        {  81,  99, 181, 242, 176, 190, 249, 202, 255, 255, 128 }
+                    },
+                    { /* Coeff Band ( 2 )*/
+                        {   1, 129, 232, 253, 214, 197, 242, 196, 255, 255, 128 },
+                        {  99, 121, 210, 250, 201, 198, 255, 202, 128, 128, 128 },
+                        {  23,  91, 163, 242, 170, 187, 247, 210, 255, 255, 128 }
+                    },
+                    { /* Coeff Band ( 3 )*/
+                        {   1, 200, 246, 255, 234, 255, 128, 128, 128, 128, 128 },
+                        { 109, 178, 241, 255, 231, 245, 255, 255, 128, 128, 128 },
+                        {  44, 130, 201, 253, 205, 192, 255, 255, 128, 128, 128 }
+                    },
+                    { /* Coeff Band ( 4 )*/
+                        {   1, 132, 239, 251, 219, 209, 255, 165, 128, 128, 128 },
+                        {  94, 136, 225, 251, 218, 190, 255, 255, 128, 128, 128 },
+                        {  22, 100, 174, 245, 186, 161, 255, 199, 128, 128, 128 }
+                    },
+                    { /* Coeff Band ( 5 )*/
+                        {   1, 182, 249, 255, 232, 235, 128, 128, 128, 128, 128 },
+                        { 124, 143, 241, 255, 227, 234, 128, 128, 128, 128, 128 },
+                        {  35,  77, 181, 251, 193, 211, 255, 205, 128, 128, 128 }
+                    },
+                    { /* Coeff Band ( 6 )*/
+                        {   1, 157, 247, 255, 236, 231, 255, 255, 128, 128, 128 },
+                        { 121, 141, 235, 255, 225, 227, 255, 255, 128, 128, 128 },
+                        {  45,  99, 188, 251, 195, 217, 255, 224, 128, 128, 128 }
+                    },
+                    { /* Coeff Band ( 7 )*/
+                        {   1,   1, 251, 255, 213, 255, 128, 128, 128, 128, 128 },
+                        { 203,   1, 248, 255, 255, 128, 128, 128, 128, 128, 128 },
+                        { 137,   1, 177, 255, 224, 255, 128, 128, 128, 128, 128 }
+                    }
+                },
+                { /* Block Type ( 2 ) */
+                    { /* Coeff Band ( 0 )*/
+                        { 253,   9, 248, 251, 207, 208, 255, 192, 128, 128, 128 },
+                        { 175,  13, 224, 243, 193, 185, 249, 198, 255, 255, 128 },
+                        {  73,  17, 171, 221, 161, 179, 236, 167, 255, 234, 128 }
+                    },
+                    { /* Coeff Band ( 1 )*/
+                        {   1,  95, 247, 253, 212, 183, 255, 255, 128, 128, 128 },
+                        { 239,  90, 244, 250, 211, 209, 255, 255, 128, 128, 128 },
+                        { 155,  77, 195, 248, 188, 195, 255, 255, 128, 128, 128 }
+                    },
+                    { /* Coeff Band ( 2 )*/
+                        {   1,  24, 239, 251, 218, 219, 255, 205, 128, 128, 128 },
+                        { 201,  51, 219, 255, 196, 186, 128, 128, 128, 128, 128 },
+                        {  69,  46, 190, 239, 201, 218, 255, 228, 128, 128, 128 }
+                    },
+                    { /* Coeff Band ( 3 )*/
+                        {   1, 191, 251, 255, 255, 128, 128, 128, 128, 128, 128 },
+                        { 223, 165, 249, 255, 213, 255, 128, 128, 128, 128, 128 },
+                        { 141, 124, 248, 255, 255, 128, 128, 128, 128, 128, 128 }
+                    },
+                    { /* Coeff Band ( 4 )*/
+                        {   1,  16, 248, 255, 255, 128, 128, 128, 128, 128, 128 },
+                        { 190,  36, 230, 255, 236, 255, 128, 128, 128, 128, 128 },
+                        { 149,   1, 255, 128, 128, 128, 128, 128, 128, 128, 128 }
+                    },
+                    { /* Coeff Band ( 5 )*/
+                        {   1, 226, 255, 128, 128, 128, 128, 128, 128, 128, 128 },
+                        { 247, 192, 255, 128, 128, 128, 128, 128, 128, 128, 128 },
+                        { 240, 128, 255, 128, 128, 128, 128, 128, 128, 128, 128 }
+                    },
+                    { /* Coeff Band ( 6 )*/
+                        {   1, 134, 252, 255, 255, 128, 128, 128, 128, 128, 128 },
+                        { 213,  62, 250, 255, 255, 128, 128, 128, 128, 128, 128 },
+                        {  55,  93, 255, 128, 128, 128, 128, 128, 128, 128, 128 }
+                    },
+                    { /* Coeff Band ( 7 )*/
+                        { 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128 },
+                        { 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128 },
+                        { 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128 }
+                    }
+                },
+                { /* Block Type ( 3 ) */
+                    { /* Coeff Band ( 0 )*/
+                        { 202,  24, 213, 235, 186, 191, 220, 160, 240, 175, 255 },
+                        { 126,  38, 182, 232, 169, 184, 228, 174, 255, 187, 128 },
+                        {  61,  46, 138, 219, 151, 178, 240, 170, 255, 216, 128 }
+                    },
+                    { /* Coeff Band ( 1 )*/
+                        {   1, 112, 230, 250, 199, 191, 247, 159, 255, 255, 128 },
+                        { 166, 109, 228, 252, 211, 215, 255, 174, 128, 128, 128 },
+                        {  39,  77, 162, 232, 172, 180, 245, 178, 255, 255, 128 }
+                    },
+                    { /* Coeff Band ( 2 )*/
+                        {   1,  52, 220, 246, 198, 199, 249, 220, 255, 255, 128 },
+                        { 124,  74, 191, 243, 183, 193, 250, 221, 255, 255, 128 },
+                        {  24,  71, 130, 219, 154, 170, 243, 182, 255, 255, 128 }
+                    },
+                    { /* Coeff Band ( 3 )*/
+                        {   1, 182, 225, 249, 219, 240, 255, 224, 128, 128, 128 },
+                        { 149, 150, 226, 252, 216, 205, 255, 171, 128, 128, 128 },
+                        {  28, 108, 170, 242, 183, 194, 254, 223, 255, 255, 128 }
+                    },
+                    { /* Coeff Band ( 4 )*/
+                        {   1,  81, 230, 252, 204, 203, 255, 192, 128, 128, 128 },
+                        { 123, 102, 209, 247, 188, 196, 255, 233, 128, 128, 128 },
+                        {  20,  95, 153, 243, 164, 173, 255, 203, 128, 128, 128 }
+                    },
+                    { /* Coeff Band ( 5 )*/
+                        {   1, 222, 248, 255, 216, 213, 128, 128, 128, 128, 128 },
+                        { 168, 175, 246, 252, 235, 205, 255, 255, 128, 128, 128 },
+                        {  47, 116, 215, 255, 211, 212, 255, 255, 128, 128, 128 }
+                    },
+                    { /* Coeff Band ( 6 )*/
+                        {   1, 121, 236, 253, 212, 214, 255, 255, 128, 128, 128 },
+                        { 141,  84, 213, 252, 201, 202, 255, 219, 128, 128, 128 },
+                        {  42,  80, 160, 240, 162, 185, 255, 205, 128, 128, 128 }
+                    },
+                    { /* Coeff Band ( 7 )*/
+                        {   1,   1, 255, 128, 128, 128, 128, 128, 128, 128, 128 },
+                        { 244,   1, 255, 128, 128, 128, 128, 128, 128, 128, 128 },
+                        { 238,   1, 255, 128, 128, 128, 128, 128, 128, 128, 128 }
+                    }
+                }
+            };
+    };
+
+}  // namespace android
+
+#endif  // ANDROID_V4L2_CODEC2_COMPONENTS_VP8_PARSER_VP8_PARSER_H
diff --git a/components/include/v4l2_codec2/components/vp8/parser/VP8Picture.h b/components/include/v4l2_codec2/components/vp8/parser/VP8Picture.h
new file mode 100644
index 0000000..1b63428
--- /dev/null
+++ b/components/include/v4l2_codec2/components/vp8/parser/VP8Picture.h
@@ -0,0 +1,46 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * GStreamer
+ * Copyright (C) 2019 Seungha Yang <seungha.yang@navercorp.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#ifndef ANDROID_V4L2_CODEC2_COMPONENTS_VP8_PARSER_VP8_PICTURE_H
+#define ANDROID_V4L2_CODEC2_COMPONENTS_VP8_PARSER_VP8_PICTURE_H
+
+#include "VP8Parser.h"
+
+namespace android {
+
+struct VP8Picture {
+  uint32_t systemFrameNumber;
+
+  VP8FrameHdr frameHdr;
+
+  /* raw data and size (does not have ownership) */
+  const uint8_t *data;
+  size_t size;
+
+    std::shared_ptr<void> userData;
+};
+
+using VP8PicturePtr = std::shared_ptr<VP8Picture>;
+
+} // android
+
+#endif // ANDROID_V4L2_CODEC2_COMPONENTS_VP8_PARSER_VP8_PICTURE_H
diff --git a/components/include/v4l2_codec2/components/vp8/parser/VP8RangeDecoder.h b/components/include/v4l2_codec2/components/vp8/parser/VP8RangeDecoder.h
new file mode 100644
index 0000000..e060d7f
--- /dev/null
+++ b/components/include/v4l2_codec2/components/vp8/parser/VP8RangeDecoder.h
@@ -0,0 +1,54 @@
+/*
+ * NOTE: some of implementations are copied/modified from WebM code
+ *
+ *  Copyright (c) 2010 The WebM project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef ANDROID_V4L2_CODEC2_COMPONENTS_VP8_PARSER_VP8_RANGE_DECODER_H
+#define ANDROID_V4L2_CODEC2_COMPONENTS_VP8_PARSER_VP8_RANGE_DECODER_H
+
+#include "VP8BoolDecoder.h"
+
+namespace android {
+
+    /**
+     * GstVP8RangeDecoder:
+     * @buf: the original bitstream buffer start
+     * @bufSize: the original bitstream buffer size
+     *
+     * Range decoder.
+     */
+
+    class VP8RangeDecoder : VP8BoolDecoder {
+        public:
+            struct State {
+                uint8_t range;
+                uint8_t value;
+                uint8_t count;
+            };
+
+            VP8RangeDecoder (const unsigned char *buf, unsigned int bufSize);
+
+            unsigned int getPos ();
+            void getState (VP8RangeDecoder::State &state);
+
+            int read (uint8_t prob);
+            int readLiteral (int bits);
+
+            bool readBool (void);
+            unsigned int readUint (int nbits);
+            int readSint (int nbits);
+
+        private:
+            const unsigned char *mBuf;
+    };
+
+}
+
+#endif // ANDROID_V4L2_CODEC2_COMPONENTS_VP8_PARSER_VP8_RANGE_DECODER_H
diff --git a/components/vp8/V4L2VP8Decoder.cpp b/components/vp8/V4L2VP8Decoder.cpp
new file mode 100644
index 0000000..e428117
--- /dev/null
+++ b/components/vp8/V4L2VP8Decoder.cpp
@@ -0,0 +1,309 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * GStreamer
+ * Copyright (C) 2020 Nicolas Dufresne <nicolas.dufresne@collabora.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "V4L2VP8Decoder"
+
+#include <v4l2_codec2/components/vp8/V4L2VP8Decoder.h>
+#include <base/memory/ptr_util.h>
+#include <sys/mman.h>
+
+#include <cstdio>
+#include <iostream>
+#include <fstream>
+
+#define KERNEL_VERSION(a,b,c) (((a) << 16) + ((b) << 8) + (c))
+
+#define V4L2_MIN_KERNEL_VER_MAJOR 5
+#define V4L2_MIN_KERNEL_VER_MINOR 13
+#define V4L2_MIN_KERNEL_VERSION KERNEL_VERSION(V4L2_MIN_KERNEL_VER_MAJOR, V4L2_MIN_KERNEL_VER_MINOR, 0)
+
+#define N_ELEMENTS(arr) (sizeof (arr) / sizeof ((arr)[0]))
+
+using namespace std::chrono_literals;
+
+namespace android {
+
+    std::unique_ptr<VideoDecoder> V4L2VP8Decoder::Create(
+            const size_t inputBufferSize,
+            GetPoolCB getPoolCb, OutputCB outputCb, ErrorCB errorCb,
+            scoped_refptr<::base::SequencedTaskRunner> taskRunner) {
+        std::unique_ptr<V4L2VP8Decoder> decoder =
+            ::base::WrapUnique<V4L2VP8Decoder>(new V4L2VP8Decoder(taskRunner));
+        if (!decoder->start(VideoCodec::VP8, inputBufferSize, std::move(getPoolCb),
+                    std::move(outputCb), std::move(errorCb))) {
+            return nullptr;
+        }
+
+        return decoder;
+    }
+
+    V4L2VP8Decoder::V4L2VP8Decoder(scoped_refptr<::base::SequencedTaskRunner> taskRunner)
+        : V4L2Decoder(taskRunner), mWidth(0), mHeight(0) {
+    }
+
+    V4L2VP8Decoder::~V4L2VP8Decoder() {
+    }
+
+    unsigned int V4L2VP8Decoder::getPreferredOutputDelay (bool live)
+    {
+        return live ? 0 : 1;
+    }
+
+    bool V4L2VP8Decoder::negotiate (void)
+    {
+        std::vector<V4L2ExtCtrl> controls;
+        struct v4l2_ext_control control = {
+            .id = V4L2_CID_STATELESS_VP8_FRAME,
+            .ptr = &mFrameHeader,
+            .size = sizeof(mFrameHeader),
+        };
+        controls.push_back(V4L2ExtCtrl(control));
+
+        ALOGV("Negotiate");
+
+        return changeResolution(ui::Size(mWidth, mHeight), controls);
+    }
+
+    void V4L2VP8Decoder::fillSegment (struct v4l2_vp8_segment &segment,
+            const VP8Segmentation &segmentation)
+    {
+        int i;
+
+        segment.flags =
+            (segmentation.segmentationEnabled ? V4L2_VP8_SEGMENT_FLAG_ENABLED : 0) |
+            (segmentation.updateMbSegmentationMap ? V4L2_VP8_SEGMENT_FLAG_UPDATE_MAP : 0) |
+            (segmentation.updateSegmentFeatureData ? V4L2_VP8_SEGMENT_FLAG_UPDATE_FEATURE_DATA : 0) |
+            (segmentation.segmentFeatureMode ? 0 : V4L2_VP8_SEGMENT_FLAG_DELTA_VALUE_MODE);
+
+        for (i = 0; i < 4; i++) {
+            segment.quant_update[i] = segmentation.quantizerUpdateValue[i];
+            segment.lf_update[i] = segmentation.lfUpdateValue[i];
+        }
+
+        for (i = 0; i < 3; i++)
+            segment.segment_probs[i] = segmentation.segmentProb[i];
+
+        segment.padding = 0;
+    }
+
+    void V4L2VP8Decoder::fillLf (struct v4l2_vp8_loop_filter &lf,
+            const VP8MbLfAdjustments &lfAdj)
+    {
+        int i;
+
+        lf.flags |= (lfAdj.loopFilterAdjEnable ? V4L2_VP8_LF_ADJ_ENABLE : 0) |
+            (lfAdj.modeRefLfDeltaUpdate ? V4L2_VP8_LF_DELTA_UPDATE : 0);
+
+        for (i = 0; i < 4; i++) {
+            lf.ref_frm_delta[i] = lfAdj.refFrameDelta[i];
+            lf.mb_mode_delta[i] = lfAdj.mbModeDelta[i];
+        }
+    }
+
+    void V4L2VP8Decoder::fillEntropy (struct v4l2_vp8_entropy &entropy,
+            const VP8FrameHdr &frameHdr)
+    {
+        memcpy(entropy.coeff_probs, frameHdr.tokenProbs.prob, sizeof(frameHdr.tokenProbs.prob));
+        memcpy(entropy.y_mode_probs, frameHdr.modeProbs.yProb, sizeof(frameHdr.modeProbs.yProb));
+        memcpy(entropy.uv_mode_probs, frameHdr.modeProbs.uvProb, sizeof(frameHdr.modeProbs.uvProb));
+        memcpy(entropy.mv_probs, frameHdr.mvProbs.prob, sizeof(frameHdr.mvProbs.prob));
+    }
+
+    void V4L2VP8Decoder::fillFrameHeader (const VP8FrameHdr &frameHdr)
+    {
+        int i;
+
+        mFrameHeader = (struct v4l2_ctrl_vp8_frame) {
+            .lf = (struct v4l2_vp8_loop_filter) {
+                .sharpness_level = frameHdr.sharpnessLevel,
+                .level = frameHdr.loopFilterLevel,
+                .flags = (uint32_t) (frameHdr.filterType == 1 ? V4L2_VP8_LF_FILTER_TYPE_SIMPLE : 0)
+            },
+            .quant = (struct v4l2_vp8_quantization) {
+                .y_ac_qi = frameHdr.quantIndices.yAcQi,
+                .y_dc_delta = frameHdr.quantIndices.yDcDelta,
+                .y2_dc_delta = frameHdr.quantIndices.y2DcDelta,
+                .y2_ac_delta = frameHdr.quantIndices.y2AcDelta,
+                .uv_dc_delta = frameHdr.quantIndices.uvDcDelta,
+                .uv_ac_delta = frameHdr.quantIndices.uvAcDelta
+            },
+            .coder_state = (struct v4l2_vp8_entropy_coder_state) {
+                .range = frameHdr.rdRange,
+                .value = frameHdr.rdValue,
+                .bit_count = frameHdr.rdCount
+            },
+
+            .width = mWidth,
+            .height = mHeight,
+
+            .horizontal_scale = frameHdr.horizScaleCode,
+            .vertical_scale = frameHdr.vertScaleCode,
+
+            .version = frameHdr.version,
+            .prob_skip_false = frameHdr.probSkipFalse,
+            .prob_intra = frameHdr.probIntra,
+            .prob_last = frameHdr.probLast,
+            .prob_gf = frameHdr.probGf,
+            .num_dct_parts = (uint8_t) (1 << frameHdr.log2NbrOfDctPartitions),
+
+            .first_part_size = frameHdr.firstPartSize,
+            .first_part_header_bits = frameHdr.headerSize,
+
+            .flags = (uint64_t) (frameHdr.keyFrame ? V4L2_VP8_FRAME_FLAG_KEY_FRAME : 0) |
+                (frameHdr.showFrame ? V4L2_VP8_FRAME_FLAG_SHOW_FRAME : 0) |
+                (frameHdr.mbNoSkipCoeff ? V4L2_VP8_FRAME_FLAG_MB_NO_SKIP_COEFF : 0) |
+                (frameHdr.signBiasGolden ? V4L2_VP8_FRAME_FLAG_SIGN_BIAS_GOLDEN : 0) |
+                (frameHdr.signBiasAlternate ? V4L2_VP8_FRAME_FLAG_SIGN_BIAS_ALT : 0),
+        };
+
+        for (i = 0; i < 8; i++)
+            mFrameHeader.dct_part_sizes[i] = frameHdr.partitionSize[i];
+
+        fillEntropy(mFrameHeader.entropy, frameHdr);
+    }
+
+    void V4L2VP8Decoder::fillReferences ()
+    {
+        if (mLastPicture) {
+            mFrameHeader.last_frame_ts = mLastPicture->systemFrameNumber * 1000;
+        }
+
+        if (mGoldenRefPicture) {
+            mFrameHeader.golden_frame_ts = mGoldenRefPicture->systemFrameNumber * 1000;
+        }
+
+        if (mAltRefPicture) {
+            mFrameHeader.alt_frame_ts = mAltRefPicture->systemFrameNumber * 1000;
+        }
+
+        ALOGV("Passing references: last %u, golden %u, alt %u",
+                (uint32_t) mFrameHeader.last_frame_ts / 1000,
+                (uint32_t) mFrameHeader.golden_frame_ts / 1000,
+                (uint32_t) mFrameHeader.alt_frame_ts / 1000);
+    }
+
+    bool V4L2VP8Decoder::newSequence (const VP8FrameHdr &frameHdr, int maxDpbSize)
+    {
+        bool negotiationNeeded = false;
+
+        /* TODO Check if current buffers are large enough, and reuse them */
+        ALOGV("Check resolution %dx%d vs %hux%hu", frameHdr.width, frameHdr.height, mWidth, mHeight);
+        if (mWidth != frameHdr.width || mHeight != frameHdr.height) {
+            mWidth = frameHdr.width;
+            mHeight = frameHdr.height;
+            negotiationNeeded = true;
+            ALOGI("Resolution changed to %hux%hu", mWidth, mHeight);
+        }
+
+        fillFrameHeader(frameHdr);
+
+        if (negotiationNeeded) {
+            if (!negotiate()) {
+                ALOGE("Failed to negotiate with downstream");
+                return false;
+            }
+        }
+
+        return true;
+    }
+
+    bool V4L2VP8Decoder::startPicture (const VP8PicturePtr &picture)
+    {
+        return V4L2Decoder::ensureInputBuffer();
+    }
+
+    bool V4L2VP8Decoder::decodePicture (const VP8PicturePtr &picture)
+    {
+        uint8_t *bitstreamData = reinterpret_cast<uint8_t *>(mInputBuffer->getPlaneMapping(0));
+        if (!bitstreamData)
+            return false;
+
+        if (picture->size > mInputBuffer->getPlaneSize(0)) {
+            ALOGE("Not enough space to send the whole picture.");
+            return false;
+        }
+
+        fillFrameHeader(picture->frameHdr);
+        fillSegment(mFrameHeader.segment, mParser.mSegmentation);
+        fillLf(mFrameHeader.lf, mParser.mMbLfAdjust);
+        fillReferences();
+
+        memcpy(bitstreamData, picture->data, picture->size);
+        mInputBuffer->setPlaneBytesUsed(0, picture->size);
+
+        return true;
+    }
+
+    bool V4L2VP8Decoder::endPicture (const VP8PicturePtr &picture)
+    {
+        std::vector<V4L2ExtCtrl> controls;
+        RequestHandle request;
+
+        struct v4l2_ext_control control = {
+            .id = V4L2_CID_STATELESS_VP8_FRAME,
+            .ptr = &mFrameHeader,
+            .size = sizeof(mFrameHeader),
+        };
+
+        controls.push_back(V4L2ExtCtrl(control));
+
+        request = allocRequest(picture->systemFrameNumber);
+
+        /* Keep a reference to hold the decoded data until it is not used anymore */
+        if (request)
+            picture->userData = submitRequest(request, controls, 0);
+        else
+        {
+            picture->userData = nullptr;
+            ALOGE("%s() cannot allocate request", __func__);
+        }
+
+        // Nothing to do?
+        //resetPicture();
+
+        return picture->userData != nullptr;
+    }
+
+    bool V4L2VP8Decoder::outputPicture (const VP8PicturePtr &picture)
+    {
+        finish(picture->systemFrameNumber);
+
+        return true;
+    }
+
+    bool V4L2VP8Decoder::decode(std::unique_ptr<ConstBitstreamBuffer> buffer)
+    {
+        return VP8Decoder::decode(std::move(buffer));
+    }
+
+    void V4L2VP8Decoder::flushInternal (void)
+    {
+        VP8Decoder::flush();
+    }
+
+    bool V4L2VP8Decoder::drainInternal()
+    {
+        return VP8Decoder::drain();
+    }
+
+}  // namespace android
diff --git a/components/vp8/VP8Decoder.cpp b/components/vp8/VP8Decoder.cpp
new file mode 100644
index 0000000..68f46bd
--- /dev/null
+++ b/components/vp8/VP8Decoder.cpp
@@ -0,0 +1,275 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * GStreamer
+ * Copyright (C) 2020 Nicolas Dufresne <nicolas.dufresne@collabora.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "VP8Decoder"
+
+#include <v4l2_codec2/common/Common.h>
+#include <v4l2_codec2/common/Fourcc.h>
+#include <v4l2_codec2/components/vp8/VP8Decoder.h>
+
+namespace android {
+
+    VP8Decoder::VP8Decoder (void)
+        : mHadSequence(false), mWaitKeyFrame(true)
+    {
+    }
+
+    void VP8Decoder::reset (void)
+    {
+        mLastPicture.reset();
+        mGoldenRefPicture.reset();
+        mAltRefPicture.reset();
+
+        mWaitKeyFrame = true;
+        std::queue<VP8PicturePtr>().swap(mOutputQueue);
+    }
+
+    bool VP8Decoder::checkCodecChange (const VP8FrameHdr &frameHdr)
+    {
+        bool ret = true;
+        bool changed = false;
+
+        ALOGV("Check resolution %dx%d vs %dx%d", frameHdr.width, frameHdr.height, mWidth, mHeight);
+        if (mWidth != frameHdr.width || mHeight != frameHdr.height) {
+            ALOGI("Resolution changed to %dx%d", frameHdr.width, frameHdr.height);
+            mWidth = frameHdr.width;
+            mHeight = frameHdr.height;
+            changed = true;
+        }
+
+        if (changed || !mHadSequence) {
+            ALOGV("Prepare for new sequence");
+            /* Drain before new sequence */
+            ret = drainInternal(false);
+            if (!ret) {
+                ALOGW("Failed to drain pending frames");
+                return ret;
+            }
+
+            mHadSequence = true;
+
+            mPreferredOutputDelay = getPreferredOutputDelay(mIsLive);
+
+            /* last/golden/alt 3 reference pictures + current picture */
+            ret = newSequence(frameHdr, 4 + mPreferredOutputDelay);
+        }
+
+        return ret;
+    }
+
+    bool VP8Decoder::updateReference (VP8PicturePtr picture)
+    {
+        VP8FrameHdr *frameHdr = &picture->frameHdr;
+
+        if (frameHdr->keyFrame) {
+            mLastPicture = picture;
+            mGoldenRefPicture = picture;
+            mAltRefPicture = picture;
+
+            return true;
+        }
+
+        if (frameHdr->refreshAlternateFrame) {
+            mAltRefPicture = picture;
+        } else {
+            switch (frameHdr->copyBufferToAlternate) {
+                case 0:
+                    /* do nothing */
+                    break;
+                case 1:
+                    mAltRefPicture = mLastPicture;
+                    break;
+                case 2:
+                    mAltRefPicture = mGoldenRefPicture;
+                    break;
+                default:
+                    ALOGW("unrecognized copyBufferToAlternate %d", frameHdr->copyBufferToAlternate);
+                    break;
+            }
+        }
+
+        if (frameHdr->refreshGoldenFrame) {
+            mGoldenRefPicture = picture;
+        } else {
+            switch (frameHdr->copyBufferToGolden) {
+                case 0:
+                    /* do nothing */
+                    break;
+                case 1:
+                    mGoldenRefPicture = mLastPicture;
+                    break;
+                case 2:
+                    mGoldenRefPicture = mAltRefPicture;
+                    break;
+                default:
+                    ALOGW("unrecognized copyBufferToGolden %d", frameHdr->copyBufferToAlternate);
+                    break;
+            }
+        }
+
+        if (frameHdr->refreshLast)
+            mLastPicture = picture;
+
+        return true;
+    }
+
+    bool VP8Decoder::drainInternal (bool waitKeyFrame)
+    {
+        bool ret;
+
+        ret = drainOutputQueue(0);
+        mLastPicture.reset();
+        mGoldenRefPicture.reset();
+        mAltRefPicture.reset();
+
+        mWaitKeyFrame = waitKeyFrame;
+
+        return ret;
+    }
+
+    void VP8Decoder::flush (void)
+    {
+        ALOGD("flush");
+
+        reset();
+    }
+
+    bool VP8Decoder::drain (void)
+    {
+        return drainInternal(true);
+    }
+
+    bool VP8Decoder::decode (std::unique_ptr<ConstBitstreamBuffer> buffer)
+    {
+        VP8FrameHdr frameHdr;
+        const VP8PicturePtr &picture = std::make_shared<VP8Picture>();
+        VP8Parser::Result parseRet;
+        bool ret = true;
+
+        std::optional<C2ReadView> view = buffer->dmabuf.map().get();
+
+        parseRet = mParser.parseFrameHeader(frameHdr, view->data(), view->capacity());
+        if (parseRet != VP8Parser::Ok) {
+            ALOGE("Cannot parse frame header");
+            ret = false;
+            goto unmapAndError;
+        }
+
+        if (mWaitKeyFrame) {
+            if (!frameHdr.keyFrame) {
+                ALOGV("Waiting initial keyframe, drop buffer");
+                return true;
+            }
+
+            mWaitKeyFrame = false;
+        }
+
+        if (frameHdr.keyFrame) {
+            ALOGV("Handle key frame");
+            ret = checkCodecChange(frameHdr);
+            if (!ret) {
+                ALOGW("Subclass cannot handle codec change");
+                goto unmapAndError;
+            }
+        }
+
+        picture->frameHdr = frameHdr;
+        picture->data = view->data();
+        picture->size = view->capacity();
+        picture->systemFrameNumber = buffer->id;
+
+        ret = newPicture(*buffer, picture);
+        if (!ret) {
+            ALOGW("subclass failed to handle new picture");
+            goto unmapAndError;
+        }
+
+        ret = startPicture(picture);
+        if (!ret) {
+            ALOGW("subclass failed to handle start picture");
+            goto unmapAndError;
+        }
+
+        ret = decodePicture(picture);
+        if (!ret) {
+            ALOGW("subclass failed to decode current picture");
+            goto unmapAndError;
+        }
+
+        ret = endPicture(picture);
+        if (!ret) {
+            ALOGW("subclass failed to handle end picture");
+            goto unmapAndError;
+        }
+
+        // unmap the buffer
+        view = std::nullopt;
+        updateReference(picture);
+
+        if (!picture->frameHdr.showFrame) {
+            ALOGV("Decode only picture %p", picture.get());
+        } else {
+            mOutputQueue.push(picture);
+        }
+
+        if (!drainOutputQueue(mPreferredOutputDelay)) {
+            ALOGE("Output failed");
+            return false;
+        }
+
+        if (!ret) {
+            ALOGE("Failed to decode data");
+        }
+
+        return ret;
+
+unmapAndError:
+        // unmap the buffer
+        view = std::nullopt;
+        goto error;
+
+error:
+        if (!ret) {
+            ALOGE("Failed to decode data");
+        }
+
+        return ret;
+    }
+
+    bool VP8Decoder::drainOutputQueue (unsigned int num)
+    {
+        bool ret = true;
+
+        while (mOutputQueue.size() > num) {
+            bool aux = outputPicture(std::move(mOutputQueue.front()));
+            if (!aux)
+            {
+                ALOGE("outputPicture failed\n");
+                ret = false;
+            }
+            mOutputQueue.pop();
+        }
+
+        return ret;
+    }
+}
diff --git a/components/vp8/parser/ByteReader.cpp b/components/vp8/parser/ByteReader.cpp
new file mode 100644
index 0000000..5c96361
--- /dev/null
+++ b/components/vp8/parser/ByteReader.cpp
@@ -0,0 +1,134 @@
+/*
+ * Copyright 2024, The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <v4l2_codec2/components/vp8/parser/ByteReader.h>
+#include <log/log.h>
+
+namespace android {
+
+ByteReader::ByteReader (const uint8_t *data, size_t size): mData(data), mSize(size)
+{
+}
+
+uint8_t ByteReader::getUint8 (uint8_t &val)
+{
+    if (mPos == mSize)
+    {
+        ALOGE("Trying to read uint8 from 0 bytes");
+        return false; // TODO: Raise something
+    }
+
+    val = mData[mPos ++];
+
+    return true;
+}
+
+uint16_t ByteReader::getUint16Le (uint16_t &val)
+{
+    if (mPos > mSize - sizeof(uint16_t))
+    {
+        ALOGE("Trying to read uint16 from %lu bytes", mSize - mPos);
+        return false; // TODO: Raise something
+    }
+
+    val = mData[mPos ++];
+    val |= ((uint16_t) mData[mPos ++] << 8);
+
+    return true;
+}
+
+uint16_t ByteReader::getUint16Be (uint16_t &val)
+{
+    if (mPos > mSize - sizeof(uint16_t))
+    {
+        ALOGE("Trying to read uint16 from %lu bytes", mSize - mPos);
+        return false; // TODO: Raise something
+    }
+
+    val = ((uint16_t) mData[mPos ++] << 8);
+    val |= mData[mPos ++];
+
+    return true;
+}
+
+uint32_t ByteReader::getUint24Le (uint32_t &val)
+{
+    if (mPos > mSize - 3)
+    {
+        ALOGE("Trying to read uint24 from %lu bytes", mSize - mPos);
+        return false; // TODO: Raise something
+    }
+
+    val = mData[mPos ++];
+    val |= ((uint32_t) mData[mPos ++] << 8);
+    val |= ((uint32_t) mData[mPos ++] << 16);
+
+    return true;
+}
+
+uint32_t ByteReader::getUint24Be (uint32_t &val)
+{
+    if (mPos > mSize - 3)
+    {
+        ALOGE("Trying to read uint24 from %lu bytes", mSize - mPos);
+        return false; // TODO: Raise something
+    }
+
+    val = ((uint32_t) mData[mPos ++] << 16);
+    val |= ((uint32_t) mData[mPos ++] << 8);
+    val |= mData[mPos ++];
+
+    return true;
+}
+
+uint32_t ByteReader::getUint32Le (uint32_t &val)
+{
+    if (mPos > mSize - sizeof(uint32_t))
+    {
+        ALOGE("Trying to read uint32 from %lu bytes", mSize - mPos);
+        return false; // TODO: Raise something
+    }
+
+    val = mData[mPos ++];
+    val |= ((uint32_t) mData[mPos ++] << 8);
+    val |= ((uint32_t) mData[mPos ++] << 16);
+    val |= ((uint32_t) mData[mPos ++] << 24);
+
+    return true;
+}
+
+uint32_t ByteReader::getUint32Be (uint32_t &val)
+{
+    if (mPos > mSize - sizeof(uint32_t))
+    {
+        ALOGE("Trying to read uint32 from %lu bytes", mSize - mPos);
+        return false; // TODO: Raise something
+    }
+
+    val = ((uint32_t) mData[mPos ++] << 24);
+    val |= ((uint32_t) mData[mPos ++] << 16);
+    val |= ((uint32_t) mData[mPos ++] << 8);
+    val |= mData[mPos ++];
+
+    return true;
+}
+
+size_t ByteReader::getPos (void)
+{
+    return mPos;
+}
+
+}
diff --git a/components/vp8/parser/VP8BoolDecoder.cpp b/components/vp8/parser/VP8BoolDecoder.cpp
new file mode 100644
index 0000000..6383346
--- /dev/null
+++ b/components/vp8/parser/VP8BoolDecoder.cpp
@@ -0,0 +1,135 @@
+/*
+ * NOTE: some of implementations are copied/modified from WebM code
+ *
+ *  Copyright (c) 2010 The WebM project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include <v4l2_codec2/components/vp8/parser/VP8BoolDecoder.h>
+
+namespace android {
+
+    VP8BoolDecoder::VP8BoolDecoder (const unsigned char *source, unsigned int sourceSz,
+            DecryptCb decryptCb, void *decryptState):
+        mCount(-8), mRange(255), mValue(0), mUserBuffer(source),
+        mUserBufferEnd(source + sourceSz), mDecryptCb(decryptCb), mDecryptState(decryptState)
+    {
+        /* Populate the buffer */
+        fill();
+    }
+
+    void VP8BoolDecoder::fill ()
+    {
+        const unsigned char *bufptr = mUserBuffer;
+        VP8BdValue value = mValue;
+        int count = mCount;
+        int shift = VP8_BD_VALUE_SIZE - 8 - (count + 8);
+        size_t bytesLeft = mUserBufferEnd - bufptr;
+        size_t bitsLeft = bytesLeft * CHAR_BIT;
+        int x = (int) (shift + CHAR_BIT - bitsLeft);
+        int loopEnd = 0;
+        unsigned char decrypted[sizeof(VP8BdValue) + 1];
+
+        if (mDecryptCb) {
+            size_t n = bytesLeft > sizeof(decrypted) ? sizeof(decrypted) : bytesLeft;
+            mDecryptCb(mDecryptState, bufptr, decrypted, (int) n);
+            bufptr = decrypted;
+        }
+
+        if (x >= 0) {
+            count += VP8_LOTS_OF_BITS;
+            loopEnd = x;
+        }
+
+        if (x < 0 || bitsLeft) {
+            while (shift >= loopEnd) {
+                count += CHAR_BIT;
+                value |= (VP8BdValue) * bufptr << shift;
+                ++ bufptr;
+                ++ mUserBuffer;
+                shift -= CHAR_BIT;
+            }
+        }
+
+        mValue = value;
+        mCount = count;
+    }
+
+    int VP8BoolDecoder::decodeBool(int probability)
+    {
+        unsigned int bit = 0;
+        VP8BdValue value;
+        unsigned int split;
+        VP8BdValue bigsplit;
+        int count;
+        unsigned int range;
+
+        split = 1 + (((mRange - 1) * probability) >> 8);
+
+        if (mCount < 0)
+            fill();
+
+        value = mValue;
+        count = mCount;
+
+        bigsplit = (VP8BdValue) split << (VP8_BD_VALUE_SIZE - 8);
+
+        range = split;
+
+        if (value >= bigsplit)
+        {
+            range = mRange - split;
+            value = value - bigsplit;
+            bit = 1;
+        }
+
+        {
+            unsigned int shift = vp8Norm[range];
+            range <<= shift;
+            value <<= shift;
+            count -= shift;
+        }
+
+        mValue = value;
+        mCount = count;
+        mRange = range;
+
+        return bit;
+    }
+
+
+    int VP8BoolDecoder::decodeValue(int bits)
+    {
+        int z = 0;
+        int bit;
+
+        for (bit = bits - 1; bit >= 0; bit --)
+        {
+            z |= decodeBool(0x80) << bit;
+        }
+
+        return z;
+    }
+
+    bool VP8BoolDecoder::inError()
+    {
+        /* Check if we have reached the end of the buffer.
+         *
+         * Field 'mCount' stores the number of bits in the 'value' buffer, minus
+         * 8. The top byte is part of the algorithm, and the remainder is buffered
+         * to be shifted into it. So if mCount == 8, the top 16 bits of 'value' are
+         * occupied, 8 for the algorithm and 8 in the buffer.
+         *
+         * When reading a byte from the user's buffer, mCount is filled with 8 and
+         * one byte is filled into the value buffer. When we reach the end of the
+         * data, mCount is additionally filled with VP8_LOTS_OF_BITS. So when
+         * mCount == VP8_LOTS_OF_BITS - 1, the user's data has been exhausted.
+         */
+        return (mCount > VP8_BD_VALUE_SIZE) && (mCount < VP8_LOTS_OF_BITS);
+    }
+}
diff --git a/components/vp8/parser/VP8Parser.cpp b/components/vp8/parser/VP8Parser.cpp
new file mode 100644
index 0000000..48c72f7
--- /dev/null
+++ b/components/vp8/parser/VP8Parser.cpp
@@ -0,0 +1,455 @@
+/*
+ * NOTE: some of implementations are copied/modified from GStreamer code
+ *
+ * GStreamer
+ * Copyright (C) 2019 Seungha Yang <seungha.yang@navercorp.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public
+ * License along with this library; if not, write to the
+ * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+#include <v4l2_codec2/components/vp8/parser/VP8Parser.h>
+
+#define LOG_NDEBUG 1
+#define LOG_TAG "VP8Parser"
+#include <log/log.h>
+
+#include <cstring>
+#include <string>
+
+#define N_ELEMENTS(arr) (sizeof (arr) / sizeof ((arr)[0]))
+
+namespace android {
+
+    VP8Parser::VP8Parser (void)
+    {
+        init();
+    }
+
+    /* Parse updateSegmentation() */
+    bool VP8Parser::parseUpdateSegmentation (VP8RangeDecoder &rd, VP8Segmentation &seg)
+    {
+        bool update;
+        int i;
+
+        seg.updateMbSegmentationMap = false;
+        seg.updateSegmentFeatureData = false;
+
+        seg.segmentationEnabled = rd.readBool();
+        if (!seg.segmentationEnabled)
+            return true;
+
+        seg.updateMbSegmentationMap = rd.readBool();
+        seg.updateSegmentFeatureData = rd.readBool();
+
+        if (seg.updateSegmentFeatureData) {
+            seg.segmentFeatureMode = rd.readUint(1);
+
+            /* quantizerUpdateValue defaults to zero if update flag is zero
+               (Section 9.3, 4.b) */
+            for (i = 0; i < 4; i ++) {
+                update = rd.readBool();
+                seg.quantizerUpdateValue[i] = update ? rd.readSint(7) : 0;
+            }
+
+            /* lfUpdateValue defaults to zero if update flag is zero
+               (Section 9.3, 4.b) */
+            for (i = 0; i < 4; i ++) {
+                update = rd.readBool();
+                seg.lfUpdateValue[i] = update ? rd.readSint(6) : 0;
+            }
+        }
+
+        /* segmentProb defaults to 255 if update flag is zero
+           (Section 9.3, 5) */
+        if (seg.updateMbSegmentationMap) {
+            for (i = 0; i < 3; i ++) {
+                update = rd.readBool();
+                seg.segmentProb[i] = update ? rd.readUint(8) : 255;
+            }
+        }
+        return true;
+    }
+
+    /* Parse mbLfAdjustments() to update loop filter delta adjustments */
+    bool VP8Parser::parseMbLfAdjustments (VP8RangeDecoder &rd, VP8MbLfAdjustments &adj)
+    {
+        bool update;
+        int i;
+
+        adj.modeRefLfDeltaUpdate = false;
+
+        adj.loopFilterAdjEnable = rd.readBool();
+        if (!adj.loopFilterAdjEnable)
+            return true;
+
+        adj.modeRefLfDeltaUpdate = rd.readBool();
+        if (!adj.modeRefLfDeltaUpdate)
+            return true;
+
+        for (i = 0; i < 4; i ++) {
+            update = rd.readBool();
+            if (update)
+                adj.refFrameDelta[i] = rd.readSint(6);
+        }
+
+        for (i = 0; i < 4; i ++) {
+            update = rd.readBool();
+            if (update)
+                adj.mbModeDelta[i] = rd.readSint(6);
+        }
+
+        return true;
+    }
+
+    /* Parse quantIndices() */
+    bool VP8Parser::parseQuantIndices (VP8RangeDecoder &rd, VP8QuantIndices &qip)
+    {
+        bool update;
+
+        qip.yAcQi = rd.readUint(7);
+
+        update = rd.readBool();
+        qip.yDcDelta = update ? rd.readSint(4) : 0;
+
+        update = rd.readBool();
+        qip.y2DcDelta = update ? rd.readSint(4) : 0;
+
+        update = rd.readBool();
+        qip.y2AcDelta = update ? rd.readSint(4) : 0;
+
+        update = rd.readBool();
+        qip.uvDcDelta = update ? rd.readSint(4) : 0;
+
+        update = rd.readBool();
+        qip.uvAcDelta = update ? rd.readSint(4) : 0;
+
+        return true;
+    }
+
+    /* Parse tokenProbUpdate() to update persistent token probabilities */
+    bool VP8Parser::parseTokenProbUpdate (VP8RangeDecoder &rd, VP8TokenProbs &probs)
+    {
+        int i, j, k, l;
+        uint8_t prob;
+
+        for (i = 0; i < 4; i++) {
+            for (j = 0; j < 8; j++) {
+                for (k = 0; k < 3; k++) {
+                    for (l = 0; l < 11; l++) {
+                        if (rd.read(tokenUpdateProbs[i][j][k][l])) {
+                            prob = rd.readUint(8);
+                            probs.prob[i][j][k][l] = prob;
+                        }
+                    }
+                }
+            }
+        }
+
+        return true;
+    }
+
+    /* Parse probUpdate() to update probabilities used for MV decoding */
+    bool VP8Parser::parseMvProbUpdate (VP8RangeDecoder &rd, VP8MvProbs &probs)
+    {
+        int i, j;
+        uint8_t prob;
+
+        for (i = 0; i < 2; i ++) {
+            for (j = 0; j < 19; j ++) {
+                if (rd.read(mvUpdateProbs[i][j])) {
+                    prob = rd.readUint(7);
+                    probs.prob[i][j] = prob ? (prob << 1) : 1;
+                }
+            }
+        }
+
+        return true;
+    }
+
+    /* Calculate partition sizes */
+
+    bool VP8Parser::calcPartitionSizes (VP8FrameHdr &frameHdr, const uint8_t *data,
+            unsigned int size)
+    {
+        const unsigned int numPartitions = 1 << frameHdr.log2NbrOfDctPartitions;
+        unsigned int i, ofs, partSize, partSizeOfs = frameHdr.firstPartSize;
+
+        ofs = partSizeOfs + 3 * (numPartitions - 1);
+        if (ofs > size) {
+            ALOGE("not enough bytes left to parse partition sizes");
+            return false;
+        }
+
+        /* The size of the last partition is not specified (9.5) */
+        for (i = 0; i < numPartitions - 1; i ++) {
+            partSize = (uint32_t) data[partSizeOfs + 0] |
+                ((uint32_t) data[partSizeOfs + 1] << 8) |
+                ((uint32_t) data[partSizeOfs + 2] << 16);
+            partSizeOfs += 3;
+
+            frameHdr.partitionSize[i] = partSize;
+            ofs += partSize;
+        }
+
+        if (ofs > size) {
+            ALOGE("not enough bytes left to determine the last partition size");
+            return false;
+        }
+        frameHdr.partitionSize[i] = size - ofs;
+
+        while (++ i < N_ELEMENTS(frameHdr.partitionSize))
+            frameHdr.partitionSize[i] = 0;
+
+        return true;
+    }
+
+    /* Parse uncompressed data chunk (19.1) */
+    VP8Parser::Result VP8Parser::parseUncompressedDataChunk (ByteReader &br,
+            VP8FrameHdr &frameHdr)
+    {
+        uint32_t frameTag;
+
+        if (!br.getUint24Le(frameTag))
+            goto error;
+
+        frameHdr.keyFrame = !(frameTag & 0x01);
+        frameHdr.version = (frameTag >> 1) & 0x07;
+        frameHdr.showFrame = (frameTag >> 4) & 0x01;
+        frameHdr.firstPartSize = (frameTag >> 5) & 0x7ffff;
+
+        if (frameHdr.keyFrame) {
+            uint32_t startCode;
+            uint16_t sizeCode;
+
+            if (!br.getUint24Be(startCode))
+                goto error;
+            if (startCode != 0x9d012a)
+                ALOGW("vp8 parser: invalid start code in frame header");
+
+            if (!br.getUint16Le(sizeCode))
+                goto error;
+            frameHdr.width = sizeCode & 0x3fff;
+            frameHdr.horizScaleCode = sizeCode >> 14;
+
+            if (!br.getUint16Le(sizeCode))
+                goto error;
+            frameHdr.height = sizeCode & 0x3fff;
+            frameHdr.vertScaleCode = sizeCode >> 14;
+
+            /* Reset parser state on key frames */
+            init();
+        } else {
+            frameHdr.width = 0;
+            frameHdr.height = 0;
+            frameHdr.horizScaleCode = 0;
+            frameHdr.vertScaleCode = 0;
+        }
+
+        /* Calculated values */
+        frameHdr.dataChunkSize = br.getPos();
+
+        return Ok;
+
+error:
+        ALOGW("error parsing Uncompressed Data Chunk");
+
+        return Error;
+    }
+
+    /* Parse Frame Header (19.2) */
+    VP8Parser::Result VP8Parser::parseFrameHeader (VP8RangeDecoder &rd, VP8FrameHdr &frameHdr)
+    {
+        bool update;
+        unsigned int i;
+
+        if (frameHdr.keyFrame) {
+            frameHdr.colorSpace = rd.readUint(1);
+            frameHdr.clampingType = rd.readUint(1);
+        }
+
+        if (!parseUpdateSegmentation(rd, mSegmentation))
+            goto error;
+
+        frameHdr.filterType = rd.readUint(1);
+        frameHdr.loopFilterLevel = rd.readUint(6);
+        frameHdr.sharpnessLevel = rd.readUint(3);
+
+        if (!parseMbLfAdjustments(rd, mMbLfAdjust))
+            goto error;
+
+        frameHdr.log2NbrOfDctPartitions = rd.readUint(2);
+
+        if (!parseQuantIndices(rd, frameHdr.quantIndices))
+            goto error;
+
+        frameHdr.copyBufferToGolden = 0;
+        frameHdr.copyBufferToAlternate = 0;
+
+        if (frameHdr.keyFrame) {
+            frameHdr.refreshEntropyProbs = rd.readBool();
+
+            frameHdr.refreshLast = true;
+            frameHdr.refreshGoldenFrame = true;
+            frameHdr.refreshAlternateFrame = true;
+
+            memcpy(frameHdr.modeProbs.yProb, kfYModeProbs, sizeof(kfYModeProbs));
+            memcpy(frameHdr.modeProbs.uvProb, kfUvModeProbs, sizeof(kfUvModeProbs));
+        } else {
+            frameHdr.refreshGoldenFrame = rd.readBool();
+            frameHdr.refreshAlternateFrame = rd.readBool();
+
+            if (!frameHdr.refreshGoldenFrame) {
+                frameHdr.copyBufferToGolden = rd.readUint(2);
+            }
+
+            if (!frameHdr.refreshAlternateFrame) {
+                frameHdr.copyBufferToAlternate = rd.readUint(2);
+            }
+
+            frameHdr.signBiasGolden = rd.readUint(1);
+            frameHdr.signBiasAlternate = rd.readUint(1);
+            frameHdr.refreshEntropyProbs = rd.readBool();
+            frameHdr.refreshLast = rd.readBool();
+
+            memcpy(&frameHdr.modeProbs, &mModeProbs, sizeof(mModeProbs));
+        }
+
+        memcpy (&frameHdr.tokenProbs, &mTokenProbs, sizeof(mTokenProbs));
+        memcpy (&frameHdr.mvProbs, &mMvProbs, sizeof(mMvProbs));
+
+        if (!parseTokenProbUpdate(rd, frameHdr.tokenProbs))
+            goto error;
+
+        frameHdr.mbNoSkipCoeff = rd.readBool();
+        if (frameHdr.mbNoSkipCoeff)
+            frameHdr.probSkipFalse = rd.readUint(8);
+
+        if (!frameHdr.keyFrame) {
+            frameHdr.probIntra = rd.readUint(8);
+            frameHdr.probLast = rd.readUint(8);
+            frameHdr.probGf = rd.readUint(8);
+
+            update = rd.readBool();
+            if (update) {
+                for (i = 0; i < 4; i++) {
+                    frameHdr.modeProbs.yProb[i] = rd.readUint(8);
+                }
+            }
+
+            update = rd.readBool();
+            if (update) {
+                for (i = 0; i < 3; i++) {
+                    frameHdr.modeProbs.uvProb[i] = rd.readUint(8);
+                }
+            }
+
+            if (!parseMvProbUpdate(rd, frameHdr.mvProbs))
+                goto error;
+        }
+
+        /* Refresh entropy probabilities */
+        if (frameHdr.refreshEntropyProbs) {
+            memcpy (&mTokenProbs, &frameHdr.tokenProbs, sizeof(frameHdr.tokenProbs));
+            memcpy (&mMvProbs, &frameHdr.mvProbs, sizeof(frameHdr.mvProbs));
+            if (!frameHdr.keyFrame)
+                memcpy(&mModeProbs, &frameHdr.modeProbs, sizeof(frameHdr.modeProbs));
+        }
+
+        /* Calculated values */
+        frameHdr.headerSize = rd.getPos();
+        return Ok;
+
+error:
+        ALOGW("error parsing Frame Header");
+        return Error;
+    }
+
+    /**** API ****/
+    /**
+     * gstVP8ParserInit:
+     * @parser: The #VP8Parser to initialize
+     *
+     * Initializes the supplied @parser structure with its default values.
+     *
+     * Since: 1.4
+     */
+    void VP8Parser::init ()
+    {
+        memset(&mSegmentation, 0, sizeof(mSegmentation));
+        memset(&mMbLfAdjust, 0, sizeof(mMbLfAdjust));
+        memcpy(mTokenProbs.prob, defaultTokenProbs, sizeof(defaultTokenProbs));
+        memcpy(mMvProbs.prob, defaultMvProbs, sizeof(defaultMvProbs));
+        memcpy(mModeProbs.yProb, nkYModeProbs, sizeof(nkYModeProbs));
+        memcpy(mModeProbs.uvProb, nkUvModeProbs, sizeof(nkUvModeProbs));
+    }
+
+    /**
+     * gstVP8ParserParseFrameHeader:
+     * @parser: The #VP8Parser
+     * @frameHdr: The #VP8FrameHdr to fill
+     * @data: The data to parse
+     * @size: The size of the @data to parse
+     *
+     * Parses the VP8 bitstream contained in @data, and fills in @frameHdr
+     * with the information. The supplied @data shall point to a complete
+     * frame since there is no sync code specified for VP8 bitstreams. Thus,
+     * the @size argument shall represent the whole frame size.
+     *
+     * Returns: a #VP8Parser::Result
+     *
+     * Since: 1.4
+     */
+    VP8Parser::Result VP8Parser::parseFrameHeader (VP8FrameHdr &frameHdr, const uint8_t *data,
+            size_t size)
+    {
+        ByteReader br(data, size);
+        VP8Parser::Result result;
+
+        memset(&frameHdr, 0, sizeof(VP8FrameHdr));
+
+        result = parseUncompressedDataChunk(br, frameHdr);
+        if (result != Ok)
+            return result;
+
+        /* Frame Header */
+        if (frameHdr.dataChunkSize + frameHdr.firstPartSize > size)
+            return BrokenData;
+
+        data += frameHdr.dataChunkSize;
+        size -= frameHdr.dataChunkSize;
+
+        {
+            VP8RangeDecoder rd(data, size);
+            VP8RangeDecoder::State rdState;
+
+            result = parseFrameHeader(rd, frameHdr);
+            if (result != Ok)
+                return result;
+
+            /* Calculate partition sizes */
+            if (!calcPartitionSizes(frameHdr, data, size))
+                return BrokenData;
+
+            /* Sync range decoder state */
+            rd.getState(rdState);
+            frameHdr.rdRange = rdState.range;
+            frameHdr.rdValue = rdState.value;
+            frameHdr.rdCount = rdState.count;
+        }
+
+        return Ok;
+    }
+}
diff --git a/components/vp8/parser/VP8RangeDecoder.cpp b/components/vp8/parser/VP8RangeDecoder.cpp
new file mode 100644
index 0000000..05005dc
--- /dev/null
+++ b/components/vp8/parser/VP8RangeDecoder.cpp
@@ -0,0 +1,68 @@
+/*
+ * NOTE: some of implementations are copied/modified from WebM code
+ *
+ *  Copyright (c) 2010 The WebM project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include <v4l2_codec2/components/vp8/parser/VP8RangeDecoder.h>
+
+namespace android {
+
+    VP8RangeDecoder::VP8RangeDecoder (const unsigned char *buf, unsigned int bufSize):
+        VP8BoolDecoder(buf, bufSize, NULL, NULL), mBuf(buf)
+    {
+    }
+
+    int VP8RangeDecoder::read (uint8_t prob)
+    {
+        return decodeBool(prob);
+    }
+
+    int VP8RangeDecoder::readLiteral (int bits)
+    {
+        return decodeValue(bits);
+    }
+
+    unsigned int VP8RangeDecoder::getPos ()
+    {
+        return (mUserBuffer - mBuf) * 8 - (8 + mCount);
+    }
+
+    void VP8RangeDecoder::getState (VP8RangeDecoder::State &state)
+    {
+        if (mCount < 0)
+            fill();
+
+        state.range = mRange;
+        state.value = (uint8_t) (mValue >> (VP8_BD_VALUE_SIZE - 8));
+        state.count = (8 + mCount) % 8;
+    }
+
+    bool VP8RangeDecoder::readBool (void)
+    {
+        return (bool) readLiteral(1);
+    }
+
+    unsigned int VP8RangeDecoder::readUint (int nbits)
+    {
+        return (unsigned int) readLiteral(nbits);
+    }
+
+    int VP8RangeDecoder::readSint (int nbits)
+    {
+        int v;
+
+        v = readLiteral(nbits);
+        if (readLiteral(1))
+            v = -v;
+
+        return v;
+    }
+
+}
diff --git a/plugin_store/Android.bp b/plugin_store/Android.bp
index 621cbfc..ec44f13 100644
--- a/plugin_store/Android.bp
+++ b/plugin_store/Android.bp
@@ -9,7 +9,7 @@ package {
 
 cc_library_shared {
     name: "libc2plugin_store",
-    vendor: true,
+    vendor_available: true,
 
     defaults: [
         "libcodec2-impl-defaults",
-- 
2.34.1

